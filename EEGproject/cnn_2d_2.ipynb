{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For subject 1\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]] - 769\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]] - 769\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True)\n",
    "\n",
    "\n",
    "X_train_1 = X_train_1.reshape(X_train_1.shape[0],1,X_train_1.shape[1],X_train_1.shape[2])\n",
    "X_valid_1 = X_valid_1.reshape(X_valid_1.shape[0],1,X_valid_1.shape[1],X_valid_1.shape[2])\n",
    "X_test_1 = X_test_1.reshape(X_test_1.shape[0],1,X_test_1.shape[1],X_test_1.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = Dataset(X_train_1,y_train_1)\n",
    "val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size = 12,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163.0\n"
     ]
    }
   ],
   "source": [
    "print(489/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net,self).__init__()  # initial the model\\n        self.conv11 = nn.Conv2d(1,25,(1,10)) # depth 25, 22*990\\n        self.bn11 = nn.BatchNorm2d(25)\\n        # permute 990,  22 x 12\\n        self.conv12 = nn.Conv2d(25,25,kernel_size = (2,5),stride = (1,1)) # 25, 21 x 986\\n        self.bn12 = nn.BatchNorm2d(25) \\n        \\n        self.conv13 = nn.Conv2d(25,25,kernel_size = (4,3),stride = (1,1)) # 25, 18 x 984\\n        self.bn13 = nn.BatchNorm2d(25) \\n        \\n        self.conv14 = nn.Conv2d(25,25,kernel_size = (18,2),stride = (1,1)) # 25, 1 x 983\\n        self.bn14 = nn.BatchNorm2d(25) \\n        # permute 0, 2,1,3 ----> N, 1,25,983\\n        self.pool1 = nn.MaxPool2d((1,3),stride = (1,3)) # 1, 25*328\\n        # now do normal conv - maxpool\\n        # block2\\n        # after permute, starts at 1,25,328\\n        self.conv21 = nn.Conv2d(1,50,kernel_size = (25,10),stride = (1,1)) # 50,1,319\\n        self.bn21 = nn.BatchNorm2d(50)\\n        self.pool21 = nn.MaxPool2d((1,3),stride = (1,3))\\n        # block3\\n        self.conv31 = nn.Conv2d(1,100,(50,10))# after permute 1, 100*150\\n        self.bn31 = nn.BatchNorm2d(100)\\n        self.pool31 = nn.MaxPool2d((1,3),stride = (1,3))\\n        #block4\\n        self.conv41 = nn.Conv2d(1,200,(100,10)) # after permute 1, 200*40\\n        self.bn41 = nn.BatchNorm2d(200)\\n        self.pool41= nn.MaxPool2d((1,3),stride = (1,3))\\n        #linear \\n        self.fc1 = nn.Linear(200*7,600)\\n        self.fc2 = nn.Linear(600,60)\\n        self.fc3 = nn.Linear(60,4)\\n        self.drop = nn.Dropout(0.8)\\n \\n    def forward(self,x):\\n        x = F.relu(self.bn11(self.conv11(x)))\\n        x = F.relu(self.bn12(self.conv12(x)))\\n        x = F.relu(self.bn13(self.conv13(x)))\\n        x = F.relu(self.bn14(self.conv14(x)))\\n        #x = F.relu(self.conv11(x))\\n        #x = F.relu(self.conv12(x))\\n        #x = F.relu(self.conv13(x))\\n        #x = F.relu(self.bn14(self.conv14(x)))\\n        x = self.pool1(x)\\n        #print(x.size())\\n        x = x.permute(0,2,1,3)\\n        print(list(x.size())[2])\\n        print(x.shape)\\n        x = x.view(list(x.size())[0],list(x.size())[2],list(x.size())[3])\\n        print(x.shape)\\n        #x = x.reshape()\\n        #print(x.size())\\n        \\n        \\n        # now do normal 2d [conv - max] * 3\\n        x = F.relu(self.bn21(self.conv21(x)))\\n        #x = F.relu(self.conv21(x))\\n        x = x.permute(0,2,1,3)\\n        x = self.pool21(x)\\n        #print('after block 2',x.size())\\n        \\n        x = F.relu(self.bn31(self.conv31(x)))\\n        #x = F.relu(self.conv31(x))\\n        x = x.permute(0,2,1,3)\\n        x = self.pool31(x)\\n        #print(x.size())\\n        \\n        x = F.relu(self.bn41(self.conv41(x)))\\n        #x = F.relu(self.conv41(x))\\n        x = x.permute(0,2,1,3)\\n        x = self.pool41(x)\\n       # print(x.size())\\n        \\n        x = x.view(-1,200*7)\\n        x = F.elu(self.fc1(x))\\n        x = self.drop(F.elu(self.fc2(x)))\\n        x = self.fc3(x)\\n        \\n        return x\\nnet = Net()\\nprint(net)\\n\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.conv11 = nn.Conv2d(1,25,(1,10)) # depth 25, 22*990\n",
    "        self.bn11 = nn.BatchNorm2d(25)\n",
    "        # permute 990,  22 x 12\n",
    "        self.conv12 = nn.Conv2d(25,25,kernel_size = (2,5),stride = (1,1)) # 25, 21 x 986\n",
    "        self.bn12 = nn.BatchNorm2d(25) \n",
    "        \n",
    "        self.conv13 = nn.Conv2d(25,25,kernel_size = (4,3),stride = (1,1)) # 25, 18 x 984\n",
    "        self.bn13 = nn.BatchNorm2d(25) \n",
    "        \n",
    "        self.conv14 = nn.Conv2d(25,25,kernel_size = (18,2),stride = (1,1)) # 25, 1 x 983\n",
    "        self.bn14 = nn.BatchNorm2d(25) \n",
    "        # permute 0, 2,1,3 ----> N, 1,25,983\n",
    "        self.pool1 = nn.MaxPool2d((1,3),stride = (1,3)) # 1, 25*328\n",
    "        # now do normal conv - maxpool\n",
    "        # block2\n",
    "        # after permute, starts at 1,25,328\n",
    "        self.conv21 = nn.Conv2d(1,50,kernel_size = (25,10),stride = (1,1)) # 50,1,319\n",
    "        self.bn21 = nn.BatchNorm2d(50)\n",
    "        self.pool21 = nn.MaxPool2d((1,3),stride = (1,3))\n",
    "        # block3\n",
    "        self.conv31 = nn.Conv2d(1,100,(50,10))# after permute 1, 100*150\n",
    "        self.bn31 = nn.BatchNorm2d(100)\n",
    "        self.pool31 = nn.MaxPool2d((1,3),stride = (1,3))\n",
    "        #block4\n",
    "        self.conv41 = nn.Conv2d(1,200,(100,10)) # after permute 1, 200*40\n",
    "        self.bn41 = nn.BatchNorm2d(200)\n",
    "        self.pool41= nn.MaxPool2d((1,3),stride = (1,3))\n",
    "        #linear \n",
    "        self.fc1 = nn.Linear(200*7,600)\n",
    "        self.fc2 = nn.Linear(600,60)\n",
    "        self.fc3 = nn.Linear(60,4)\n",
    "        self.drop = nn.Dropout(0.8)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn11(self.conv11(x)))\n",
    "        x = F.relu(self.bn12(self.conv12(x)))\n",
    "        x = F.relu(self.bn13(self.conv13(x)))\n",
    "        x = F.relu(self.bn14(self.conv14(x)))\n",
    "        #x = F.relu(self.conv11(x))\n",
    "        #x = F.relu(self.conv12(x))\n",
    "        #x = F.relu(self.conv13(x))\n",
    "        #x = F.relu(self.bn14(self.conv14(x)))\n",
    "        x = self.pool1(x)\n",
    "        #print(x.size())\n",
    "        x = x.permute(0,2,1,3)\n",
    "        print(list(x.size())[2])\n",
    "        print(x.shape)\n",
    "        x = x.view(list(x.size())[0],list(x.size())[2],list(x.size())[3])\n",
    "        print(x.shape)\n",
    "        #x = x.reshape()\n",
    "        #print(x.size())\n",
    "        \n",
    "        \n",
    "        # now do normal 2d [conv - max] * 3\n",
    "        x = F.relu(self.bn21(self.conv21(x)))\n",
    "        #x = F.relu(self.conv21(x))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.pool21(x)\n",
    "        #print('after block 2',x.size())\n",
    "        \n",
    "        x = F.relu(self.bn31(self.conv31(x)))\n",
    "        #x = F.relu(self.conv31(x))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.pool31(x)\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = F.relu(self.bn41(self.conv41(x)))\n",
    "        #x = F.relu(self.conv41(x))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.pool41(x)\n",
    "       # print(x.size())\n",
    "        \n",
    "        x = x.view(-1,200*7)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.drop(F.elu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "net = Net()\n",
    "print(net)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()  # initial the model\n",
    "        self.conv11 = nn.Conv2d(1,30,(1,10)) # depth 30, 22*991\n",
    "        self.bn11 = nn.BatchNorm2d(30)\n",
    "        # permute 990,  22 x 12\n",
    "        self.conv12 = nn.Conv2d(30,40,kernel_size = (2,5),stride = (1,1)) # 25, 21 x 987\n",
    "        self.bn12 = nn.BatchNorm2d(40) \n",
    "        \n",
    "        self.conv13 = nn.Conv2d(40,40,kernel_size = (5,3),stride = (1,1)) # 25, 17 x 985\n",
    "        self.bn13 = nn.BatchNorm2d(40) \n",
    "        \n",
    "        self.conv14 = nn.Conv2d(40,40,kernel_size = (17,2),stride = (1,1)) # 25, 1 x 984\n",
    "        self.bn14 = nn.BatchNorm2d(40) \n",
    "        # permute 0, 2,1,3 ----> N, 1,25,984\n",
    "        self.pool1 = nn.MaxPool2d((1,4),stride = (1,2)) # 1, 40*491\n",
    " \n",
    "    def forward(self,x):\n",
    "        #x = torch.Tensor(x.numpy().transpose(0,2,1))\n",
    "        x = F.relu(self.bn11(self.conv11(x)))\n",
    "        x = F.relu(self.bn12(self.conv12(x)))\n",
    "        x = F.relu(self.bn13(self.conv13(x)))\n",
    "        x = F.relu(self.bn14(self.conv14(x)))\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = x.permute(0,2,1,3)\n",
    "\n",
    "        x = x.view(list(x.size())[0],list(x.size())[2],list(x.size())[3])\n",
    "        # N, 40,492\n",
    "        x = torch.Tensor(x.detach().numpy().transpose(0,2,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两层CNN + 三层LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        #self.conv = convnet  #这个是用已经训练过得到的CNN\n",
    "        self.conv = ConvNet()  #这个是用没有训练过的CNN\n",
    "        self.LSTM1 = nn.LSTM(input_dim, hidden_dim1, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        self.LSTM2 = nn.LSTM(hidden_dim1*2, hidden_dim2, bidirectional = True, batch_first = True)\n",
    "        self.LSTM3 = nn.LSTM(hidden_dim2*2, hidden_dim3, bidirectional = True, batch_first = True)\n",
    "        self.fc1 = nn.Linear(hidden_dim3*2*491, 1000) #要取决于用那种数据，249对应未处理的数据，124对应嵘哥的downsample数据（嵘哥ds！）\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        self.drop1 = nn.Dropout(0.9)\n",
    "        self.fc2 = nn.Linear(1000,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        x = self.conv(x)\n",
    "        if type(h) == type(None) and type(c) == type(None):\n",
    "            out, (hn, cn) = self.LSTM1(x)\n",
    "            out, (hn, cn) = self.LSTM2(out)\n",
    "            out, (hn, cn) = self.LSTM3(out)\n",
    "        else:\n",
    "            out, (hn, cn) = self.LSTM1(x, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM2(out, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM3(out, h.detach(), c.detach())\n",
    "        #out = self.drop1(F.relu(self.bn1(self.fc1(out[:, -1, :]))))\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(out.reshape(out.shape[0],-1)))))\n",
    "        out = self.drop1(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 40\n",
    "hidden_dim1 = 40\n",
    "hidden_dim2 = 40\n",
    "hidden_dim3 = 40\n",
    "output_dim = 4\n",
    "model = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),alpha = 0.99, lr=0.001, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1      time: 26.32    train_loss: 8.226    train acc: 0.344    val_loss: 5.619    val acc: 0.229\n",
      "epoch: 2      time: 25.90    train_loss: 8.033    train acc: 0.328    val_loss: 5.714    val acc: 0.229\n",
      "epoch: 3      time: 25.51    train_loss: 7.747    train acc: 0.413    val_loss: 5.577    val acc: 0.292\n",
      "epoch: 4      time: 25.44    train_loss: 7.566    train acc: 0.450    val_loss: 5.682    val acc: 0.375\n",
      "epoch: 5      time: 25.36    train_loss: 7.440    train acc: 0.487    val_loss: 5.436    val acc: 0.354\n",
      "epoch: 6      time: 25.30    train_loss: 7.385    train acc: 0.508    val_loss: 5.475    val acc: 0.396\n",
      "epoch: 7      time: 25.31    train_loss: 7.158    train acc: 0.587    val_loss: 5.670    val acc: 0.271\n",
      "epoch: 8      time: 25.33    train_loss: 7.155    train acc: 0.614    val_loss: 5.670    val acc: 0.292\n",
      "epoch: 9      time: 25.41    train_loss: 6.955    train acc: 0.688    val_loss: 5.635    val acc: 0.271\n",
      "epoch: 10     time: 25.27    train_loss: 6.972    train acc: 0.677    val_loss: 5.501    val acc: 0.271\n",
      "epoch: 11     time: 25.52    train_loss: 6.663    train acc: 0.704    val_loss: 5.466    val acc: 0.271\n",
      "epoch: 12     time: 26.84    train_loss: 6.849    train acc: 0.656    val_loss: 5.754    val acc: 0.250\n",
      "epoch: 13     time: 26.61    train_loss: 6.463    train acc: 0.704    val_loss: 5.667    val acc: 0.229\n",
      "epoch: 14     time: 26.07    train_loss: 6.547    train acc: 0.767    val_loss: 5.534    val acc: 0.312\n",
      "epoch: 15     time: 25.80    train_loss: 6.467    train acc: 0.698    val_loss: 5.450    val acc: 0.333\n",
      "epoch: 16     time: 25.37    train_loss: 6.363    train acc: 0.534    val_loss: 5.681    val acc: 0.271\n",
      "epoch: 17     time: 25.55    train_loss: 6.189    train acc: 0.841    val_loss: 5.512    val acc: 0.271\n",
      "epoch: 18     time: 25.56    train_loss: 6.130    train acc: 0.550    val_loss: 5.460    val acc: 0.229\n",
      "epoch: 19     time: 25.53    train_loss: 5.751    train acc: 0.720    val_loss: 5.486    val acc: 0.271\n",
      "epoch: 20     time: 25.35    train_loss: 6.035    train acc: 0.587    val_loss: 5.771    val acc: 0.292\n",
      "epoch: 21     time: 25.36    train_loss: 5.471    train acc: 0.683    val_loss: 5.479    val acc: 0.354\n",
      "epoch: 22     time: 25.80    train_loss: 5.586    train acc: 0.783    val_loss: 5.541    val acc: 0.292\n",
      "epoch: 23     time: 25.42    train_loss: 5.338    train acc: 0.746    val_loss: 5.377    val acc: 0.333\n",
      "epoch: 24     time: 25.63    train_loss: 5.063    train acc: 0.836    val_loss: 5.196    val acc: 0.396\n",
      "epoch: 25     time: 25.53    train_loss: 6.264    train acc: 0.497    val_loss: 5.980    val acc: 0.167\n",
      "epoch: 26     time: 26.41    train_loss: 6.264    train acc: 0.519    val_loss: 5.667    val acc: 0.229\n",
      "epoch: 27     time: 26.22    train_loss: 5.764    train acc: 0.534    val_loss: 5.536    val acc: 0.229\n",
      "epoch: 28     time: 26.00    train_loss: 4.964    train acc: 0.788    val_loss: 5.308    val acc: 0.417\n",
      "epoch: 29     time: 26.29    train_loss: 4.793    train acc: 0.868    val_loss: 5.386    val acc: 0.354\n",
      "epoch: 30     time: 25.58    train_loss: 5.356    train acc: 0.656    val_loss: 5.560    val acc: 0.208\n",
      "epoch: 31     time: 25.48    train_loss: 4.720    train acc: 0.862    val_loss: 5.157    val acc: 0.354\n",
      "epoch: 32     time: 25.98    train_loss: 4.301    train acc: 0.852    val_loss: 5.477    val acc: 0.312\n",
      "epoch: 33     time: 26.34    train_loss: 5.236    train acc: 0.630    val_loss: 5.625    val acc: 0.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-529908493c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-141-0b5bbaa7693b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-d57e139cb773>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#x = torch.Tensor(x.numpy().transpose(0,2,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "t0 = time.time()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    tstart = time.time()\n",
    "    for i, data in enumerate(train_loader_1):\n",
    "        inputs, labels = data\n",
    "        #inputs = convnet(inputs)\n",
    "        #inputs = torch.Tensor(inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "    model.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    train_loss = 0\n",
    "    for train_data in train_loader_1:\n",
    "        train_inputs, train_labels = train_data\n",
    "        #train_inputs = convnet(train_inputs)\n",
    "        #train_inputs = torch.Tensor(train_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        train_outputs = model(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "        train_loss += criterion(train_outputs, train_labels).item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append(train_loss)\n",
    "        \n",
    "    #pXtrain = model(Xtrain)\n",
    "    #ptrain = torch.argmax(pXtrain, axis = 1)\n",
    "    #train_acc = np.mean(ptrain.numpy() == ytrain.numpy())\n",
    "    #train_accs.append(train_acc)\n",
    "    #tloss = criterion(pXtrain, ytrain)\n",
    "    #train_losses.append(tloss.item())\n",
    "    \n",
    "    val_correct, val_total = 0, 0\n",
    "    val_loss = 0\n",
    "    for val_data in val_loader_1:\n",
    "        val_inputs, val_labels = val_data\n",
    "        #val_inputs = convnet(val_inputs)\n",
    "        #val_inputs = torch.Tensor(val_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        val_outputs = model(val_inputs)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "        val_loss += criterion(val_outputs, val_labels).item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    val_loss_history.append(val_loss)\n",
    "    \n",
    "    #pXval = model(Xval)\n",
    "    #pval = torch.argmax(pXval, axis = 1)\n",
    "    #val_acc = np.mean(pval.numpy() == yval.numpy())\n",
    "    #val_accs.append(val_acc)\n",
    "    #vloss = criterion(pXval, yval)\n",
    "    #val_losses.append(vloss.item())\n",
    "    tend = time.time()\n",
    "    print('epoch: {:<3d}    time: {:<3.2f}    train_loss: {:<3.3f}    train acc: {:<1.3f}    val_loss: {:<3.3f}    val acc: {:<1.3f}'.format(epoch+1, \n",
    "            tend - tstart, train_loss, train_acc, val_loss, val_acc))\n",
    "time_total = time.time() - t0\n",
    "print('Total time: {:4.3f} seconds, average time per epoch: {:4.3f}'.format(time_total, time_total / num_epochs))\n",
    "\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_inputs, test_labels = test_data\n",
    "    #test_inputs = convnet(test_inputs)\n",
    "    #test_inputs = torch.Tensor(test_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "    test_outputs = model(test_inputs)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
