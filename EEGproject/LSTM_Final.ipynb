{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train_valid)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_test)\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_1,   (236, 22, 500)\n",
      "X_train_s   (472, 22, 500)\n",
      "(472, 22, 1000)\n",
      "(708, 22, 1000)\n",
      "(708,)\n",
      "(708, 22, 1000)\n",
      "(708,)\n",
      "(50, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Read trainingdata for one subject and sample them\n",
    "\n",
    "def double_ax2(a):\n",
    "    result = np.zeros((a.shape[0],a.shape[1],a.shape[2] * 2))\n",
    "    b = np.reshape(a[:,:,-1],(a.shape[0],a.shape[1],1))\n",
    "    aMod = np.concatenate((a,b),axis = 2)\n",
    "    for i in range(a.shape[2]):\n",
    "        ave = (aMod[:,:,i] + aMod[:,:,i+1]) / 2\n",
    "        result[:,:,2 * i] = aMod[:,:,i]\n",
    "        result[:,:,2*i + 1] = ave\n",
    "    return result\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==1)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==1)[0]]\n",
    "X_test_1 = X_test[np.where(person_test==1)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==1)[0]]\n",
    "#--------------------------------------------------------------------------------------------------------------\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "#                                                              test_size=0.2,shuffle=True,stratify=y_train_valid_1)\n",
    "\n",
    "#print(X_train_1.shape)\n",
    "\n",
    "num_time = X_train_valid_1.shape[2]\n",
    "sample_1 = list(np.arange(0,num_time,2))\n",
    "sample_2 = list(np.arange(1,num_time,2))\n",
    "\n",
    "X_tr_1 = X_train_valid_1[:,:,sample_1]\n",
    "X_tr_2 = X_train_valid_1[:,:,sample_2]\n",
    "#X_test_s1 = X_test[:,:,sample_1]\n",
    "#X_test_s2 = X_test[:,:,sample_2]\n",
    "print('X_tr_1,  ',X_tr_1.shape)\n",
    "\n",
    "#X_train_s = X_tr_1   \n",
    "X_train_s = np.concatenate((X_tr_1,X_tr_2), axis=0)  \n",
    "#y_train_s = y_train_1  \n",
    "y_train_s = np.concatenate((y_train_valid_1,y_train_valid_1), axis=0) \n",
    "print('X_train_s  ',X_train_s.shape)\n",
    "X_train_s_x2 = double_ax2(X_train_s)\n",
    "print(X_train_s_x2.shape)\n",
    "X_train_s = np.concatenate((X_train_valid_1,X_train_s_x2), axis=0)\n",
    "print(X_train_s.shape)\n",
    "\n",
    "y_train_s = np.concatenate((y_train_valid_1,y_train_s), axis=0)\n",
    "print(y_train_s.shape)\n",
    "\n",
    "#person_train_valid_s = np.concatenate((person_train_valid,person_train_valid,person_train_valid), axis=0)\n",
    "#person_test_s = person_test\n",
    "#X_test_s = np.concatenate((X_test_s1,X_test_s2), axis=0)\n",
    "X_test_s = X_test_1\n",
    "#X_test_s1\n",
    "#y_test_s = np.concatenate((y_test,y_test), axis=0)\n",
    "y_test_s = y_test_1\n",
    "#y_test\n",
    "#person_test_s = np.concatenate((person_test,person_test), axis=0)\n",
    "\n",
    "print(X_train_s.shape)\n",
    "print(y_train_s.shape)\n",
    "print(X_test_s.shape)\n",
    "#print(person_train_s.shape)\n",
    "#print(person_test.shape)\n",
    "X_train_s = X_train_s.transpose(0,2,1)\n",
    "#X_valid_1 = X_valid_1.transpose(0,2,1)\n",
    "X_test_1 = X_test_1.transpose(0,2,1)\n",
    "\n",
    "train_set_1 = Dataset(X_train_s,y_train_s)\n",
    "#val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=72,shuffle=True)\n",
    "#val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "torch.Size([72, 1000, 22]) torch.Size([72])\n",
      "torch.Size([72, 1000, 22]) torch.Size([72])\n",
      "torch.Size([72, 1000, 22]) torch.Size([72])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s.shape[0])\n",
    "for i, data in enumerate(train_loader_1):\n",
    "    print(data[0].shape, data[1].shape)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 1000, 22])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(22, 40, kernel_size=(2,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(40, 60, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (conv3): Conv1d(60, 80, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(80, 100, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv1d(100, 120, kernel_size=(3,), stride=(2,))\n",
      "  (bn5): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc1): Linear(in_features=7320, out_features=300, bias=True)\n",
      "  (bn6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.8, inplace=False)\n",
      "  (fc2): Linear(in_features=300, out_features=40, bias=True)\n",
      "  (bn7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop2): Dropout(p=0.8, inplace=False)\n",
      "  (fc3): Linear(in_features=40, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# [conv-relu]*2 -> 2*2 avg-pooling -> [conv-relu]*3 -> 2*2 avg_pooling -> (affine-relu)*2 -> affine -> softmax\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.AvgPool1d(2,2) \n",
    "        \n",
    "        self.conv3 = nn.Conv1d(60,80,kernel_size = 3, stride = 1) \n",
    "        self.bn3 = nn.BatchNorm1d(80)\n",
    "        self.conv4 = nn.Conv1d(80,100,kernel_size = 3, stride = 1) \n",
    "        self.bn4 = nn.BatchNorm1d(100)\n",
    "        self.conv5 = nn.Conv1d(100,120,kernel_size = 3, stride = 2) #120*122\n",
    "        self.bn5 = nn.BatchNorm1d(120)\n",
    "        self.pool2 = nn.AvgPool1d(2,2) #120*61\n",
    "        \n",
    "        self.fc1 = nn.Linear(120*61, 300) # input dim , output dim\n",
    "        self.bn6 = nn.BatchNorm1d(300)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(300,40)  \n",
    "        self.bn7 = nn.BatchNorm1d(40)\n",
    "        self.drop2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(40,4)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1) \n",
    "        #x = torch.Tensor(x.numpy().transpose(0,2,1))\n",
    "        x = self.pool1(F.elu(self.bn2(self.conv2(F.elu(self.bn1(self.conv1(x)))))))\n",
    "        x = F.elu(self.bn3(self.conv3(x)))\n",
    "        x = F.elu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(F.elu(self.bn5(self.conv5(x))))\n",
    "        x = x.view(-1,120*61)\n",
    "        \n",
    "        x = self.drop1(F.elu(self.bn6(self.fc1(x))))\n",
    "        x = self.drop2(F.elu(self.bn7(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN投票**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training Net 1\n",
      "Epoch 1 | Iter1 | Loss2.7302 | TrainAcc0.2917 | Testacc 0.2400\n",
      "Epoch 1 | Iter3 | Loss2.6363 | TrainAcc0.3056 | Testacc 0.2400\n",
      "Epoch 1 | Iter5 | Loss2.6781 | TrainAcc0.3333 | Testacc 0.2600\n",
      "Epoch 1 | Iter7 | Loss2.5519 | TrainAcc0.3194 | Testacc 0.3000\n",
      "Epoch 1 | Iter9 | Loss2.5456 | TrainAcc0.2833 | Testacc 0.3200\n",
      "Epoch 2 | Iter1 | Loss2.6045 | TrainAcc0.3333 | Testacc 0.3600\n",
      "Epoch 2 | Iter3 | Loss2.5562 | TrainAcc0.3056 | Testacc 0.3400\n",
      "Epoch 2 | Iter5 | Loss2.3187 | TrainAcc0.3750 | Testacc 0.3000\n",
      "Epoch 2 | Iter7 | Loss2.3908 | TrainAcc0.3056 | Testacc 0.3200\n",
      "Epoch 2 | Iter9 | Loss2.4018 | TrainAcc0.4333 | Testacc 0.3200\n",
      "Epoch 3 | Iter1 | Loss2.2943 | TrainAcc0.4306 | Testacc 0.3600\n",
      "Epoch 3 | Iter3 | Loss2.3769 | TrainAcc0.3611 | Testacc 0.3800\n",
      "Epoch 3 | Iter5 | Loss2.3994 | TrainAcc0.4028 | Testacc 0.3600\n",
      "Epoch 3 | Iter7 | Loss2.3658 | TrainAcc0.3333 | Testacc 0.4000\n",
      "Epoch 3 | Iter9 | Loss2.2462 | TrainAcc0.4000 | Testacc 0.4200\n",
      "Epoch 4 | Iter1 | Loss2.2744 | TrainAcc0.4167 | Testacc 0.4000\n",
      "Epoch 4 | Iter3 | Loss2.3985 | TrainAcc0.3750 | Testacc 0.4000\n",
      "Epoch 4 | Iter5 | Loss2.2340 | TrainAcc0.4444 | Testacc 0.4000\n",
      "Epoch 4 | Iter7 | Loss2.2506 | TrainAcc0.4306 | Testacc 0.4200\n",
      "Epoch 4 | Iter9 | Loss2.1681 | TrainAcc0.4667 | Testacc 0.4200\n",
      "Epoch 5 | Iter1 | Loss2.0566 | TrainAcc0.5417 | Testacc 0.4200\n",
      "Epoch 5 | Iter3 | Loss2.0986 | TrainAcc0.4722 | Testacc 0.4400\n",
      "Epoch 5 | Iter5 | Loss2.1532 | TrainAcc0.5139 | Testacc 0.4400\n",
      "Epoch 5 | Iter7 | Loss2.0854 | TrainAcc0.5278 | Testacc 0.4200\n",
      "Epoch 5 | Iter9 | Loss2.0859 | TrainAcc0.5167 | Testacc 0.4400\n",
      "Epoch 6 | Iter1 | Loss2.1487 | TrainAcc0.5000 | Testacc 0.4600\n",
      "Epoch 6 | Iter3 | Loss2.0439 | TrainAcc0.5556 | Testacc 0.4800\n",
      "Epoch 6 | Iter5 | Loss2.0077 | TrainAcc0.6389 | Testacc 0.4800\n",
      "Epoch 6 | Iter7 | Loss1.8611 | TrainAcc0.6250 | Testacc 0.4600\n",
      "Epoch 6 | Iter9 | Loss1.9607 | TrainAcc0.5833 | Testacc 0.4600\n",
      "Epoch 7 | Iter1 | Loss2.1310 | TrainAcc0.4722 | Testacc 0.4800\n",
      "Epoch 7 | Iter3 | Loss1.9226 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 7 | Iter5 | Loss2.0246 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 7 | Iter7 | Loss1.9376 | TrainAcc0.6111 | Testacc 0.5000\n",
      "Epoch 7 | Iter9 | Loss2.0181 | TrainAcc0.5500 | Testacc 0.5000\n",
      "Epoch 8 | Iter1 | Loss2.0653 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 8 | Iter3 | Loss1.8931 | TrainAcc0.6389 | Testacc 0.4800\n",
      "Epoch 8 | Iter5 | Loss1.8393 | TrainAcc0.6944 | Testacc 0.4800\n",
      "Epoch 8 | Iter7 | Loss1.8832 | TrainAcc0.6944 | Testacc 0.4600\n",
      "Epoch 8 | Iter9 | Loss1.8673 | TrainAcc0.6333 | Testacc 0.4600\n",
      "Epoch 9 | Iter1 | Loss1.8294 | TrainAcc0.6667 | Testacc 0.4600\n",
      "Epoch 9 | Iter3 | Loss1.8179 | TrainAcc0.6944 | Testacc 0.4600\n",
      "Epoch 9 | Iter5 | Loss1.9589 | TrainAcc0.5833 | Testacc 0.4400\n",
      "Epoch 9 | Iter7 | Loss1.7589 | TrainAcc0.7083 | Testacc 0.4600\n",
      "Epoch 9 | Iter9 | Loss1.9009 | TrainAcc0.6333 | Testacc 0.4400\n",
      "Epoch 10 | Iter1 | Loss1.9114 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 10 | Iter3 | Loss1.8898 | TrainAcc0.6250 | Testacc 0.4600\n",
      "Epoch 10 | Iter5 | Loss1.8302 | TrainAcc0.6111 | Testacc 0.4600\n",
      "Epoch 10 | Iter7 | Loss1.7343 | TrainAcc0.7361 | Testacc 0.4600\n",
      "Epoch 10 | Iter9 | Loss1.8265 | TrainAcc0.6833 | Testacc 0.4800\n",
      "Epoch 11 | Iter1 | Loss1.7941 | TrainAcc0.6528 | Testacc 0.4800\n",
      "Epoch 11 | Iter3 | Loss1.7322 | TrainAcc0.7222 | Testacc 0.5000\n",
      "Epoch 11 | Iter5 | Loss1.7633 | TrainAcc0.7222 | Testacc 0.5000\n",
      "Epoch 11 | Iter7 | Loss1.7355 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 11 | Iter9 | Loss1.6835 | TrainAcc0.7833 | Testacc 0.5200\n",
      "Epoch 12 | Iter1 | Loss1.7639 | TrainAcc0.7083 | Testacc 0.5000\n",
      "Epoch 12 | Iter3 | Loss1.7023 | TrainAcc0.7778 | Testacc 0.5200\n",
      "Epoch 12 | Iter5 | Loss1.8023 | TrainAcc0.6528 | Testacc 0.5000\n",
      "Epoch 12 | Iter7 | Loss1.7413 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 12 | Iter9 | Loss1.7382 | TrainAcc0.7000 | Testacc 0.5200\n",
      "Epoch 13 | Iter1 | Loss1.7487 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 13 | Iter3 | Loss1.7784 | TrainAcc0.6944 | Testacc 0.5200\n",
      "Epoch 13 | Iter5 | Loss1.6798 | TrainAcc0.7778 | Testacc 0.5000\n",
      "Epoch 13 | Iter7 | Loss1.7315 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 13 | Iter9 | Loss1.7101 | TrainAcc0.7500 | Testacc 0.5000\n",
      "Epoch 14 | Iter1 | Loss1.6094 | TrainAcc0.8194 | Testacc 0.4800\n",
      "Epoch 14 | Iter3 | Loss1.6610 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 14 | Iter5 | Loss1.6002 | TrainAcc0.8056 | Testacc 0.4600\n",
      "Epoch 14 | Iter7 | Loss1.7115 | TrainAcc0.7778 | Testacc 0.4800\n",
      "Epoch 14 | Iter9 | Loss1.6741 | TrainAcc0.7500 | Testacc 0.5000\n",
      "Epoch 15 | Iter1 | Loss1.6687 | TrainAcc0.7917 | Testacc 0.5000\n",
      "Epoch 15 | Iter3 | Loss1.6013 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 15 | Iter5 | Loss1.5970 | TrainAcc0.8611 | Testacc 0.5400\n",
      "Epoch 15 | Iter7 | Loss1.4898 | TrainAcc0.8889 | Testacc 0.5400\n",
      "Epoch 15 | Iter9 | Loss1.5865 | TrainAcc0.8500 | Testacc 0.5000\n",
      "Epoch 16 | Iter1 | Loss1.5322 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 16 | Iter3 | Loss1.5748 | TrainAcc0.7917 | Testacc 0.5200\n",
      "Epoch 16 | Iter5 | Loss1.6547 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 16 | Iter7 | Loss1.6533 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 16 | Iter9 | Loss1.5972 | TrainAcc0.7500 | Testacc 0.5400\n",
      "Epoch 17 | Iter1 | Loss1.5186 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 17 | Iter3 | Loss1.5323 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 17 | Iter5 | Loss1.6526 | TrainAcc0.7500 | Testacc 0.4800\n",
      "Epoch 17 | Iter7 | Loss1.4959 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 17 | Iter9 | Loss1.5584 | TrainAcc0.8000 | Testacc 0.4800\n",
      "Epoch 18 | Iter1 | Loss1.4930 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 18 | Iter3 | Loss1.6678 | TrainAcc0.7639 | Testacc 0.5000\n",
      "Epoch 18 | Iter5 | Loss1.6006 | TrainAcc0.7639 | Testacc 0.5000\n",
      "Epoch 18 | Iter7 | Loss1.4833 | TrainAcc0.8472 | Testacc 0.5000\n",
      "Epoch 18 | Iter9 | Loss1.4777 | TrainAcc0.8833 | Testacc 0.5200\n",
      "Epoch 19 | Iter1 | Loss1.5500 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 19 | Iter3 | Loss1.5500 | TrainAcc0.8194 | Testacc 0.5000\n",
      "Epoch 19 | Iter5 | Loss1.6114 | TrainAcc0.7778 | Testacc 0.4800\n",
      "Epoch 19 | Iter7 | Loss1.4898 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 19 | Iter9 | Loss1.4102 | TrainAcc0.9333 | Testacc 0.4800\n",
      "Epoch 20 | Iter1 | Loss1.5638 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 20 | Iter3 | Loss1.4158 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 20 | Iter5 | Loss1.4270 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 20 | Iter7 | Loss1.5380 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 20 | Iter9 | Loss1.4810 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 21 | Iter1 | Loss1.4771 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 21 | Iter3 | Loss1.4153 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 21 | Iter5 | Loss1.4055 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 21 | Iter7 | Loss1.4856 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 21 | Iter9 | Loss1.4000 | TrainAcc0.8667 | Testacc 0.5000\n",
      "Epoch 22 | Iter1 | Loss1.4279 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 22 | Iter3 | Loss1.4524 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 22 | Iter5 | Loss1.4558 | TrainAcc0.8472 | Testacc 0.5000\n",
      "Epoch 22 | Iter7 | Loss1.3854 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 22 | Iter9 | Loss1.3455 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 23 | Iter1 | Loss1.3272 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 23 | Iter3 | Loss1.4606 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 23 | Iter5 | Loss1.4128 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 23 | Iter7 | Loss1.4167 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 23 | Iter9 | Loss1.3072 | TrainAcc0.9333 | Testacc 0.4800\n",
      "Epoch 24 | Iter1 | Loss1.3875 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 24 | Iter3 | Loss1.3501 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 24 | Iter5 | Loss1.3765 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 24 | Iter7 | Loss1.4062 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 24 | Iter9 | Loss1.3921 | TrainAcc0.9000 | Testacc 0.4800\n",
      "Epoch 25 | Iter1 | Loss1.3529 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 25 | Iter3 | Loss1.3650 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 25 | Iter5 | Loss1.2889 | TrainAcc0.9444 | Testacc 0.4800\n",
      "Epoch 25 | Iter7 | Loss1.3357 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 25 | Iter9 | Loss1.3102 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 26 | Iter1 | Loss1.3835 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 26 | Iter3 | Loss1.3464 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 26 | Iter5 | Loss1.3994 | TrainAcc0.8611 | Testacc 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Iter7 | Loss1.3665 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 26 | Iter9 | Loss1.3998 | TrainAcc0.9000 | Testacc 0.5400\n",
      "Epoch 27 | Iter1 | Loss1.3038 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 27 | Iter3 | Loss1.3159 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 27 | Iter5 | Loss1.4323 | TrainAcc0.8472 | Testacc 0.5000\n",
      "Epoch 27 | Iter7 | Loss1.3861 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 27 | Iter9 | Loss1.3493 | TrainAcc0.9333 | Testacc 0.5200\n",
      "Epoch 28 | Iter1 | Loss1.3051 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 28 | Iter3 | Loss1.3386 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 28 | Iter5 | Loss1.3469 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 28 | Iter7 | Loss1.3815 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 28 | Iter9 | Loss1.3488 | TrainAcc0.8833 | Testacc 0.5200\n",
      "Epoch 29 | Iter1 | Loss1.2434 | TrainAcc0.9861 | Testacc 0.5200\n",
      "Epoch 29 | Iter3 | Loss1.2977 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 29 | Iter5 | Loss1.2878 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 29 | Iter7 | Loss1.2647 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 29 | Iter9 | Loss1.3821 | TrainAcc0.9000 | Testacc 0.5000\n",
      "Epoch 30 | Iter1 | Loss1.2949 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 30 | Iter3 | Loss1.2256 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 30 | Iter5 | Loss1.2857 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 30 | Iter7 | Loss1.2879 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 30 | Iter9 | Loss1.3279 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 31 | Iter1 | Loss1.2752 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 31 | Iter3 | Loss1.3430 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 31 | Iter5 | Loss1.3178 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 31 | Iter7 | Loss1.2247 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 31 | Iter9 | Loss1.3461 | TrainAcc0.8833 | Testacc 0.4800\n",
      "Epoch 32 | Iter1 | Loss1.2171 | TrainAcc0.9722 | Testacc 0.4600\n",
      "Epoch 32 | Iter3 | Loss1.2974 | TrainAcc0.9444 | Testacc 0.4600\n",
      "Epoch 32 | Iter5 | Loss1.2354 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 32 | Iter7 | Loss1.2743 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 32 | Iter9 | Loss1.2651 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 33 | Iter1 | Loss1.2878 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 33 | Iter3 | Loss1.3063 | TrainAcc0.9444 | Testacc 0.4800\n",
      "Epoch 33 | Iter5 | Loss1.1961 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 33 | Iter7 | Loss1.2541 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 33 | Iter9 | Loss1.2099 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 34 | Iter1 | Loss1.2200 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 34 | Iter3 | Loss1.2227 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 34 | Iter5 | Loss1.1820 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 34 | Iter7 | Loss1.2498 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 34 | Iter9 | Loss1.2853 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 35 | Iter1 | Loss1.2929 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 35 | Iter3 | Loss1.3034 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 35 | Iter5 | Loss1.2107 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 35 | Iter7 | Loss1.2392 | TrainAcc0.9444 | Testacc 0.4800\n",
      "Epoch 35 | Iter9 | Loss1.2191 | TrainAcc0.9667 | Testacc 0.4800\n",
      "Test accuracy of model 1:  0.48\n",
      "--------------------------------------------------\n",
      "Training Net 2\n",
      "Epoch 1 | Iter1 | Loss2.7274 | TrainAcc0.2083 | Testacc 0.2400\n",
      "Epoch 1 | Iter3 | Loss2.7774 | TrainAcc0.2639 | Testacc 0.2400\n",
      "Epoch 1 | Iter5 | Loss2.6751 | TrainAcc0.2639 | Testacc 0.2400\n",
      "Epoch 1 | Iter7 | Loss2.5945 | TrainAcc0.3056 | Testacc 0.2400\n",
      "Epoch 1 | Iter9 | Loss2.6386 | TrainAcc0.3000 | Testacc 0.2400\n",
      "Epoch 2 | Iter1 | Loss2.6503 | TrainAcc0.2639 | Testacc 0.2600\n",
      "Epoch 2 | Iter3 | Loss2.4443 | TrainAcc0.4583 | Testacc 0.2600\n",
      "Epoch 2 | Iter5 | Loss2.4114 | TrainAcc0.3056 | Testacc 0.2800\n",
      "Epoch 2 | Iter7 | Loss2.4502 | TrainAcc0.3750 | Testacc 0.3000\n",
      "Epoch 2 | Iter9 | Loss2.3815 | TrainAcc0.3667 | Testacc 0.2800\n",
      "Epoch 3 | Iter1 | Loss2.4265 | TrainAcc0.3194 | Testacc 0.2800\n",
      "Epoch 3 | Iter3 | Loss2.2959 | TrainAcc0.3889 | Testacc 0.3000\n",
      "Epoch 3 | Iter5 | Loss2.3137 | TrainAcc0.3889 | Testacc 0.3000\n",
      "Epoch 3 | Iter7 | Loss2.2146 | TrainAcc0.3889 | Testacc 0.3400\n",
      "Epoch 3 | Iter9 | Loss2.3340 | TrainAcc0.3833 | Testacc 0.4000\n",
      "Epoch 4 | Iter1 | Loss2.0464 | TrainAcc0.5694 | Testacc 0.3600\n",
      "Epoch 4 | Iter3 | Loss2.2270 | TrainAcc0.4722 | Testacc 0.3800\n",
      "Epoch 4 | Iter5 | Loss2.2557 | TrainAcc0.3472 | Testacc 0.4200\n",
      "Epoch 4 | Iter7 | Loss2.3224 | TrainAcc0.4306 | Testacc 0.3600\n",
      "Epoch 4 | Iter9 | Loss2.1381 | TrainAcc0.4667 | Testacc 0.3800\n",
      "Epoch 5 | Iter1 | Loss2.1249 | TrainAcc0.4306 | Testacc 0.4200\n",
      "Epoch 5 | Iter3 | Loss1.9899 | TrainAcc0.5139 | Testacc 0.4400\n",
      "Epoch 5 | Iter5 | Loss2.0565 | TrainAcc0.5417 | Testacc 0.4600\n",
      "Epoch 5 | Iter7 | Loss2.3343 | TrainAcc0.3194 | Testacc 0.4800\n",
      "Epoch 5 | Iter9 | Loss2.0223 | TrainAcc0.5167 | Testacc 0.5000\n",
      "Epoch 6 | Iter1 | Loss2.0706 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 6 | Iter3 | Loss2.0968 | TrainAcc0.5000 | Testacc 0.5000\n",
      "Epoch 6 | Iter5 | Loss2.1085 | TrainAcc0.5139 | Testacc 0.4800\n",
      "Epoch 6 | Iter7 | Loss2.0947 | TrainAcc0.5278 | Testacc 0.5000\n",
      "Epoch 6 | Iter9 | Loss1.9712 | TrainAcc0.5333 | Testacc 0.5000\n",
      "Epoch 7 | Iter1 | Loss1.9263 | TrainAcc0.5972 | Testacc 0.5000\n",
      "Epoch 7 | Iter3 | Loss1.8572 | TrainAcc0.6250 | Testacc 0.5000\n",
      "Epoch 7 | Iter5 | Loss1.9681 | TrainAcc0.5972 | Testacc 0.5000\n",
      "Epoch 7 | Iter7 | Loss2.0268 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 7 | Iter9 | Loss1.9538 | TrainAcc0.6167 | Testacc 0.4600\n",
      "Epoch 8 | Iter1 | Loss1.9209 | TrainAcc0.5972 | Testacc 0.4600\n",
      "Epoch 8 | Iter3 | Loss1.9718 | TrainAcc0.6528 | Testacc 0.4800\n",
      "Epoch 8 | Iter5 | Loss1.9205 | TrainAcc0.6250 | Testacc 0.5000\n",
      "Epoch 8 | Iter7 | Loss1.9711 | TrainAcc0.6528 | Testacc 0.5000\n",
      "Epoch 8 | Iter9 | Loss1.9304 | TrainAcc0.6000 | Testacc 0.5000\n",
      "Epoch 9 | Iter1 | Loss1.8200 | TrainAcc0.6806 | Testacc 0.5000\n",
      "Epoch 9 | Iter3 | Loss1.8820 | TrainAcc0.6389 | Testacc 0.5000\n",
      "Epoch 9 | Iter5 | Loss1.8685 | TrainAcc0.5972 | Testacc 0.5000\n",
      "Epoch 9 | Iter7 | Loss1.9973 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 9 | Iter9 | Loss1.8780 | TrainAcc0.6500 | Testacc 0.4800\n",
      "Epoch 10 | Iter1 | Loss1.8406 | TrainAcc0.6389 | Testacc 0.4800\n",
      "Epoch 10 | Iter3 | Loss1.8935 | TrainAcc0.6250 | Testacc 0.4800\n",
      "Epoch 10 | Iter5 | Loss1.8253 | TrainAcc0.6528 | Testacc 0.5000\n",
      "Epoch 10 | Iter7 | Loss1.7737 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 10 | Iter9 | Loss1.8684 | TrainAcc0.6333 | Testacc 0.5000\n",
      "Epoch 11 | Iter1 | Loss1.8452 | TrainAcc0.6389 | Testacc 0.4800\n",
      "Epoch 11 | Iter3 | Loss1.8145 | TrainAcc0.7222 | Testacc 0.4600\n",
      "Epoch 11 | Iter5 | Loss1.7823 | TrainAcc0.6944 | Testacc 0.4800\n",
      "Epoch 11 | Iter7 | Loss1.6919 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 11 | Iter9 | Loss1.7554 | TrainAcc0.6667 | Testacc 0.4800\n",
      "Epoch 12 | Iter1 | Loss1.6996 | TrainAcc0.7222 | Testacc 0.5000\n",
      "Epoch 12 | Iter3 | Loss1.7168 | TrainAcc0.7500 | Testacc 0.4600\n",
      "Epoch 12 | Iter5 | Loss1.6888 | TrainAcc0.7778 | Testacc 0.4600\n",
      "Epoch 12 | Iter7 | Loss1.7824 | TrainAcc0.6667 | Testacc 0.4200\n",
      "Epoch 12 | Iter9 | Loss1.6978 | TrainAcc0.6833 | Testacc 0.4000\n",
      "Epoch 13 | Iter1 | Loss1.7765 | TrainAcc0.6528 | Testacc 0.4000\n",
      "Epoch 13 | Iter3 | Loss1.7554 | TrainAcc0.7500 | Testacc 0.4000\n",
      "Epoch 13 | Iter5 | Loss1.7406 | TrainAcc0.7222 | Testacc 0.4000\n",
      "Epoch 13 | Iter7 | Loss1.6120 | TrainAcc0.8056 | Testacc 0.4200\n",
      "Epoch 13 | Iter9 | Loss1.6866 | TrainAcc0.7833 | Testacc 0.4200\n",
      "Epoch 14 | Iter1 | Loss1.7401 | TrainAcc0.7500 | Testacc 0.4400\n",
      "Epoch 14 | Iter3 | Loss1.7397 | TrainAcc0.7500 | Testacc 0.4400\n",
      "Epoch 14 | Iter5 | Loss1.6296 | TrainAcc0.7778 | Testacc 0.4600\n",
      "Epoch 14 | Iter7 | Loss1.6687 | TrainAcc0.8333 | Testacc 0.4600\n",
      "Epoch 14 | Iter9 | Loss1.5985 | TrainAcc0.8167 | Testacc 0.4600\n",
      "Epoch 15 | Iter1 | Loss1.6920 | TrainAcc0.7500 | Testacc 0.4800\n",
      "Epoch 15 | Iter3 | Loss1.5849 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 15 | Iter5 | Loss1.6617 | TrainAcc0.7361 | Testacc 0.4600\n",
      "Epoch 15 | Iter7 | Loss1.5692 | TrainAcc0.8194 | Testacc 0.4600\n",
      "Epoch 15 | Iter9 | Loss1.6783 | TrainAcc0.7167 | Testacc 0.4800\n",
      "Epoch 16 | Iter1 | Loss1.5904 | TrainAcc0.8194 | Testacc 0.4800\n",
      "Epoch 16 | Iter3 | Loss1.6101 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 16 | Iter5 | Loss1.6961 | TrainAcc0.7917 | Testacc 0.4600\n",
      "Epoch 16 | Iter7 | Loss1.6407 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 16 | Iter9 | Loss1.6755 | TrainAcc0.7333 | Testacc 0.4800\n",
      "Epoch 17 | Iter1 | Loss1.5218 | TrainAcc0.8611 | Testacc 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Iter3 | Loss1.5783 | TrainAcc0.8194 | Testacc 0.4800\n",
      "Epoch 17 | Iter5 | Loss1.6693 | TrainAcc0.7083 | Testacc 0.4400\n",
      "Epoch 17 | Iter7 | Loss1.4776 | TrainAcc0.8472 | Testacc 0.4600\n",
      "Epoch 17 | Iter9 | Loss1.4691 | TrainAcc0.8833 | Testacc 0.4600\n",
      "Epoch 18 | Iter1 | Loss1.5026 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 18 | Iter3 | Loss1.4491 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 18 | Iter5 | Loss1.5663 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 18 | Iter7 | Loss1.4753 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 18 | Iter9 | Loss1.5103 | TrainAcc0.8500 | Testacc 0.4800\n",
      "Epoch 19 | Iter1 | Loss1.5104 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 19 | Iter3 | Loss1.5768 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 19 | Iter5 | Loss1.4414 | TrainAcc0.9028 | Testacc 0.4400\n",
      "Epoch 19 | Iter7 | Loss1.4024 | TrainAcc0.9167 | Testacc 0.4400\n",
      "Epoch 19 | Iter9 | Loss1.5141 | TrainAcc0.9000 | Testacc 0.4400\n",
      "Epoch 20 | Iter1 | Loss1.5010 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 20 | Iter3 | Loss1.3619 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 20 | Iter5 | Loss1.4554 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 20 | Iter7 | Loss1.4525 | TrainAcc0.8472 | Testacc 0.4600\n",
      "Epoch 20 | Iter9 | Loss1.4762 | TrainAcc0.8500 | Testacc 0.4400\n",
      "Epoch 21 | Iter1 | Loss1.3511 | TrainAcc0.9444 | Testacc 0.4400\n",
      "Epoch 21 | Iter3 | Loss1.4681 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 21 | Iter5 | Loss1.5139 | TrainAcc0.8056 | Testacc 0.5000\n",
      "Epoch 21 | Iter7 | Loss1.3648 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 21 | Iter9 | Loss1.3640 | TrainAcc0.8833 | Testacc 0.4800\n",
      "Epoch 22 | Iter1 | Loss1.4537 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 22 | Iter3 | Loss1.3720 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 22 | Iter5 | Loss1.4455 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 22 | Iter7 | Loss1.3768 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 22 | Iter9 | Loss1.4002 | TrainAcc0.9000 | Testacc 0.4400\n",
      "Epoch 23 | Iter1 | Loss1.4839 | TrainAcc0.8333 | Testacc 0.4400\n",
      "Epoch 23 | Iter3 | Loss1.3343 | TrainAcc0.9583 | Testacc 0.4400\n",
      "Epoch 23 | Iter5 | Loss1.3415 | TrainAcc0.9167 | Testacc 0.4400\n",
      "Epoch 23 | Iter7 | Loss1.4639 | TrainAcc0.8333 | Testacc 0.4400\n",
      "Epoch 23 | Iter9 | Loss1.3976 | TrainAcc0.9000 | Testacc 0.4600\n",
      "Epoch 24 | Iter1 | Loss1.4060 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 24 | Iter3 | Loss1.4102 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 24 | Iter5 | Loss1.4251 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 24 | Iter7 | Loss1.3781 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 24 | Iter9 | Loss1.3438 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 25 | Iter1 | Loss1.3289 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 25 | Iter3 | Loss1.4200 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 25 | Iter5 | Loss1.3446 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 25 | Iter7 | Loss1.3349 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 25 | Iter9 | Loss1.3415 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 26 | Iter1 | Loss1.3218 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 26 | Iter3 | Loss1.3259 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 26 | Iter5 | Loss1.3272 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 26 | Iter7 | Loss1.3631 | TrainAcc0.8750 | Testacc 0.4400\n",
      "Epoch 26 | Iter9 | Loss1.3968 | TrainAcc0.8167 | Testacc 0.4600\n",
      "Epoch 27 | Iter1 | Loss1.3218 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 27 | Iter3 | Loss1.2571 | TrainAcc0.9444 | Testacc 0.4400\n",
      "Epoch 27 | Iter5 | Loss1.2918 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 27 | Iter7 | Loss1.3964 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 27 | Iter9 | Loss1.4394 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 28 | Iter1 | Loss1.4217 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 28 | Iter3 | Loss1.2708 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 28 | Iter5 | Loss1.2870 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 28 | Iter7 | Loss1.2473 | TrainAcc0.9861 | Testacc 0.5200\n",
      "Epoch 28 | Iter9 | Loss1.3652 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 29 | Iter1 | Loss1.3320 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 29 | Iter3 | Loss1.3319 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 29 | Iter5 | Loss1.3003 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 29 | Iter7 | Loss1.3326 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 29 | Iter9 | Loss1.3135 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 30 | Iter1 | Loss1.3245 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 30 | Iter3 | Loss1.2426 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 30 | Iter5 | Loss1.2421 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 30 | Iter7 | Loss1.2889 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 30 | Iter9 | Loss1.3404 | TrainAcc0.9000 | Testacc 0.5200\n",
      "Epoch 31 | Iter1 | Loss1.2797 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 31 | Iter3 | Loss1.2890 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 31 | Iter5 | Loss1.2925 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 31 | Iter7 | Loss1.2933 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 31 | Iter9 | Loss1.2843 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 32 | Iter1 | Loss1.2824 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 32 | Iter3 | Loss1.2524 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 32 | Iter5 | Loss1.1799 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 32 | Iter7 | Loss1.2930 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 32 | Iter9 | Loss1.3134 | TrainAcc0.8833 | Testacc 0.4800\n",
      "Epoch 33 | Iter1 | Loss1.2725 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 33 | Iter3 | Loss1.2364 | TrainAcc0.9722 | Testacc 0.5400\n",
      "Epoch 33 | Iter5 | Loss1.3476 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 33 | Iter7 | Loss1.2240 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 33 | Iter9 | Loss1.2292 | TrainAcc0.9833 | Testacc 0.5200\n",
      "Epoch 34 | Iter1 | Loss1.2901 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 34 | Iter3 | Loss1.2484 | TrainAcc0.9583 | Testacc 0.5200\n",
      "Epoch 34 | Iter5 | Loss1.2879 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 34 | Iter7 | Loss1.2577 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 34 | Iter9 | Loss1.2388 | TrainAcc0.9500 | Testacc 0.5200\n",
      "Epoch 35 | Iter1 | Loss1.2124 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 35 | Iter3 | Loss1.2458 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 35 | Iter5 | Loss1.2044 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 35 | Iter7 | Loss1.2553 | TrainAcc0.9583 | Testacc 0.5200\n",
      "Epoch 35 | Iter9 | Loss1.1997 | TrainAcc0.9833 | Testacc 0.5200\n",
      "Test accuracy of model 2:  0.52\n",
      "--------------------------------------------------\n",
      "Training Net 3\n",
      "Epoch 1 | Iter1 | Loss2.8780 | TrainAcc0.2222 | Testacc 0.3200\n",
      "Epoch 1 | Iter3 | Loss2.6840 | TrainAcc0.2222 | Testacc 0.3400\n",
      "Epoch 1 | Iter5 | Loss2.5380 | TrainAcc0.3056 | Testacc 0.3200\n",
      "Epoch 1 | Iter7 | Loss2.7626 | TrainAcc0.1667 | Testacc 0.3400\n",
      "Epoch 1 | Iter9 | Loss2.5073 | TrainAcc0.3500 | Testacc 0.2800\n",
      "Epoch 2 | Iter1 | Loss2.5297 | TrainAcc0.3194 | Testacc 0.2800\n",
      "Epoch 2 | Iter3 | Loss2.6374 | TrainAcc0.2917 | Testacc 0.3200\n",
      "Epoch 2 | Iter5 | Loss2.4771 | TrainAcc0.3056 | Testacc 0.3600\n",
      "Epoch 2 | Iter7 | Loss2.4155 | TrainAcc0.4444 | Testacc 0.3800\n",
      "Epoch 2 | Iter9 | Loss2.4099 | TrainAcc0.4000 | Testacc 0.3400\n",
      "Epoch 3 | Iter1 | Loss2.4758 | TrainAcc0.3194 | Testacc 0.4200\n",
      "Epoch 3 | Iter3 | Loss2.2311 | TrainAcc0.4722 | Testacc 0.3800\n",
      "Epoch 3 | Iter5 | Loss2.3102 | TrainAcc0.4028 | Testacc 0.4200\n",
      "Epoch 3 | Iter7 | Loss2.1034 | TrainAcc0.4722 | Testacc 0.4200\n",
      "Epoch 3 | Iter9 | Loss2.2372 | TrainAcc0.4500 | Testacc 0.3800\n",
      "Epoch 4 | Iter1 | Loss2.1751 | TrainAcc0.5417 | Testacc 0.3800\n",
      "Epoch 4 | Iter3 | Loss2.1728 | TrainAcc0.4583 | Testacc 0.4000\n",
      "Epoch 4 | Iter5 | Loss2.0006 | TrainAcc0.5833 | Testacc 0.4400\n",
      "Epoch 4 | Iter7 | Loss2.1163 | TrainAcc0.5139 | Testacc 0.4400\n",
      "Epoch 4 | Iter9 | Loss2.1595 | TrainAcc0.4667 | Testacc 0.4600\n",
      "Epoch 5 | Iter1 | Loss2.1219 | TrainAcc0.4444 | Testacc 0.4600\n",
      "Epoch 5 | Iter3 | Loss2.2044 | TrainAcc0.4444 | Testacc 0.4800\n",
      "Epoch 5 | Iter5 | Loss1.8489 | TrainAcc0.6806 | Testacc 0.4800\n",
      "Epoch 5 | Iter7 | Loss2.0177 | TrainAcc0.5417 | Testacc 0.4800\n",
      "Epoch 5 | Iter9 | Loss2.1579 | TrainAcc0.5000 | Testacc 0.4800\n",
      "Epoch 6 | Iter1 | Loss1.9668 | TrainAcc0.5556 | Testacc 0.5000\n",
      "Epoch 6 | Iter3 | Loss2.0228 | TrainAcc0.5139 | Testacc 0.5200\n",
      "Epoch 6 | Iter5 | Loss2.1018 | TrainAcc0.5278 | Testacc 0.5200\n",
      "Epoch 6 | Iter7 | Loss1.9342 | TrainAcc0.6389 | Testacc 0.5200\n",
      "Epoch 6 | Iter9 | Loss2.1035 | TrainAcc0.4667 | Testacc 0.5200\n",
      "Epoch 7 | Iter1 | Loss1.9649 | TrainAcc0.5972 | Testacc 0.5000\n",
      "Epoch 7 | Iter3 | Loss2.0079 | TrainAcc0.6389 | Testacc 0.5000\n",
      "Epoch 7 | Iter5 | Loss1.8987 | TrainAcc0.5972 | Testacc 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Iter7 | Loss1.9298 | TrainAcc0.6250 | Testacc 0.5000\n",
      "Epoch 7 | Iter9 | Loss1.8630 | TrainAcc0.6333 | Testacc 0.5000\n",
      "Epoch 8 | Iter1 | Loss1.8531 | TrainAcc0.6667 | Testacc 0.5000\n",
      "Epoch 8 | Iter3 | Loss1.8327 | TrainAcc0.6944 | Testacc 0.5000\n",
      "Epoch 8 | Iter5 | Loss1.8468 | TrainAcc0.6806 | Testacc 0.5000\n",
      "Epoch 8 | Iter7 | Loss1.8332 | TrainAcc0.6944 | Testacc 0.5200\n",
      "Epoch 8 | Iter9 | Loss1.8708 | TrainAcc0.6667 | Testacc 0.5200\n",
      "Epoch 9 | Iter1 | Loss1.9037 | TrainAcc0.5694 | Testacc 0.5400\n",
      "Epoch 9 | Iter3 | Loss1.8022 | TrainAcc0.6667 | Testacc 0.5400\n",
      "Epoch 9 | Iter5 | Loss1.8153 | TrainAcc0.7361 | Testacc 0.5400\n",
      "Epoch 9 | Iter7 | Loss1.7876 | TrainAcc0.7222 | Testacc 0.5000\n",
      "Epoch 9 | Iter9 | Loss1.8842 | TrainAcc0.6000 | Testacc 0.5000\n",
      "Epoch 10 | Iter1 | Loss1.7302 | TrainAcc0.7222 | Testacc 0.5200\n",
      "Epoch 10 | Iter3 | Loss1.6944 | TrainAcc0.6806 | Testacc 0.5200\n",
      "Epoch 10 | Iter5 | Loss1.7603 | TrainAcc0.7361 | Testacc 0.5600\n",
      "Epoch 10 | Iter7 | Loss1.8266 | TrainAcc0.7361 | Testacc 0.5600\n",
      "Epoch 10 | Iter9 | Loss1.6368 | TrainAcc0.7667 | Testacc 0.5600\n",
      "Epoch 11 | Iter1 | Loss1.6933 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 11 | Iter3 | Loss1.7495 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 11 | Iter5 | Loss1.6987 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 11 | Iter7 | Loss1.7449 | TrainAcc0.6944 | Testacc 0.5200\n",
      "Epoch 11 | Iter9 | Loss1.7561 | TrainAcc0.7000 | Testacc 0.5200\n",
      "Epoch 12 | Iter1 | Loss1.6436 | TrainAcc0.7778 | Testacc 0.5200\n",
      "Epoch 12 | Iter3 | Loss1.6739 | TrainAcc0.7500 | Testacc 0.5400\n",
      "Epoch 12 | Iter5 | Loss1.6570 | TrainAcc0.7778 | Testacc 0.5400\n",
      "Epoch 12 | Iter7 | Loss1.7120 | TrainAcc0.7500 | Testacc 0.5600\n",
      "Epoch 12 | Iter9 | Loss1.6912 | TrainAcc0.7500 | Testacc 0.5600\n",
      "Epoch 13 | Iter1 | Loss1.6822 | TrainAcc0.7917 | Testacc 0.5400\n",
      "Epoch 13 | Iter3 | Loss1.6933 | TrainAcc0.7778 | Testacc 0.5000\n",
      "Epoch 13 | Iter5 | Loss1.6052 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 13 | Iter7 | Loss1.6311 | TrainAcc0.7500 | Testacc 0.4800\n",
      "Epoch 13 | Iter9 | Loss1.7114 | TrainAcc0.7333 | Testacc 0.5200\n",
      "Epoch 14 | Iter1 | Loss1.5480 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 14 | Iter3 | Loss1.5243 | TrainAcc0.8472 | Testacc 0.5000\n",
      "Epoch 14 | Iter5 | Loss1.5817 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 14 | Iter7 | Loss1.6650 | TrainAcc0.7917 | Testacc 0.5400\n",
      "Epoch 14 | Iter9 | Loss1.5973 | TrainAcc0.7333 | Testacc 0.5400\n",
      "Epoch 15 | Iter1 | Loss1.4682 | TrainAcc0.8611 | Testacc 0.5600\n",
      "Epoch 15 | Iter3 | Loss1.5524 | TrainAcc0.7778 | Testacc 0.5400\n",
      "Epoch 15 | Iter5 | Loss1.6419 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 15 | Iter7 | Loss1.5510 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 15 | Iter9 | Loss1.5063 | TrainAcc0.8667 | Testacc 0.5000\n",
      "Epoch 16 | Iter1 | Loss1.5263 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 16 | Iter3 | Loss1.5462 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 16 | Iter5 | Loss1.4957 | TrainAcc0.8056 | Testacc 0.5400\n",
      "Epoch 16 | Iter7 | Loss1.5778 | TrainAcc0.8472 | Testacc 0.5400\n",
      "Epoch 16 | Iter9 | Loss1.5554 | TrainAcc0.8000 | Testacc 0.5000\n",
      "Epoch 17 | Iter1 | Loss1.4905 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 17 | Iter3 | Loss1.4968 | TrainAcc0.8611 | Testacc 0.5400\n",
      "Epoch 17 | Iter5 | Loss1.4989 | TrainAcc0.8472 | Testacc 0.5400\n",
      "Epoch 17 | Iter7 | Loss1.6182 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 17 | Iter9 | Loss1.6479 | TrainAcc0.8167 | Testacc 0.5200\n",
      "Epoch 18 | Iter1 | Loss1.4643 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 18 | Iter3 | Loss1.4131 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 18 | Iter5 | Loss1.4598 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 18 | Iter7 | Loss1.4276 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 18 | Iter9 | Loss1.4623 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 19 | Iter1 | Loss1.4118 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 19 | Iter3 | Loss1.4391 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 19 | Iter5 | Loss1.3834 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 19 | Iter7 | Loss1.4192 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 19 | Iter9 | Loss1.4842 | TrainAcc0.9000 | Testacc 0.5400\n",
      "Epoch 20 | Iter1 | Loss1.4843 | TrainAcc0.8472 | Testacc 0.5400\n",
      "Epoch 20 | Iter3 | Loss1.4781 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 20 | Iter5 | Loss1.4100 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 20 | Iter7 | Loss1.4646 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 20 | Iter9 | Loss1.4291 | TrainAcc0.9000 | Testacc 0.4800\n",
      "Epoch 21 | Iter1 | Loss1.4707 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 21 | Iter3 | Loss1.4243 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 21 | Iter5 | Loss1.4357 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 21 | Iter7 | Loss1.4718 | TrainAcc0.8194 | Testacc 0.5800\n",
      "Epoch 21 | Iter9 | Loss1.4763 | TrainAcc0.8500 | Testacc 0.5600\n",
      "Epoch 22 | Iter1 | Loss1.3955 | TrainAcc0.9028 | Testacc 0.5600\n",
      "Epoch 22 | Iter3 | Loss1.3570 | TrainAcc0.8889 | Testacc 0.5600\n",
      "Epoch 22 | Iter5 | Loss1.4183 | TrainAcc0.8889 | Testacc 0.5400\n",
      "Epoch 22 | Iter7 | Loss1.3679 | TrainAcc0.8750 | Testacc 0.5400\n",
      "Epoch 22 | Iter9 | Loss1.4123 | TrainAcc0.8667 | Testacc 0.5400\n",
      "Epoch 23 | Iter1 | Loss1.4020 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 23 | Iter3 | Loss1.3795 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 23 | Iter5 | Loss1.4141 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 23 | Iter7 | Loss1.3819 | TrainAcc0.8889 | Testacc 0.4600\n",
      "Epoch 23 | Iter9 | Loss1.3297 | TrainAcc0.9333 | Testacc 0.4800\n",
      "Epoch 24 | Iter1 | Loss1.3891 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 24 | Iter3 | Loss1.4600 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 24 | Iter5 | Loss1.3245 | TrainAcc0.9583 | Testacc 0.5200\n",
      "Epoch 24 | Iter7 | Loss1.3092 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 24 | Iter9 | Loss1.2768 | TrainAcc0.9500 | Testacc 0.5000\n",
      "Epoch 25 | Iter1 | Loss1.3255 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 25 | Iter3 | Loss1.2558 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 25 | Iter5 | Loss1.4876 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 25 | Iter7 | Loss1.3223 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 25 | Iter9 | Loss1.2820 | TrainAcc0.9667 | Testacc 0.5200\n",
      "Epoch 26 | Iter1 | Loss1.2631 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 26 | Iter3 | Loss1.2573 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 26 | Iter5 | Loss1.3361 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 26 | Iter7 | Loss1.3534 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 26 | Iter9 | Loss1.3204 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 27 | Iter1 | Loss1.2790 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 27 | Iter3 | Loss1.3355 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 27 | Iter5 | Loss1.3775 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 27 | Iter7 | Loss1.3049 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 27 | Iter9 | Loss1.3249 | TrainAcc0.9333 | Testacc 0.5400\n",
      "Epoch 28 | Iter1 | Loss1.3830 | TrainAcc0.8750 | Testacc 0.5400\n",
      "Epoch 28 | Iter3 | Loss1.2591 | TrainAcc0.9583 | Testacc 0.5400\n",
      "Epoch 28 | Iter5 | Loss1.3609 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 28 | Iter7 | Loss1.3703 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 28 | Iter9 | Loss1.2711 | TrainAcc0.9667 | Testacc 0.5400\n",
      "Epoch 29 | Iter1 | Loss1.3593 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 29 | Iter3 | Loss1.2651 | TrainAcc0.9861 | Testacc 0.5200\n",
      "Epoch 29 | Iter5 | Loss1.2825 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 29 | Iter7 | Loss1.3404 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 29 | Iter9 | Loss1.3516 | TrainAcc0.8667 | Testacc 0.5200\n",
      "Epoch 30 | Iter1 | Loss1.2501 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 30 | Iter3 | Loss1.3696 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 30 | Iter5 | Loss1.2740 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 30 | Iter7 | Loss1.3442 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 30 | Iter9 | Loss1.1849 | TrainAcc0.9667 | Testacc 0.5400\n",
      "Epoch 31 | Iter1 | Loss1.2623 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 31 | Iter3 | Loss1.3029 | TrainAcc0.8889 | Testacc 0.5600\n",
      "Epoch 31 | Iter5 | Loss1.2828 | TrainAcc0.9583 | Testacc 0.5200\n",
      "Epoch 31 | Iter7 | Loss1.1749 | TrainAcc0.9722 | Testacc 0.5400\n",
      "Epoch 31 | Iter9 | Loss1.3446 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 32 | Iter1 | Loss1.2070 | TrainAcc0.9583 | Testacc 0.5400\n",
      "Epoch 32 | Iter3 | Loss1.2569 | TrainAcc0.9583 | Testacc 0.5800\n",
      "Epoch 32 | Iter5 | Loss1.2843 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 32 | Iter7 | Loss1.2704 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 32 | Iter9 | Loss1.3056 | TrainAcc0.9500 | Testacc 0.5600\n",
      "Epoch 33 | Iter1 | Loss1.2424 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 33 | Iter3 | Loss1.2697 | TrainAcc0.9444 | Testacc 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Iter5 | Loss1.2477 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 33 | Iter7 | Loss1.2694 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 33 | Iter9 | Loss1.3426 | TrainAcc0.8167 | Testacc 0.5400\n",
      "Epoch 34 | Iter1 | Loss1.2115 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 34 | Iter3 | Loss1.2327 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 34 | Iter5 | Loss1.3217 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 34 | Iter7 | Loss1.2710 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 34 | Iter9 | Loss1.2910 | TrainAcc0.8833 | Testacc 0.5400\n",
      "Epoch 35 | Iter1 | Loss1.2638 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 35 | Iter3 | Loss1.2866 | TrainAcc0.9028 | Testacc 0.5600\n",
      "Epoch 35 | Iter5 | Loss1.3311 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 35 | Iter7 | Loss1.1545 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 35 | Iter9 | Loss1.2677 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Test accuracy of model 3:  0.5\n",
      "--------------------------------------------------\n",
      "Training Net 4\n",
      "Epoch 1 | Iter1 | Loss2.8514 | TrainAcc0.2639 | Testacc 0.3000\n",
      "Epoch 1 | Iter3 | Loss2.5877 | TrainAcc0.3611 | Testacc 0.3000\n",
      "Epoch 1 | Iter5 | Loss2.6646 | TrainAcc0.2639 | Testacc 0.3600\n",
      "Epoch 1 | Iter7 | Loss2.5085 | TrainAcc0.3472 | Testacc 0.3200\n",
      "Epoch 1 | Iter9 | Loss2.5847 | TrainAcc0.2333 | Testacc 0.2800\n",
      "Epoch 2 | Iter1 | Loss2.6568 | TrainAcc0.3333 | Testacc 0.3000\n",
      "Epoch 2 | Iter3 | Loss2.5032 | TrainAcc0.3056 | Testacc 0.3000\n",
      "Epoch 2 | Iter5 | Loss2.4007 | TrainAcc0.3611 | Testacc 0.3000\n",
      "Epoch 2 | Iter7 | Loss2.5471 | TrainAcc0.2639 | Testacc 0.3400\n",
      "Epoch 2 | Iter9 | Loss2.4397 | TrainAcc0.3667 | Testacc 0.3600\n",
      "Epoch 3 | Iter1 | Loss2.4123 | TrainAcc0.4306 | Testacc 0.3400\n",
      "Epoch 3 | Iter3 | Loss2.3526 | TrainAcc0.3889 | Testacc 0.3200\n",
      "Epoch 3 | Iter5 | Loss2.2652 | TrainAcc0.4167 | Testacc 0.3000\n",
      "Epoch 3 | Iter7 | Loss2.2833 | TrainAcc0.4028 | Testacc 0.2800\n",
      "Epoch 3 | Iter9 | Loss2.1999 | TrainAcc0.4167 | Testacc 0.2800\n",
      "Epoch 4 | Iter1 | Loss2.3548 | TrainAcc0.4444 | Testacc 0.2800\n",
      "Epoch 4 | Iter3 | Loss2.3922 | TrainAcc0.3194 | Testacc 0.2800\n",
      "Epoch 4 | Iter5 | Loss2.3084 | TrainAcc0.4028 | Testacc 0.2800\n",
      "Epoch 4 | Iter7 | Loss2.1753 | TrainAcc0.4444 | Testacc 0.2800\n",
      "Epoch 4 | Iter9 | Loss2.1337 | TrainAcc0.4667 | Testacc 0.3000\n",
      "Epoch 5 | Iter1 | Loss2.1791 | TrainAcc0.5000 | Testacc 0.3000\n",
      "Epoch 5 | Iter3 | Loss2.1823 | TrainAcc0.4444 | Testacc 0.3000\n",
      "Epoch 5 | Iter5 | Loss2.2430 | TrainAcc0.4583 | Testacc 0.3200\n",
      "Epoch 5 | Iter7 | Loss2.1214 | TrainAcc0.5000 | Testacc 0.3000\n",
      "Epoch 5 | Iter9 | Loss2.1190 | TrainAcc0.4833 | Testacc 0.3200\n",
      "Epoch 6 | Iter1 | Loss2.1552 | TrainAcc0.5278 | Testacc 0.3200\n",
      "Epoch 6 | Iter3 | Loss2.1002 | TrainAcc0.5139 | Testacc 0.3000\n",
      "Epoch 6 | Iter5 | Loss2.0693 | TrainAcc0.4444 | Testacc 0.3000\n",
      "Epoch 6 | Iter7 | Loss2.0218 | TrainAcc0.5972 | Testacc 0.3000\n",
      "Epoch 6 | Iter9 | Loss2.2217 | TrainAcc0.5000 | Testacc 0.3000\n",
      "Epoch 7 | Iter1 | Loss1.9570 | TrainAcc0.5556 | Testacc 0.2800\n",
      "Epoch 7 | Iter3 | Loss1.9840 | TrainAcc0.6111 | Testacc 0.3000\n",
      "Epoch 7 | Iter5 | Loss2.0761 | TrainAcc0.5139 | Testacc 0.3000\n",
      "Epoch 7 | Iter7 | Loss2.1372 | TrainAcc0.4722 | Testacc 0.3400\n",
      "Epoch 7 | Iter9 | Loss2.0888 | TrainAcc0.4500 | Testacc 0.3400\n",
      "Epoch 8 | Iter1 | Loss1.9851 | TrainAcc0.5833 | Testacc 0.3400\n",
      "Epoch 8 | Iter3 | Loss2.0002 | TrainAcc0.5278 | Testacc 0.3600\n",
      "Epoch 8 | Iter5 | Loss1.9231 | TrainAcc0.6667 | Testacc 0.3400\n",
      "Epoch 8 | Iter7 | Loss1.9272 | TrainAcc0.6389 | Testacc 0.3800\n",
      "Epoch 8 | Iter9 | Loss1.9662 | TrainAcc0.6333 | Testacc 0.4000\n",
      "Epoch 9 | Iter1 | Loss1.8833 | TrainAcc0.6806 | Testacc 0.4000\n",
      "Epoch 9 | Iter3 | Loss1.9161 | TrainAcc0.6528 | Testacc 0.4000\n",
      "Epoch 9 | Iter5 | Loss2.0214 | TrainAcc0.5833 | Testacc 0.4000\n",
      "Epoch 9 | Iter7 | Loss2.0172 | TrainAcc0.5139 | Testacc 0.4000\n",
      "Epoch 9 | Iter9 | Loss2.0418 | TrainAcc0.5667 | Testacc 0.4000\n",
      "Epoch 10 | Iter1 | Loss1.9078 | TrainAcc0.6389 | Testacc 0.4000\n",
      "Epoch 10 | Iter3 | Loss1.9613 | TrainAcc0.6111 | Testacc 0.4200\n",
      "Epoch 10 | Iter5 | Loss1.8385 | TrainAcc0.7500 | Testacc 0.4200\n",
      "Epoch 10 | Iter7 | Loss1.8979 | TrainAcc0.6111 | Testacc 0.4200\n",
      "Epoch 10 | Iter9 | Loss1.9256 | TrainAcc0.6333 | Testacc 0.4200\n",
      "Epoch 11 | Iter1 | Loss1.7991 | TrainAcc0.7083 | Testacc 0.4200\n",
      "Epoch 11 | Iter3 | Loss1.8188 | TrainAcc0.6806 | Testacc 0.4200\n",
      "Epoch 11 | Iter5 | Loss1.7780 | TrainAcc0.6389 | Testacc 0.4000\n",
      "Epoch 11 | Iter7 | Loss1.8592 | TrainAcc0.6667 | Testacc 0.4000\n",
      "Epoch 11 | Iter9 | Loss1.8629 | TrainAcc0.6167 | Testacc 0.4400\n",
      "Epoch 12 | Iter1 | Loss1.8446 | TrainAcc0.6389 | Testacc 0.4400\n",
      "Epoch 12 | Iter3 | Loss1.8768 | TrainAcc0.6389 | Testacc 0.4400\n",
      "Epoch 12 | Iter5 | Loss1.8102 | TrainAcc0.6944 | Testacc 0.4400\n",
      "Epoch 12 | Iter7 | Loss1.7489 | TrainAcc0.7639 | Testacc 0.4200\n",
      "Epoch 12 | Iter9 | Loss1.8426 | TrainAcc0.6500 | Testacc 0.4000\n",
      "Epoch 13 | Iter1 | Loss1.7788 | TrainAcc0.7361 | Testacc 0.4200\n",
      "Epoch 13 | Iter3 | Loss1.6705 | TrainAcc0.7222 | Testacc 0.4000\n",
      "Epoch 13 | Iter5 | Loss1.8478 | TrainAcc0.6806 | Testacc 0.4000\n",
      "Epoch 13 | Iter7 | Loss1.7918 | TrainAcc0.6667 | Testacc 0.4200\n",
      "Epoch 13 | Iter9 | Loss1.8119 | TrainAcc0.6333 | Testacc 0.4400\n",
      "Epoch 14 | Iter1 | Loss1.6772 | TrainAcc0.7917 | Testacc 0.4000\n",
      "Epoch 14 | Iter3 | Loss1.7423 | TrainAcc0.7361 | Testacc 0.4000\n",
      "Epoch 14 | Iter5 | Loss1.6196 | TrainAcc0.8333 | Testacc 0.4000\n",
      "Epoch 14 | Iter7 | Loss1.7444 | TrainAcc0.7361 | Testacc 0.4200\n",
      "Epoch 14 | Iter9 | Loss1.6987 | TrainAcc0.7000 | Testacc 0.4600\n",
      "Epoch 15 | Iter1 | Loss1.6809 | TrainAcc0.7222 | Testacc 0.4400\n",
      "Epoch 15 | Iter3 | Loss1.6183 | TrainAcc0.8194 | Testacc 0.4600\n",
      "Epoch 15 | Iter5 | Loss1.6884 | TrainAcc0.7500 | Testacc 0.4400\n",
      "Epoch 15 | Iter7 | Loss1.6432 | TrainAcc0.8056 | Testacc 0.4400\n",
      "Epoch 15 | Iter9 | Loss1.7060 | TrainAcc0.8167 | Testacc 0.4600\n",
      "Epoch 16 | Iter1 | Loss1.6048 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 16 | Iter3 | Loss1.6583 | TrainAcc0.7639 | Testacc 0.5200\n",
      "Epoch 16 | Iter5 | Loss1.5676 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 16 | Iter7 | Loss1.5960 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 16 | Iter9 | Loss1.6327 | TrainAcc0.7833 | Testacc 0.4600\n",
      "Epoch 17 | Iter1 | Loss1.5606 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 17 | Iter3 | Loss1.5570 | TrainAcc0.8056 | Testacc 0.4600\n",
      "Epoch 17 | Iter5 | Loss1.4752 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 17 | Iter7 | Loss1.6759 | TrainAcc0.7500 | Testacc 0.4800\n",
      "Epoch 17 | Iter9 | Loss1.6947 | TrainAcc0.7333 | Testacc 0.5200\n",
      "Epoch 18 | Iter1 | Loss1.6435 | TrainAcc0.7917 | Testacc 0.5400\n",
      "Epoch 18 | Iter3 | Loss1.5635 | TrainAcc0.7778 | Testacc 0.5600\n",
      "Epoch 18 | Iter5 | Loss1.6378 | TrainAcc0.7917 | Testacc 0.5400\n",
      "Epoch 18 | Iter7 | Loss1.5386 | TrainAcc0.8611 | Testacc 0.5400\n",
      "Epoch 18 | Iter9 | Loss1.6025 | TrainAcc0.8167 | Testacc 0.5200\n",
      "Epoch 19 | Iter1 | Loss1.5503 | TrainAcc0.8056 | Testacc 0.5000\n",
      "Epoch 19 | Iter3 | Loss1.5312 | TrainAcc0.8750 | Testacc 0.5400\n",
      "Epoch 19 | Iter5 | Loss1.4935 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 19 | Iter7 | Loss1.4494 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 19 | Iter9 | Loss1.5592 | TrainAcc0.7667 | Testacc 0.5400\n",
      "Epoch 20 | Iter1 | Loss1.4329 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 20 | Iter3 | Loss1.5035 | TrainAcc0.8889 | Testacc 0.5400\n",
      "Epoch 20 | Iter5 | Loss1.4866 | TrainAcc0.8194 | Testacc 0.5600\n",
      "Epoch 20 | Iter7 | Loss1.4839 | TrainAcc0.8333 | Testacc 0.5400\n",
      "Epoch 20 | Iter9 | Loss1.4411 | TrainAcc0.8833 | Testacc 0.5400\n",
      "Epoch 21 | Iter1 | Loss1.4583 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 21 | Iter3 | Loss1.4846 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 21 | Iter5 | Loss1.4937 | TrainAcc0.8194 | Testacc 0.5400\n",
      "Epoch 21 | Iter7 | Loss1.4436 | TrainAcc0.8889 | Testacc 0.5600\n",
      "Epoch 21 | Iter9 | Loss1.4066 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 22 | Iter1 | Loss1.4757 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 22 | Iter3 | Loss1.4028 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 22 | Iter5 | Loss1.4972 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 22 | Iter7 | Loss1.4606 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 22 | Iter9 | Loss1.4549 | TrainAcc0.8667 | Testacc 0.5000\n",
      "Epoch 23 | Iter1 | Loss1.4761 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 23 | Iter3 | Loss1.4797 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 23 | Iter5 | Loss1.4209 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 23 | Iter7 | Loss1.3797 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 23 | Iter9 | Loss1.4091 | TrainAcc0.8667 | Testacc 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Iter1 | Loss1.3384 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 24 | Iter3 | Loss1.3967 | TrainAcc0.8611 | Testacc 0.5600\n",
      "Epoch 24 | Iter5 | Loss1.4101 | TrainAcc0.8750 | Testacc 0.5400\n",
      "Epoch 24 | Iter7 | Loss1.4217 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 24 | Iter9 | Loss1.4346 | TrainAcc0.8833 | Testacc 0.5800\n",
      "Epoch 25 | Iter1 | Loss1.4520 | TrainAcc0.8611 | Testacc 0.6000\n",
      "Epoch 25 | Iter3 | Loss1.3761 | TrainAcc0.9306 | Testacc 0.5800\n",
      "Epoch 25 | Iter5 | Loss1.4788 | TrainAcc0.8333 | Testacc 0.5800\n",
      "Epoch 25 | Iter7 | Loss1.4218 | TrainAcc0.8750 | Testacc 0.6000\n",
      "Epoch 25 | Iter9 | Loss1.2835 | TrainAcc0.9333 | Testacc 0.6000\n",
      "Epoch 26 | Iter1 | Loss1.3330 | TrainAcc0.9167 | Testacc 0.5800\n",
      "Epoch 26 | Iter3 | Loss1.4271 | TrainAcc0.8611 | Testacc 0.5800\n",
      "Epoch 26 | Iter5 | Loss1.4135 | TrainAcc0.9028 | Testacc 0.5800\n",
      "Epoch 26 | Iter7 | Loss1.2884 | TrainAcc0.9583 | Testacc 0.5600\n",
      "Epoch 26 | Iter9 | Loss1.3337 | TrainAcc0.9667 | Testacc 0.5600\n",
      "Epoch 27 | Iter1 | Loss1.3094 | TrainAcc0.9028 | Testacc 0.5800\n",
      "Epoch 27 | Iter3 | Loss1.3322 | TrainAcc0.9722 | Testacc 0.5800\n",
      "Epoch 27 | Iter5 | Loss1.4000 | TrainAcc0.8472 | Testacc 0.5600\n",
      "Epoch 27 | Iter7 | Loss1.3865 | TrainAcc0.9167 | Testacc 0.5800\n",
      "Epoch 27 | Iter9 | Loss1.3740 | TrainAcc0.9333 | Testacc 0.5600\n",
      "Epoch 28 | Iter1 | Loss1.3725 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 28 | Iter3 | Loss1.3436 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 28 | Iter5 | Loss1.3468 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 28 | Iter7 | Loss1.3292 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 28 | Iter9 | Loss1.3369 | TrainAcc1.0000 | Testacc 0.5200\n",
      "Epoch 29 | Iter1 | Loss1.3279 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 29 | Iter3 | Loss1.2783 | TrainAcc0.9583 | Testacc 0.5600\n",
      "Epoch 29 | Iter5 | Loss1.3006 | TrainAcc0.9028 | Testacc 0.5600\n",
      "Epoch 29 | Iter7 | Loss1.2197 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 29 | Iter9 | Loss1.2867 | TrainAcc0.9000 | Testacc 0.5600\n",
      "Epoch 30 | Iter1 | Loss1.2503 | TrainAcc0.9583 | Testacc 0.5800\n",
      "Epoch 30 | Iter3 | Loss1.3625 | TrainAcc0.9028 | Testacc 0.5800\n",
      "Epoch 30 | Iter5 | Loss1.3106 | TrainAcc0.9167 | Testacc 0.5800\n",
      "Epoch 30 | Iter7 | Loss1.3689 | TrainAcc0.9306 | Testacc 0.6000\n",
      "Epoch 30 | Iter9 | Loss1.3408 | TrainAcc0.9000 | Testacc 0.5800\n",
      "Epoch 31 | Iter1 | Loss1.3459 | TrainAcc0.8889 | Testacc 0.5800\n",
      "Epoch 31 | Iter3 | Loss1.3255 | TrainAcc0.9167 | Testacc 0.5800\n",
      "Epoch 31 | Iter5 | Loss1.2720 | TrainAcc0.9167 | Testacc 0.6000\n",
      "Epoch 31 | Iter7 | Loss1.2110 | TrainAcc0.9444 | Testacc 0.6000\n",
      "Epoch 31 | Iter9 | Loss1.2045 | TrainAcc0.9333 | Testacc 0.6200\n",
      "Epoch 32 | Iter1 | Loss1.2798 | TrainAcc0.9028 | Testacc 0.6200\n",
      "Epoch 32 | Iter3 | Loss1.3507 | TrainAcc0.9167 | Testacc 0.6200\n",
      "Epoch 32 | Iter5 | Loss1.3251 | TrainAcc0.8889 | Testacc 0.6200\n",
      "Epoch 32 | Iter7 | Loss1.3475 | TrainAcc0.9167 | Testacc 0.6000\n",
      "Epoch 32 | Iter9 | Loss1.3384 | TrainAcc0.9000 | Testacc 0.5800\n",
      "Epoch 33 | Iter1 | Loss1.3097 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 33 | Iter3 | Loss1.3870 | TrainAcc0.8472 | Testacc 0.5600\n",
      "Epoch 33 | Iter5 | Loss1.2441 | TrainAcc0.9722 | Testacc 0.5600\n",
      "Epoch 33 | Iter7 | Loss1.3389 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 33 | Iter9 | Loss1.2572 | TrainAcc0.9000 | Testacc 0.5400\n",
      "Epoch 34 | Iter1 | Loss1.3416 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 34 | Iter3 | Loss1.1798 | TrainAcc0.9722 | Testacc 0.5600\n",
      "Epoch 34 | Iter5 | Loss1.3207 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 34 | Iter7 | Loss1.2482 | TrainAcc0.8889 | Testacc 0.6200\n",
      "Epoch 34 | Iter9 | Loss1.3544 | TrainAcc0.8667 | Testacc 0.6000\n",
      "Epoch 35 | Iter1 | Loss1.2544 | TrainAcc0.9167 | Testacc 0.6200\n",
      "Epoch 35 | Iter3 | Loss1.2629 | TrainAcc0.9306 | Testacc 0.6000\n",
      "Epoch 35 | Iter5 | Loss1.3269 | TrainAcc0.8889 | Testacc 0.6000\n",
      "Epoch 35 | Iter7 | Loss1.2377 | TrainAcc0.9583 | Testacc 0.6000\n",
      "Epoch 35 | Iter9 | Loss1.2972 | TrainAcc0.9000 | Testacc 0.6200\n",
      "Test accuracy of model 4:  0.62\n",
      "--------------------------------------------------\n",
      "Training Net 5\n",
      "Epoch 1 | Iter1 | Loss2.6399 | TrainAcc0.2778 | Testacc 0.3200\n",
      "Epoch 1 | Iter3 | Loss2.5537 | TrainAcc0.2917 | Testacc 0.3600\n",
      "Epoch 1 | Iter5 | Loss2.7908 | TrainAcc0.2639 | Testacc 0.3600\n",
      "Epoch 1 | Iter7 | Loss2.4124 | TrainAcc0.3194 | Testacc 0.3200\n",
      "Epoch 1 | Iter9 | Loss2.3458 | TrainAcc0.3833 | Testacc 0.3600\n",
      "Epoch 2 | Iter1 | Loss2.4141 | TrainAcc0.3750 | Testacc 0.3600\n",
      "Epoch 2 | Iter3 | Loss2.4687 | TrainAcc0.2778 | Testacc 0.3800\n",
      "Epoch 2 | Iter5 | Loss2.5956 | TrainAcc0.3194 | Testacc 0.4000\n",
      "Epoch 2 | Iter7 | Loss2.2179 | TrainAcc0.4583 | Testacc 0.3800\n",
      "Epoch 2 | Iter9 | Loss2.3444 | TrainAcc0.3333 | Testacc 0.4000\n",
      "Epoch 3 | Iter1 | Loss2.3366 | TrainAcc0.3750 | Testacc 0.3800\n",
      "Epoch 3 | Iter3 | Loss2.3314 | TrainAcc0.4444 | Testacc 0.3800\n",
      "Epoch 3 | Iter5 | Loss2.4294 | TrainAcc0.3750 | Testacc 0.4000\n",
      "Epoch 3 | Iter7 | Loss2.2608 | TrainAcc0.3611 | Testacc 0.3600\n",
      "Epoch 3 | Iter9 | Loss2.2548 | TrainAcc0.4167 | Testacc 0.3600\n",
      "Epoch 4 | Iter1 | Loss2.1267 | TrainAcc0.5278 | Testacc 0.3600\n",
      "Epoch 4 | Iter3 | Loss2.1446 | TrainAcc0.5278 | Testacc 0.3800\n",
      "Epoch 4 | Iter5 | Loss2.0929 | TrainAcc0.5833 | Testacc 0.3800\n",
      "Epoch 4 | Iter7 | Loss2.1411 | TrainAcc0.5417 | Testacc 0.4000\n",
      "Epoch 4 | Iter9 | Loss2.1217 | TrainAcc0.4833 | Testacc 0.4200\n",
      "Epoch 5 | Iter1 | Loss2.1379 | TrainAcc0.4722 | Testacc 0.4000\n",
      "Epoch 5 | Iter3 | Loss2.1733 | TrainAcc0.4167 | Testacc 0.4000\n",
      "Epoch 5 | Iter5 | Loss2.1808 | TrainAcc0.4167 | Testacc 0.4000\n",
      "Epoch 5 | Iter7 | Loss2.0789 | TrainAcc0.4583 | Testacc 0.4200\n",
      "Epoch 5 | Iter9 | Loss2.1535 | TrainAcc0.4167 | Testacc 0.4200\n",
      "Epoch 6 | Iter1 | Loss2.1816 | TrainAcc0.4028 | Testacc 0.4600\n",
      "Epoch 6 | Iter3 | Loss2.0303 | TrainAcc0.5417 | Testacc 0.4600\n",
      "Epoch 6 | Iter5 | Loss2.0896 | TrainAcc0.5278 | Testacc 0.4600\n",
      "Epoch 6 | Iter7 | Loss1.9533 | TrainAcc0.5833 | Testacc 0.4400\n",
      "Epoch 6 | Iter9 | Loss1.9751 | TrainAcc0.5333 | Testacc 0.4400\n",
      "Epoch 7 | Iter1 | Loss1.9185 | TrainAcc0.5833 | Testacc 0.4400\n",
      "Epoch 7 | Iter3 | Loss1.9363 | TrainAcc0.6111 | Testacc 0.4400\n",
      "Epoch 7 | Iter5 | Loss1.8315 | TrainAcc0.7083 | Testacc 0.4400\n",
      "Epoch 7 | Iter7 | Loss1.8939 | TrainAcc0.5972 | Testacc 0.4400\n",
      "Epoch 7 | Iter9 | Loss2.0923 | TrainAcc0.4833 | Testacc 0.4400\n",
      "Epoch 8 | Iter1 | Loss1.9070 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 8 | Iter3 | Loss1.8318 | TrainAcc0.7083 | Testacc 0.4600\n",
      "Epoch 8 | Iter5 | Loss1.8118 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 8 | Iter7 | Loss1.8371 | TrainAcc0.6667 | Testacc 0.4600\n",
      "Epoch 8 | Iter9 | Loss1.9644 | TrainAcc0.6333 | Testacc 0.4400\n",
      "Epoch 9 | Iter1 | Loss1.9700 | TrainAcc0.6111 | Testacc 0.4400\n",
      "Epoch 9 | Iter3 | Loss1.9712 | TrainAcc0.5972 | Testacc 0.4400\n",
      "Epoch 9 | Iter5 | Loss1.8087 | TrainAcc0.6944 | Testacc 0.4600\n",
      "Epoch 9 | Iter7 | Loss1.8565 | TrainAcc0.6250 | Testacc 0.4600\n",
      "Epoch 9 | Iter9 | Loss1.8152 | TrainAcc0.6667 | Testacc 0.4600\n",
      "Epoch 10 | Iter1 | Loss1.7603 | TrainAcc0.7778 | Testacc 0.4800\n",
      "Epoch 10 | Iter3 | Loss1.8255 | TrainAcc0.7222 | Testacc 0.4800\n",
      "Epoch 10 | Iter5 | Loss1.8867 | TrainAcc0.6944 | Testacc 0.4600\n",
      "Epoch 10 | Iter7 | Loss1.6770 | TrainAcc0.6944 | Testacc 0.4800\n",
      "Epoch 10 | Iter9 | Loss1.7672 | TrainAcc0.7000 | Testacc 0.5000\n",
      "Epoch 11 | Iter1 | Loss1.8240 | TrainAcc0.7222 | Testacc 0.4800\n",
      "Epoch 11 | Iter3 | Loss1.7657 | TrainAcc0.7639 | Testacc 0.5000\n",
      "Epoch 11 | Iter5 | Loss1.7089 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 11 | Iter7 | Loss1.7835 | TrainAcc0.7222 | Testacc 0.5000\n",
      "Epoch 11 | Iter9 | Loss1.7789 | TrainAcc0.6667 | Testacc 0.5000\n",
      "Epoch 12 | Iter1 | Loss1.6809 | TrainAcc0.7778 | Testacc 0.5000\n",
      "Epoch 12 | Iter3 | Loss1.6339 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 12 | Iter5 | Loss1.6360 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 12 | Iter7 | Loss1.6469 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 12 | Iter9 | Loss1.6997 | TrainAcc0.8167 | Testacc 0.5000\n",
      "Epoch 13 | Iter1 | Loss1.6506 | TrainAcc0.7917 | Testacc 0.5200\n",
      "Epoch 13 | Iter3 | Loss1.5683 | TrainAcc0.8194 | Testacc 0.5200\n",
      "Epoch 13 | Iter5 | Loss1.5801 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 13 | Iter7 | Loss1.5283 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 13 | Iter9 | Loss1.6356 | TrainAcc0.7667 | Testacc 0.5000\n",
      "Epoch 14 | Iter1 | Loss1.6443 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 14 | Iter3 | Loss1.7092 | TrainAcc0.7222 | Testacc 0.5200\n",
      "Epoch 14 | Iter5 | Loss1.6085 | TrainAcc0.7778 | Testacc 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Iter7 | Loss1.5454 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 14 | Iter9 | Loss1.6536 | TrainAcc0.7667 | Testacc 0.4800\n",
      "Epoch 15 | Iter1 | Loss1.6235 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 15 | Iter3 | Loss1.5995 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 15 | Iter5 | Loss1.5885 | TrainAcc0.8194 | Testacc 0.4600\n",
      "Epoch 15 | Iter7 | Loss1.6076 | TrainAcc0.8194 | Testacc 0.4600\n",
      "Epoch 15 | Iter9 | Loss1.5447 | TrainAcc0.8167 | Testacc 0.4800\n",
      "Epoch 16 | Iter1 | Loss1.6140 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 16 | Iter3 | Loss1.4820 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 16 | Iter5 | Loss1.5039 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 16 | Iter7 | Loss1.6286 | TrainAcc0.7778 | Testacc 0.4600\n",
      "Epoch 16 | Iter9 | Loss1.6397 | TrainAcc0.8000 | Testacc 0.5000\n",
      "Epoch 17 | Iter1 | Loss1.6131 | TrainAcc0.7917 | Testacc 0.4600\n",
      "Epoch 17 | Iter3 | Loss1.4830 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 17 | Iter5 | Loss1.4738 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 17 | Iter7 | Loss1.6296 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 17 | Iter9 | Loss1.6595 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 18 | Iter1 | Loss1.5300 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 18 | Iter3 | Loss1.4961 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 18 | Iter5 | Loss1.5497 | TrainAcc0.7361 | Testacc 0.5200\n",
      "Epoch 18 | Iter7 | Loss1.5312 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 18 | Iter9 | Loss1.4034 | TrainAcc0.9000 | Testacc 0.4800\n",
      "Epoch 19 | Iter1 | Loss1.4348 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 19 | Iter3 | Loss1.3625 | TrainAcc0.9444 | Testacc 0.4800\n",
      "Epoch 19 | Iter5 | Loss1.5129 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 19 | Iter7 | Loss1.4369 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 19 | Iter9 | Loss1.3810 | TrainAcc0.9000 | Testacc 0.5000\n",
      "Epoch 20 | Iter1 | Loss1.4675 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 20 | Iter3 | Loss1.3781 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 20 | Iter5 | Loss1.4991 | TrainAcc0.8056 | Testacc 0.5000\n",
      "Epoch 20 | Iter7 | Loss1.5113 | TrainAcc0.7917 | Testacc 0.5000\n",
      "Epoch 20 | Iter9 | Loss1.4544 | TrainAcc0.9000 | Testacc 0.5000\n",
      "Epoch 21 | Iter1 | Loss1.4951 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 21 | Iter3 | Loss1.4822 | TrainAcc0.8611 | Testacc 0.4800\n",
      "Epoch 21 | Iter5 | Loss1.3843 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 21 | Iter7 | Loss1.4515 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 21 | Iter9 | Loss1.3509 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 22 | Iter1 | Loss1.4424 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 22 | Iter3 | Loss1.4357 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 22 | Iter5 | Loss1.4624 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 22 | Iter7 | Loss1.3429 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 22 | Iter9 | Loss1.3384 | TrainAcc0.9500 | Testacc 0.5200\n",
      "Epoch 23 | Iter1 | Loss1.4464 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 23 | Iter3 | Loss1.4077 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 23 | Iter5 | Loss1.3804 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 23 | Iter7 | Loss1.3768 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 23 | Iter9 | Loss1.3356 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 24 | Iter1 | Loss1.3271 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 24 | Iter3 | Loss1.3782 | TrainAcc0.8889 | Testacc 0.5200\n",
      "Epoch 24 | Iter5 | Loss1.4347 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 24 | Iter7 | Loss1.3259 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 24 | Iter9 | Loss1.4870 | TrainAcc0.8667 | Testacc 0.5000\n",
      "Epoch 25 | Iter1 | Loss1.3369 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 25 | Iter3 | Loss1.3154 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 25 | Iter5 | Loss1.3130 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 25 | Iter7 | Loss1.3363 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 25 | Iter9 | Loss1.3488 | TrainAcc0.8833 | Testacc 0.5000\n",
      "Epoch 26 | Iter1 | Loss1.3148 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 26 | Iter3 | Loss1.3547 | TrainAcc0.9306 | Testacc 0.5000\n",
      "Epoch 26 | Iter5 | Loss1.3343 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 26 | Iter7 | Loss1.3768 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 26 | Iter9 | Loss1.3109 | TrainAcc0.9333 | Testacc 0.5000\n",
      "Epoch 27 | Iter1 | Loss1.3041 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 27 | Iter3 | Loss1.2836 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 27 | Iter5 | Loss1.3631 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 27 | Iter7 | Loss1.2793 | TrainAcc0.9583 | Testacc 0.5200\n",
      "Epoch 27 | Iter9 | Loss1.2576 | TrainAcc0.9500 | Testacc 0.5400\n",
      "Epoch 28 | Iter1 | Loss1.3190 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 28 | Iter3 | Loss1.3259 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 28 | Iter5 | Loss1.2048 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 28 | Iter7 | Loss1.3638 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 28 | Iter9 | Loss1.3708 | TrainAcc0.8500 | Testacc 0.5400\n",
      "Epoch 29 | Iter1 | Loss1.2455 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 29 | Iter3 | Loss1.3242 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 29 | Iter5 | Loss1.3447 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 29 | Iter7 | Loss1.3286 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 29 | Iter9 | Loss1.2978 | TrainAcc0.9500 | Testacc 0.5200\n",
      "Epoch 30 | Iter1 | Loss1.3007 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 30 | Iter3 | Loss1.2231 | TrainAcc0.9861 | Testacc 0.5000\n",
      "Epoch 30 | Iter5 | Loss1.3787 | TrainAcc0.8750 | Testacc 0.5200\n",
      "Epoch 30 | Iter7 | Loss1.2450 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 30 | Iter9 | Loss1.2083 | TrainAcc0.9667 | Testacc 0.5000\n",
      "Epoch 31 | Iter1 | Loss1.2856 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 31 | Iter3 | Loss1.2793 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 31 | Iter5 | Loss1.3327 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 31 | Iter7 | Loss1.2648 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 31 | Iter9 | Loss1.3307 | TrainAcc0.8667 | Testacc 0.5000\n",
      "Epoch 32 | Iter1 | Loss1.2554 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 32 | Iter3 | Loss1.2185 | TrainAcc0.9444 | Testacc 0.5000\n",
      "Epoch 32 | Iter5 | Loss1.2990 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 32 | Iter7 | Loss1.2184 | TrainAcc0.9583 | Testacc 0.5000\n",
      "Epoch 32 | Iter9 | Loss1.2778 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 33 | Iter1 | Loss1.2648 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 33 | Iter3 | Loss1.2109 | TrainAcc0.9861 | Testacc 0.5000\n",
      "Epoch 33 | Iter5 | Loss1.3112 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 33 | Iter7 | Loss1.3138 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 33 | Iter9 | Loss1.2229 | TrainAcc0.9500 | Testacc 0.5200\n",
      "Epoch 34 | Iter1 | Loss1.2440 | TrainAcc0.9306 | Testacc 0.5400\n",
      "Epoch 34 | Iter3 | Loss1.2032 | TrainAcc0.9444 | Testacc 0.5200\n",
      "Epoch 34 | Iter5 | Loss1.2909 | TrainAcc0.9583 | Testacc 0.5400\n",
      "Epoch 34 | Iter7 | Loss1.2807 | TrainAcc0.9583 | Testacc 0.5400\n",
      "Epoch 34 | Iter9 | Loss1.2127 | TrainAcc0.9500 | Testacc 0.5200\n",
      "Epoch 35 | Iter1 | Loss1.2512 | TrainAcc0.9861 | Testacc 0.5200\n",
      "Epoch 35 | Iter3 | Loss1.3197 | TrainAcc0.8472 | Testacc 0.5400\n",
      "Epoch 35 | Iter5 | Loss1.2244 | TrainAcc0.9722 | Testacc 0.5200\n",
      "Epoch 35 | Iter7 | Loss1.2532 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 35 | Iter9 | Loss1.1853 | TrainAcc0.9833 | Testacc 0.5200\n",
      "Test accuracy of model 5:  0.52\n",
      "--------------------------------------------------\n",
      "Training Net 6\n",
      "Epoch 1 | Iter1 | Loss2.8254 | TrainAcc0.2083 | Testacc 0.2600\n",
      "Epoch 1 | Iter3 | Loss2.8422 | TrainAcc0.0833 | Testacc 0.2600\n",
      "Epoch 1 | Iter5 | Loss2.7705 | TrainAcc0.2083 | Testacc 0.2600\n",
      "Epoch 1 | Iter7 | Loss2.6637 | TrainAcc0.2500 | Testacc 0.3000\n",
      "Epoch 1 | Iter9 | Loss2.5215 | TrainAcc0.3000 | Testacc 0.3000\n",
      "Epoch 2 | Iter1 | Loss2.4397 | TrainAcc0.3333 | Testacc 0.3000\n",
      "Epoch 2 | Iter3 | Loss2.4894 | TrainAcc0.3056 | Testacc 0.3000\n",
      "Epoch 2 | Iter5 | Loss2.3875 | TrainAcc0.3889 | Testacc 0.3000\n",
      "Epoch 2 | Iter7 | Loss2.5872 | TrainAcc0.3056 | Testacc 0.3000\n",
      "Epoch 2 | Iter9 | Loss2.6252 | TrainAcc0.3500 | Testacc 0.2800\n",
      "Epoch 3 | Iter1 | Loss2.2959 | TrainAcc0.4028 | Testacc 0.3400\n",
      "Epoch 3 | Iter3 | Loss2.3620 | TrainAcc0.3611 | Testacc 0.3400\n",
      "Epoch 3 | Iter5 | Loss2.5102 | TrainAcc0.2778 | Testacc 0.3200\n",
      "Epoch 3 | Iter7 | Loss2.6035 | TrainAcc0.2917 | Testacc 0.3400\n",
      "Epoch 3 | Iter9 | Loss2.1942 | TrainAcc0.4500 | Testacc 0.3400\n",
      "Epoch 4 | Iter1 | Loss2.2368 | TrainAcc0.3750 | Testacc 0.3400\n",
      "Epoch 4 | Iter3 | Loss2.1967 | TrainAcc0.4722 | Testacc 0.3800\n",
      "Epoch 4 | Iter5 | Loss2.2306 | TrainAcc0.5000 | Testacc 0.3800\n",
      "Epoch 4 | Iter7 | Loss2.1350 | TrainAcc0.4444 | Testacc 0.4200\n",
      "Epoch 4 | Iter9 | Loss2.0779 | TrainAcc0.5333 | Testacc 0.4200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Iter1 | Loss2.1423 | TrainAcc0.4861 | Testacc 0.4400\n",
      "Epoch 5 | Iter3 | Loss2.2335 | TrainAcc0.4583 | Testacc 0.4600\n",
      "Epoch 5 | Iter5 | Loss2.2119 | TrainAcc0.5000 | Testacc 0.4600\n",
      "Epoch 5 | Iter7 | Loss2.1209 | TrainAcc0.4722 | Testacc 0.5000\n",
      "Epoch 5 | Iter9 | Loss2.1581 | TrainAcc0.4667 | Testacc 0.5400\n",
      "Epoch 6 | Iter1 | Loss2.0749 | TrainAcc0.5694 | Testacc 0.5400\n",
      "Epoch 6 | Iter3 | Loss2.0458 | TrainAcc0.5556 | Testacc 0.5000\n",
      "Epoch 6 | Iter5 | Loss2.1461 | TrainAcc0.4583 | Testacc 0.5000\n",
      "Epoch 6 | Iter7 | Loss2.0173 | TrainAcc0.5556 | Testacc 0.5200\n",
      "Epoch 6 | Iter9 | Loss2.1639 | TrainAcc0.4500 | Testacc 0.4800\n",
      "Epoch 7 | Iter1 | Loss2.0863 | TrainAcc0.5139 | Testacc 0.4800\n",
      "Epoch 7 | Iter3 | Loss2.0394 | TrainAcc0.5694 | Testacc 0.4600\n",
      "Epoch 7 | Iter5 | Loss1.9826 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 7 | Iter7 | Loss1.9661 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 7 | Iter9 | Loss1.9807 | TrainAcc0.6167 | Testacc 0.5000\n",
      "Epoch 8 | Iter1 | Loss1.9802 | TrainAcc0.5972 | Testacc 0.5000\n",
      "Epoch 8 | Iter3 | Loss2.0202 | TrainAcc0.5556 | Testacc 0.5000\n",
      "Epoch 8 | Iter5 | Loss1.9023 | TrainAcc0.6111 | Testacc 0.4800\n",
      "Epoch 8 | Iter7 | Loss1.9846 | TrainAcc0.5556 | Testacc 0.4600\n",
      "Epoch 8 | Iter9 | Loss1.8788 | TrainAcc0.6167 | Testacc 0.4600\n",
      "Epoch 9 | Iter1 | Loss1.9301 | TrainAcc0.5833 | Testacc 0.5000\n",
      "Epoch 9 | Iter3 | Loss1.9141 | TrainAcc0.6389 | Testacc 0.5200\n",
      "Epoch 9 | Iter5 | Loss1.8444 | TrainAcc0.6806 | Testacc 0.5200\n",
      "Epoch 9 | Iter7 | Loss1.9307 | TrainAcc0.6250 | Testacc 0.5000\n",
      "Epoch 9 | Iter9 | Loss1.9347 | TrainAcc0.6667 | Testacc 0.4800\n",
      "Epoch 10 | Iter1 | Loss1.8375 | TrainAcc0.6667 | Testacc 0.4800\n",
      "Epoch 10 | Iter3 | Loss1.8228 | TrainAcc0.6944 | Testacc 0.4800\n",
      "Epoch 10 | Iter5 | Loss1.7445 | TrainAcc0.7500 | Testacc 0.4800\n",
      "Epoch 10 | Iter7 | Loss1.8196 | TrainAcc0.6250 | Testacc 0.5000\n",
      "Epoch 10 | Iter9 | Loss1.9465 | TrainAcc0.5667 | Testacc 0.4800\n",
      "Epoch 11 | Iter1 | Loss1.8088 | TrainAcc0.6806 | Testacc 0.5000\n",
      "Epoch 11 | Iter3 | Loss1.7099 | TrainAcc0.7500 | Testacc 0.4600\n",
      "Epoch 11 | Iter5 | Loss1.7344 | TrainAcc0.7500 | Testacc 0.5000\n",
      "Epoch 11 | Iter7 | Loss1.6576 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 11 | Iter9 | Loss1.7247 | TrainAcc0.7000 | Testacc 0.4800\n",
      "Epoch 12 | Iter1 | Loss1.6830 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 12 | Iter3 | Loss1.7149 | TrainAcc0.8056 | Testacc 0.4600\n",
      "Epoch 12 | Iter5 | Loss1.7743 | TrainAcc0.7222 | Testacc 0.4800\n",
      "Epoch 12 | Iter7 | Loss1.7829 | TrainAcc0.6944 | Testacc 0.4600\n",
      "Epoch 12 | Iter9 | Loss1.7620 | TrainAcc0.6500 | Testacc 0.4800\n",
      "Epoch 13 | Iter1 | Loss1.7832 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 13 | Iter3 | Loss1.6070 | TrainAcc0.8333 | Testacc 0.5000\n",
      "Epoch 13 | Iter5 | Loss1.7069 | TrainAcc0.6944 | Testacc 0.5000\n",
      "Epoch 13 | Iter7 | Loss1.7082 | TrainAcc0.7778 | Testacc 0.5000\n",
      "Epoch 13 | Iter9 | Loss1.6155 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 14 | Iter1 | Loss1.6927 | TrainAcc0.7361 | Testacc 0.4800\n",
      "Epoch 14 | Iter3 | Loss1.7038 | TrainAcc0.7222 | Testacc 0.4800\n",
      "Epoch 14 | Iter5 | Loss1.6686 | TrainAcc0.8056 | Testacc 0.4600\n",
      "Epoch 14 | Iter7 | Loss1.7111 | TrainAcc0.7222 | Testacc 0.4600\n",
      "Epoch 14 | Iter9 | Loss1.6892 | TrainAcc0.6833 | Testacc 0.4800\n",
      "Epoch 15 | Iter1 | Loss1.6427 | TrainAcc0.7778 | Testacc 0.4600\n",
      "Epoch 15 | Iter3 | Loss1.5932 | TrainAcc0.8333 | Testacc 0.4600\n",
      "Epoch 15 | Iter5 | Loss1.6021 | TrainAcc0.7500 | Testacc 0.4400\n",
      "Epoch 15 | Iter7 | Loss1.5959 | TrainAcc0.8194 | Testacc 0.4800\n",
      "Epoch 15 | Iter9 | Loss1.7074 | TrainAcc0.6667 | Testacc 0.4800\n",
      "Epoch 16 | Iter1 | Loss1.6305 | TrainAcc0.8472 | Testacc 0.5000\n",
      "Epoch 16 | Iter3 | Loss1.5697 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 16 | Iter5 | Loss1.5891 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 16 | Iter7 | Loss1.6391 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 16 | Iter9 | Loss1.5696 | TrainAcc0.8333 | Testacc 0.4200\n",
      "Epoch 17 | Iter1 | Loss1.6207 | TrainAcc0.8194 | Testacc 0.5000\n",
      "Epoch 17 | Iter3 | Loss1.4971 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 17 | Iter5 | Loss1.5476 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 17 | Iter7 | Loss1.4286 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 17 | Iter9 | Loss1.5449 | TrainAcc0.8500 | Testacc 0.4400\n",
      "Epoch 18 | Iter1 | Loss1.5713 | TrainAcc0.8056 | Testacc 0.4200\n",
      "Epoch 18 | Iter3 | Loss1.4043 | TrainAcc0.8889 | Testacc 0.4400\n",
      "Epoch 18 | Iter5 | Loss1.5145 | TrainAcc0.8750 | Testacc 0.4400\n",
      "Epoch 18 | Iter7 | Loss1.5249 | TrainAcc0.8056 | Testacc 0.4400\n",
      "Epoch 18 | Iter9 | Loss1.4722 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 19 | Iter1 | Loss1.6162 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 19 | Iter3 | Loss1.4801 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 19 | Iter5 | Loss1.5202 | TrainAcc0.8472 | Testacc 0.4600\n",
      "Epoch 19 | Iter7 | Loss1.4665 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 19 | Iter9 | Loss1.5034 | TrainAcc0.8667 | Testacc 0.4800\n",
      "Epoch 20 | Iter1 | Loss1.4426 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 20 | Iter3 | Loss1.4780 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 20 | Iter5 | Loss1.4103 | TrainAcc0.8889 | Testacc 0.4600\n",
      "Epoch 20 | Iter7 | Loss1.4365 | TrainAcc0.9167 | Testacc 0.4400\n",
      "Epoch 20 | Iter9 | Loss1.5515 | TrainAcc0.8000 | Testacc 0.4400\n",
      "Epoch 21 | Iter1 | Loss1.4213 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 21 | Iter3 | Loss1.4026 | TrainAcc0.8889 | Testacc 0.4600\n",
      "Epoch 21 | Iter5 | Loss1.4130 | TrainAcc0.8889 | Testacc 0.4400\n",
      "Epoch 21 | Iter7 | Loss1.4091 | TrainAcc0.9306 | Testacc 0.4200\n",
      "Epoch 21 | Iter9 | Loss1.4048 | TrainAcc0.9000 | Testacc 0.4200\n",
      "Epoch 22 | Iter1 | Loss1.3724 | TrainAcc0.9028 | Testacc 0.4400\n",
      "Epoch 22 | Iter3 | Loss1.4418 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 22 | Iter5 | Loss1.4421 | TrainAcc0.8750 | Testacc 0.4400\n",
      "Epoch 22 | Iter7 | Loss1.3607 | TrainAcc0.8889 | Testacc 0.4400\n",
      "Epoch 22 | Iter9 | Loss1.3415 | TrainAcc0.9667 | Testacc 0.4400\n",
      "Epoch 23 | Iter1 | Loss1.3716 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 23 | Iter3 | Loss1.3689 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 23 | Iter5 | Loss1.3079 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 23 | Iter7 | Loss1.4246 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 23 | Iter9 | Loss1.4039 | TrainAcc0.8833 | Testacc 0.4600\n",
      "Epoch 24 | Iter1 | Loss1.4358 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 24 | Iter3 | Loss1.3881 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 24 | Iter5 | Loss1.3638 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 24 | Iter7 | Loss1.3440 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 24 | Iter9 | Loss1.3347 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 25 | Iter1 | Loss1.3338 | TrainAcc0.9444 | Testacc 0.4400\n",
      "Epoch 25 | Iter3 | Loss1.4451 | TrainAcc0.8611 | Testacc 0.4400\n",
      "Epoch 25 | Iter5 | Loss1.3598 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 25 | Iter7 | Loss1.4238 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 25 | Iter9 | Loss1.3554 | TrainAcc0.9667 | Testacc 0.4800\n",
      "Epoch 26 | Iter1 | Loss1.3336 | TrainAcc0.8889 | Testacc 0.4800\n",
      "Epoch 26 | Iter3 | Loss1.4666 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 26 | Iter5 | Loss1.3607 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 26 | Iter7 | Loss1.3392 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 26 | Iter9 | Loss1.4013 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 27 | Iter1 | Loss1.3242 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 27 | Iter3 | Loss1.3415 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 27 | Iter5 | Loss1.2257 | TrainAcc0.9722 | Testacc 0.4800\n",
      "Epoch 27 | Iter7 | Loss1.3425 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 27 | Iter9 | Loss1.2827 | TrainAcc0.9667 | Testacc 0.4600\n",
      "Epoch 28 | Iter1 | Loss1.4112 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 28 | Iter3 | Loss1.3269 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 28 | Iter5 | Loss1.2847 | TrainAcc0.9722 | Testacc 0.4600\n",
      "Epoch 28 | Iter7 | Loss1.3256 | TrainAcc0.9444 | Testacc 0.4600\n",
      "Epoch 28 | Iter9 | Loss1.3061 | TrainAcc0.9000 | Testacc 0.4800\n",
      "Epoch 29 | Iter1 | Loss1.3418 | TrainAcc0.9444 | Testacc 0.4600\n",
      "Epoch 29 | Iter3 | Loss1.3486 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 29 | Iter5 | Loss1.3315 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 29 | Iter7 | Loss1.3500 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 29 | Iter9 | Loss1.3169 | TrainAcc0.9500 | Testacc 0.5000\n",
      "Epoch 30 | Iter1 | Loss1.2691 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 30 | Iter3 | Loss1.4053 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 30 | Iter5 | Loss1.3185 | TrainAcc0.9167 | Testacc 0.4800\n",
      "Epoch 30 | Iter7 | Loss1.2448 | TrainAcc0.9167 | Testacc 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Iter9 | Loss1.3025 | TrainAcc0.9167 | Testacc 0.4400\n",
      "Epoch 31 | Iter1 | Loss1.3130 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 31 | Iter3 | Loss1.2824 | TrainAcc0.9583 | Testacc 0.4600\n",
      "Epoch 31 | Iter5 | Loss1.2750 | TrainAcc0.9167 | Testacc 0.4400\n",
      "Epoch 31 | Iter7 | Loss1.2395 | TrainAcc0.9583 | Testacc 0.4600\n",
      "Epoch 31 | Iter9 | Loss1.3021 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 32 | Iter1 | Loss1.2577 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 32 | Iter3 | Loss1.3567 | TrainAcc0.8611 | Testacc 0.4600\n",
      "Epoch 32 | Iter5 | Loss1.2552 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 32 | Iter7 | Loss1.2573 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 32 | Iter9 | Loss1.3356 | TrainAcc0.8833 | Testacc 0.4600\n",
      "Epoch 33 | Iter1 | Loss1.2353 | TrainAcc0.9722 | Testacc 0.4600\n",
      "Epoch 33 | Iter3 | Loss1.2171 | TrainAcc0.9583 | Testacc 0.4800\n",
      "Epoch 33 | Iter5 | Loss1.2671 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 33 | Iter7 | Loss1.3155 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 33 | Iter9 | Loss1.1588 | TrainAcc0.9667 | Testacc 0.4800\n",
      "Epoch 34 | Iter1 | Loss1.2379 | TrainAcc0.9444 | Testacc 0.4600\n",
      "Epoch 34 | Iter3 | Loss1.3391 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 34 | Iter5 | Loss1.3158 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 34 | Iter7 | Loss1.2753 | TrainAcc0.9306 | Testacc 0.4600\n",
      "Epoch 34 | Iter9 | Loss1.2388 | TrainAcc0.9833 | Testacc 0.4600\n",
      "Epoch 35 | Iter1 | Loss1.3353 | TrainAcc0.8750 | Testacc 0.4800\n",
      "Epoch 35 | Iter3 | Loss1.1906 | TrainAcc0.9861 | Testacc 0.4600\n",
      "Epoch 35 | Iter5 | Loss1.2051 | TrainAcc0.9722 | Testacc 0.4600\n",
      "Epoch 35 | Iter7 | Loss1.2560 | TrainAcc0.9306 | Testacc 0.4800\n",
      "Epoch 35 | Iter9 | Loss1.1843 | TrainAcc0.9833 | Testacc 0.4800\n",
      "Test accuracy of model 6:  0.48\n",
      "--------------------------------------------------\n",
      "Training Net 7\n",
      "Epoch 1 | Iter1 | Loss2.9169 | TrainAcc0.1944 | Testacc 0.2600\n",
      "Epoch 1 | Iter3 | Loss2.5339 | TrainAcc0.3333 | Testacc 0.2600\n",
      "Epoch 1 | Iter5 | Loss2.4873 | TrainAcc0.2778 | Testacc 0.2600\n",
      "Epoch 1 | Iter7 | Loss2.6412 | TrainAcc0.3194 | Testacc 0.2600\n",
      "Epoch 1 | Iter9 | Loss2.5301 | TrainAcc0.2667 | Testacc 0.2800\n",
      "Epoch 2 | Iter1 | Loss2.3865 | TrainAcc0.3194 | Testacc 0.2600\n",
      "Epoch 2 | Iter3 | Loss2.6969 | TrainAcc0.3750 | Testacc 0.2600\n",
      "Epoch 2 | Iter5 | Loss2.6686 | TrainAcc0.2083 | Testacc 0.2400\n",
      "Epoch 2 | Iter7 | Loss2.4549 | TrainAcc0.3333 | Testacc 0.3400\n",
      "Epoch 2 | Iter9 | Loss2.4744 | TrainAcc0.3167 | Testacc 0.3200\n",
      "Epoch 3 | Iter1 | Loss2.4750 | TrainAcc0.3472 | Testacc 0.3200\n",
      "Epoch 3 | Iter3 | Loss2.3603 | TrainAcc0.3472 | Testacc 0.3000\n",
      "Epoch 3 | Iter5 | Loss2.3002 | TrainAcc0.4028 | Testacc 0.2800\n",
      "Epoch 3 | Iter7 | Loss2.2831 | TrainAcc0.4444 | Testacc 0.2600\n",
      "Epoch 3 | Iter9 | Loss2.3199 | TrainAcc0.3667 | Testacc 0.2600\n",
      "Epoch 4 | Iter1 | Loss2.1974 | TrainAcc0.4167 | Testacc 0.3000\n",
      "Epoch 4 | Iter3 | Loss2.2287 | TrainAcc0.4167 | Testacc 0.3000\n",
      "Epoch 4 | Iter5 | Loss2.2021 | TrainAcc0.4583 | Testacc 0.3200\n",
      "Epoch 4 | Iter7 | Loss2.2661 | TrainAcc0.4306 | Testacc 0.3600\n",
      "Epoch 4 | Iter9 | Loss2.0687 | TrainAcc0.5667 | Testacc 0.3600\n",
      "Epoch 5 | Iter1 | Loss2.0830 | TrainAcc0.5000 | Testacc 0.3400\n",
      "Epoch 5 | Iter3 | Loss2.0485 | TrainAcc0.4861 | Testacc 0.3800\n",
      "Epoch 5 | Iter5 | Loss2.2044 | TrainAcc0.4583 | Testacc 0.3800\n",
      "Epoch 5 | Iter7 | Loss2.0618 | TrainAcc0.5417 | Testacc 0.3800\n",
      "Epoch 5 | Iter9 | Loss2.1248 | TrainAcc0.5000 | Testacc 0.4000\n",
      "Epoch 6 | Iter1 | Loss1.9907 | TrainAcc0.5972 | Testacc 0.4600\n",
      "Epoch 6 | Iter3 | Loss1.9870 | TrainAcc0.5972 | Testacc 0.4600\n",
      "Epoch 6 | Iter5 | Loss2.0886 | TrainAcc0.5556 | Testacc 0.4800\n",
      "Epoch 6 | Iter7 | Loss2.1232 | TrainAcc0.5000 | Testacc 0.4400\n",
      "Epoch 6 | Iter9 | Loss1.9509 | TrainAcc0.5667 | Testacc 0.4400\n",
      "Epoch 7 | Iter1 | Loss1.9122 | TrainAcc0.6806 | Testacc 0.4400\n",
      "Epoch 7 | Iter3 | Loss1.9045 | TrainAcc0.6528 | Testacc 0.4400\n",
      "Epoch 7 | Iter5 | Loss2.0960 | TrainAcc0.5417 | Testacc 0.4200\n",
      "Epoch 7 | Iter7 | Loss1.9802 | TrainAcc0.5556 | Testacc 0.4000\n",
      "Epoch 7 | Iter9 | Loss2.1038 | TrainAcc0.4667 | Testacc 0.4000\n",
      "Epoch 8 | Iter1 | Loss1.7999 | TrainAcc0.7500 | Testacc 0.4000\n",
      "Epoch 8 | Iter3 | Loss1.9674 | TrainAcc0.5417 | Testacc 0.4200\n",
      "Epoch 8 | Iter5 | Loss1.8345 | TrainAcc0.7083 | Testacc 0.4400\n",
      "Epoch 8 | Iter7 | Loss1.9918 | TrainAcc0.5694 | Testacc 0.4400\n",
      "Epoch 8 | Iter9 | Loss1.8114 | TrainAcc0.6500 | Testacc 0.4400\n",
      "Epoch 9 | Iter1 | Loss1.8950 | TrainAcc0.6667 | Testacc 0.4600\n",
      "Epoch 9 | Iter3 | Loss1.8047 | TrainAcc0.7778 | Testacc 0.4800\n",
      "Epoch 9 | Iter5 | Loss1.8067 | TrainAcc0.6389 | Testacc 0.4800\n",
      "Epoch 9 | Iter7 | Loss1.9487 | TrainAcc0.6389 | Testacc 0.4400\n",
      "Epoch 9 | Iter9 | Loss1.8383 | TrainAcc0.6833 | Testacc 0.4800\n",
      "Epoch 10 | Iter1 | Loss1.8020 | TrainAcc0.6528 | Testacc 0.4600\n",
      "Epoch 10 | Iter3 | Loss1.7574 | TrainAcc0.7222 | Testacc 0.4600\n",
      "Epoch 10 | Iter5 | Loss1.7507 | TrainAcc0.7361 | Testacc 0.4600\n",
      "Epoch 10 | Iter7 | Loss1.8799 | TrainAcc0.6667 | Testacc 0.4600\n",
      "Epoch 10 | Iter9 | Loss1.7242 | TrainAcc0.6833 | Testacc 0.4400\n",
      "Epoch 11 | Iter1 | Loss1.7825 | TrainAcc0.6806 | Testacc 0.4600\n",
      "Epoch 11 | Iter3 | Loss1.8007 | TrainAcc0.6944 | Testacc 0.4800\n",
      "Epoch 11 | Iter5 | Loss1.7063 | TrainAcc0.7361 | Testacc 0.5000\n",
      "Epoch 11 | Iter7 | Loss1.7933 | TrainAcc0.6944 | Testacc 0.5000\n",
      "Epoch 11 | Iter9 | Loss1.8368 | TrainAcc0.6167 | Testacc 0.5200\n",
      "Epoch 12 | Iter1 | Loss1.7706 | TrainAcc0.6944 | Testacc 0.5200\n",
      "Epoch 12 | Iter3 | Loss1.6139 | TrainAcc0.7778 | Testacc 0.5400\n",
      "Epoch 12 | Iter5 | Loss1.7199 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 12 | Iter7 | Loss1.7992 | TrainAcc0.7222 | Testacc 0.5400\n",
      "Epoch 12 | Iter9 | Loss1.7079 | TrainAcc0.7500 | Testacc 0.5400\n",
      "Epoch 13 | Iter1 | Loss1.6976 | TrainAcc0.7778 | Testacc 0.5200\n",
      "Epoch 13 | Iter3 | Loss1.8005 | TrainAcc0.6806 | Testacc 0.5200\n",
      "Epoch 13 | Iter5 | Loss1.7434 | TrainAcc0.7083 | Testacc 0.5200\n",
      "Epoch 13 | Iter7 | Loss1.7079 | TrainAcc0.7500 | Testacc 0.5200\n",
      "Epoch 13 | Iter9 | Loss1.7098 | TrainAcc0.7333 | Testacc 0.5000\n",
      "Epoch 14 | Iter1 | Loss1.6560 | TrainAcc0.7639 | Testacc 0.4800\n",
      "Epoch 14 | Iter3 | Loss1.6229 | TrainAcc0.7778 | Testacc 0.4400\n",
      "Epoch 14 | Iter5 | Loss1.6118 | TrainAcc0.8472 | Testacc 0.4600\n",
      "Epoch 14 | Iter7 | Loss1.7102 | TrainAcc0.7500 | Testacc 0.5000\n",
      "Epoch 14 | Iter9 | Loss1.6264 | TrainAcc0.8167 | Testacc 0.5000\n",
      "Epoch 15 | Iter1 | Loss1.5688 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 15 | Iter3 | Loss1.5591 | TrainAcc0.8194 | Testacc 0.5200\n",
      "Epoch 15 | Iter5 | Loss1.6220 | TrainAcc0.7639 | Testacc 0.5400\n",
      "Epoch 15 | Iter7 | Loss1.7136 | TrainAcc0.7222 | Testacc 0.5400\n",
      "Epoch 15 | Iter9 | Loss1.6027 | TrainAcc0.7833 | Testacc 0.5000\n",
      "Epoch 16 | Iter1 | Loss1.5950 | TrainAcc0.7778 | Testacc 0.5000\n",
      "Epoch 16 | Iter3 | Loss1.6138 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 16 | Iter5 | Loss1.5931 | TrainAcc0.8056 | Testacc 0.4600\n",
      "Epoch 16 | Iter7 | Loss1.4792 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 16 | Iter9 | Loss1.5494 | TrainAcc0.8333 | Testacc 0.4800\n",
      "Epoch 17 | Iter1 | Loss1.5463 | TrainAcc0.8750 | Testacc 0.4600\n",
      "Epoch 17 | Iter3 | Loss1.4936 | TrainAcc0.7778 | Testacc 0.4800\n",
      "Epoch 17 | Iter5 | Loss1.4901 | TrainAcc0.8194 | Testacc 0.4600\n",
      "Epoch 17 | Iter7 | Loss1.5911 | TrainAcc0.8056 | Testacc 0.4800\n",
      "Epoch 17 | Iter9 | Loss1.5493 | TrainAcc0.7833 | Testacc 0.4800\n",
      "Epoch 18 | Iter1 | Loss1.4290 | TrainAcc0.9167 | Testacc 0.4600\n",
      "Epoch 18 | Iter3 | Loss1.4460 | TrainAcc0.9028 | Testacc 0.4600\n",
      "Epoch 18 | Iter5 | Loss1.5106 | TrainAcc0.8750 | Testacc 0.5000\n",
      "Epoch 18 | Iter7 | Loss1.4425 | TrainAcc0.9028 | Testacc 0.4800\n",
      "Epoch 18 | Iter9 | Loss1.4638 | TrainAcc0.8667 | Testacc 0.4800\n",
      "Epoch 19 | Iter1 | Loss1.4713 | TrainAcc0.8472 | Testacc 0.4800\n",
      "Epoch 19 | Iter3 | Loss1.5471 | TrainAcc0.7917 | Testacc 0.5200\n",
      "Epoch 19 | Iter5 | Loss1.4379 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 19 | Iter7 | Loss1.5678 | TrainAcc0.7917 | Testacc 0.4800\n",
      "Epoch 19 | Iter9 | Loss1.5453 | TrainAcc0.8167 | Testacc 0.4600\n",
      "Epoch 20 | Iter1 | Loss1.5332 | TrainAcc0.8056 | Testacc 0.5000\n",
      "Epoch 20 | Iter3 | Loss1.4230 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 20 | Iter5 | Loss1.4815 | TrainAcc0.8333 | Testacc 0.5200\n",
      "Epoch 20 | Iter7 | Loss1.4557 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 20 | Iter9 | Loss1.4608 | TrainAcc0.8667 | Testacc 0.5200\n",
      "Epoch 21 | Iter1 | Loss1.4203 | TrainAcc0.9028 | Testacc 0.5200\n",
      "Epoch 21 | Iter3 | Loss1.4706 | TrainAcc0.8472 | Testacc 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Iter5 | Loss1.4051 | TrainAcc0.9306 | Testacc 0.5200\n",
      "Epoch 21 | Iter7 | Loss1.4250 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 21 | Iter9 | Loss1.4874 | TrainAcc0.8833 | Testacc 0.5200\n",
      "Epoch 22 | Iter1 | Loss1.4780 | TrainAcc0.8611 | Testacc 0.5200\n",
      "Epoch 22 | Iter3 | Loss1.4158 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 22 | Iter5 | Loss1.4680 | TrainAcc0.8194 | Testacc 0.5000\n",
      "Epoch 22 | Iter7 | Loss1.4382 | TrainAcc0.8472 | Testacc 0.5200\n",
      "Epoch 22 | Iter9 | Loss1.4460 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 23 | Iter1 | Loss1.3922 | TrainAcc0.8611 | Testacc 0.5000\n",
      "Epoch 23 | Iter3 | Loss1.3677 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 23 | Iter5 | Loss1.3239 | TrainAcc0.9722 | Testacc 0.5000\n",
      "Epoch 23 | Iter7 | Loss1.3641 | TrainAcc0.9167 | Testacc 0.5000\n",
      "Epoch 23 | Iter9 | Loss1.4704 | TrainAcc0.8833 | Testacc 0.4800\n",
      "Epoch 24 | Iter1 | Loss1.4450 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 24 | Iter3 | Loss1.2601 | TrainAcc0.9722 | Testacc 0.4800\n",
      "Epoch 24 | Iter5 | Loss1.3933 | TrainAcc0.8889 | Testacc 0.5000\n",
      "Epoch 24 | Iter7 | Loss1.3744 | TrainAcc0.9028 | Testacc 0.5000\n",
      "Epoch 24 | Iter9 | Loss1.3448 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 25 | Iter1 | Loss1.4952 | TrainAcc0.8472 | Testacc 0.5400\n",
      "Epoch 25 | Iter3 | Loss1.3185 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 25 | Iter5 | Loss1.3358 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 25 | Iter7 | Loss1.2887 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 25 | Iter9 | Loss1.3129 | TrainAcc0.9333 | Testacc 0.5400\n",
      "Epoch 26 | Iter1 | Loss1.3473 | TrainAcc0.9444 | Testacc 0.5400\n",
      "Epoch 26 | Iter3 | Loss1.3368 | TrainAcc0.8889 | Testacc 0.5400\n",
      "Epoch 26 | Iter5 | Loss1.3344 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 26 | Iter7 | Loss1.3059 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 26 | Iter9 | Loss1.3210 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 27 | Iter1 | Loss1.3403 | TrainAcc0.9167 | Testacc 0.5200\n",
      "Epoch 27 | Iter3 | Loss1.2936 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 27 | Iter5 | Loss1.3080 | TrainAcc0.9167 | Testacc 0.5400\n",
      "Epoch 27 | Iter7 | Loss1.3691 | TrainAcc0.9028 | Testacc 0.5400\n",
      "Epoch 27 | Iter9 | Loss1.3177 | TrainAcc0.8833 | Testacc 0.5800\n",
      "Epoch 28 | Iter1 | Loss1.3284 | TrainAcc0.8889 | Testacc 0.6000\n",
      "Epoch 28 | Iter3 | Loss1.3182 | TrainAcc0.9167 | Testacc 0.6400\n",
      "Epoch 28 | Iter5 | Loss1.3496 | TrainAcc0.9028 | Testacc 0.6600\n",
      "Epoch 28 | Iter7 | Loss1.3068 | TrainAcc0.9306 | Testacc 0.6400\n",
      "Epoch 28 | Iter9 | Loss1.3742 | TrainAcc0.8667 | Testacc 0.6200\n",
      "Epoch 29 | Iter1 | Loss1.2943 | TrainAcc0.9583 | Testacc 0.6000\n",
      "Epoch 29 | Iter3 | Loss1.3191 | TrainAcc0.8889 | Testacc 0.6000\n",
      "Epoch 29 | Iter5 | Loss1.3411 | TrainAcc0.8750 | Testacc 0.6000\n",
      "Epoch 29 | Iter7 | Loss1.2907 | TrainAcc0.9444 | Testacc 0.6400\n",
      "Epoch 29 | Iter9 | Loss1.2105 | TrainAcc0.9667 | Testacc 0.6400\n",
      "Epoch 30 | Iter1 | Loss1.2615 | TrainAcc0.9167 | Testacc 0.6400\n",
      "Epoch 30 | Iter3 | Loss1.3203 | TrainAcc0.9028 | Testacc 0.6400\n",
      "Epoch 30 | Iter5 | Loss1.3526 | TrainAcc0.9028 | Testacc 0.6400\n",
      "Epoch 30 | Iter7 | Loss1.3122 | TrainAcc0.8889 | Testacc 0.6200\n",
      "Epoch 30 | Iter9 | Loss1.3185 | TrainAcc0.9000 | Testacc 0.6000\n",
      "Epoch 31 | Iter1 | Loss1.3214 | TrainAcc0.8889 | Testacc 0.6200\n",
      "Epoch 31 | Iter3 | Loss1.3422 | TrainAcc0.9028 | Testacc 0.6000\n",
      "Epoch 31 | Iter5 | Loss1.2906 | TrainAcc0.9028 | Testacc 0.6000\n",
      "Epoch 31 | Iter7 | Loss1.3846 | TrainAcc0.8750 | Testacc 0.5800\n",
      "Epoch 31 | Iter9 | Loss1.2189 | TrainAcc0.9667 | Testacc 0.6000\n",
      "Epoch 32 | Iter1 | Loss1.2380 | TrainAcc0.9306 | Testacc 0.5600\n",
      "Epoch 32 | Iter3 | Loss1.2619 | TrainAcc0.9583 | Testacc 0.5800\n",
      "Epoch 32 | Iter5 | Loss1.2131 | TrainAcc0.9583 | Testacc 0.5800\n",
      "Epoch 32 | Iter7 | Loss1.2751 | TrainAcc0.9722 | Testacc 0.6000\n",
      "Epoch 32 | Iter9 | Loss1.3144 | TrainAcc0.9500 | Testacc 0.6000\n",
      "Epoch 33 | Iter1 | Loss1.2001 | TrainAcc0.9722 | Testacc 0.6000\n",
      "Epoch 33 | Iter3 | Loss1.2460 | TrainAcc0.9028 | Testacc 0.6200\n",
      "Epoch 33 | Iter5 | Loss1.2756 | TrainAcc0.9306 | Testacc 0.6200\n",
      "Epoch 33 | Iter7 | Loss1.2816 | TrainAcc0.9583 | Testacc 0.6000\n",
      "Epoch 33 | Iter9 | Loss1.3998 | TrainAcc0.8333 | Testacc 0.5800\n",
      "Epoch 34 | Iter1 | Loss1.3595 | TrainAcc0.8889 | Testacc 0.5800\n",
      "Epoch 34 | Iter3 | Loss1.2224 | TrainAcc0.9722 | Testacc 0.5800\n",
      "Epoch 34 | Iter5 | Loss1.3009 | TrainAcc0.8889 | Testacc 0.6000\n",
      "Epoch 34 | Iter7 | Loss1.1781 | TrainAcc1.0000 | Testacc 0.5800\n",
      "Epoch 34 | Iter9 | Loss1.2105 | TrainAcc0.9667 | Testacc 0.5800\n",
      "Epoch 35 | Iter1 | Loss1.2114 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Epoch 35 | Iter3 | Loss1.1840 | TrainAcc0.9583 | Testacc 0.5800\n",
      "Epoch 35 | Iter5 | Loss1.2009 | TrainAcc0.9583 | Testacc 0.6000\n",
      "Epoch 35 | Iter7 | Loss1.1797 | TrainAcc0.9861 | Testacc 0.5800\n",
      "Epoch 35 | Iter9 | Loss1.3219 | TrainAcc0.9167 | Testacc 0.5600\n",
      "Test accuracy of model 7:  0.56\n",
      "Test accuracy is:  0.54\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net_1 = Net()\n",
    "net_2 = Net()\n",
    "net_3 = Net()\n",
    "net_4 = Net()\n",
    "net_5 = Net()\n",
    "net_6 = Net()\n",
    "net_7 = Net()\n",
    "list_net = [net_1, net_2, net_3, net_4, net_5, net_6, net_7]\n",
    "#list_best_net = [Net(), Net(), Net(), Net(), Net(), Net(), Net()]\n",
    "for n,net in enumerate(list_net):\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    #val_acc_history = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum = 0.9, nesterov = True, weight_decay = 1e-3)\n",
    "\n",
    "    print('--------------------------------------------------')\n",
    "    print('Training Net {}'.format(n+1))\n",
    "    for epoch in range(35): #Single subject\n",
    "    #for epoch in range(35):#All subjects\n",
    "        for i , data in enumerate(train_loader_1, 0):\n",
    "            \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            #inputs, labels = data\n",
    "            \n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            reg_loss = 0\n",
    "            for param in net.parameters():\n",
    "                reg_loss += nn.MSELoss(reduction='sum')(param,target=torch.zeros_like(param))\n",
    "            factor = 1e-3\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += factor*reg_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "            train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "            \n",
    "            if i % 2 == 1:\n",
    "                net.eval()\n",
    "                test_correct, test_total = 0, 0 \n",
    "                for test_data in test_loader_1:\n",
    "                    \n",
    "                    test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "                    \n",
    "                    #test_images, test_labels = test_data\n",
    "                    \n",
    "                    test_outputs = net(test_images)\n",
    "                    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "                    test_total += test_labels.size(0)\n",
    "                    test_correct += (test_predicted == test_labels).sum().item()\n",
    "                test_acc = test_correct / test_total\n",
    "                print('Epoch {} | Iter{} | Loss{:.4f} | TrainAcc{:.4f} | Testacc {:.4f}'.format(\n",
    "                    epoch+1, i , loss, train_acc, test_acc))\n",
    "                #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "        #net.eval()\n",
    "        #val_correct, val_total = 0, 0\n",
    "        #for val_data in val_loader_1:\n",
    "        #    val_images, val_labels = val_data\n",
    "        #    val_outputs = net(val_images)\n",
    "        #    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        #    val_total += val_labels.size(0)\n",
    "        #    val_correct += (val_predicted == val_labels).sum().item()\n",
    "        #val_acc = val_correct / val_total\n",
    "        #val_acc_history.append(val_acc)\n",
    "        #if val_acc == max(val_acc_history):\n",
    "        #    list_best_net[n] = Net()\n",
    "        #    list_best_net[n].load_state_dict(net.state_dict())\n",
    "    net.eval()\n",
    "    test_correct, test_total = 0, 0\n",
    "    for test_data in test_loader_1:\n",
    "        test_inputs, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        test_outputs = net(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_total += test_labels.size(0)\n",
    "        test_correct += (test_predicted == test_labels).sum().item()\n",
    "    test_acc = test_correct / test_total\n",
    "    print('Test accuracy of model {}: '.format(n+1),test_acc)\n",
    "    \n",
    "test_correct, test_total = 0, 0\n",
    "device = torch.device(\"cpu\")\n",
    "for test_data in test_loader_1:\n",
    "    test_images, test_labels = test_data\n",
    "    test_predicted_list = []\n",
    "    for net in list_net:\n",
    "    #for net_best in list_best_net:\n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "        test_outputs = net(test_images)\n",
    "        #test_outputs = net_best(test_images)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_predicted_list.append(test_predicted.numpy())\n",
    "    test_predicted_list = np.array(test_predicted_list)\n",
    "    test_predicted_result = []\n",
    "    for vote in range(np.shape(test_predicted_list)[1]):\n",
    "        test_predicted_result.append(Counter(test_predicted_list[:,vote]).most_common(1)[0][0])\n",
    "    test_predicted = torch.Tensor(test_predicted_result)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN+LSTM投票**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()  # initial the model\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.AvgPool1d(2,2) \n",
    " \n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1)\n",
    "        #x = torch.Tensor(x.numpy().transpose(0,2,1))\n",
    "        x = self.pool1(F.elu(self.bn2(self.conv2(F.elu(self.bn1(self.conv1(x)))))))\n",
    "        x = x.detach()\n",
    "        x = x.permute(0,2,1)\n",
    "        #x = torch.Tensor(x.detach().numpy().transpose(0,2,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net1 = ConvNet()\n",
    "conv_net2 = ConvNet()\n",
    "conv_net3 = ConvNet()\n",
    "conv_net4 = ConvNet()\n",
    "conv_net5 = ConvNet()\n",
    "conv_net6 = ConvNet()\n",
    "conv_net7 = ConvNet()\n",
    "list_convnet = [conv_net1, conv_net2, conv_net3, conv_net4, conv_net5, conv_net6, conv_net7]\n",
    "for i,convnet in enumerate(list_convnet):\n",
    "    pretrained_dict = list_net[i].state_dict()\n",
    "    convnet_dict = convnet.state_dict()\n",
    "    pretrained_dict = {k:v for k,v in pretrained_dict.items() if k in convnet_dict}\n",
    "    convnet_dict.update(pretrained_dict)\n",
    "    convnet.load_state_dict(convnet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, convnet):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.conv = convnet  \n",
    "        #self.conv = ConvNet()  \n",
    "        self.LSTM1 = nn.LSTM(input_dim, hidden_dim1, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        #self.LSTM2 = nn.LSTM(hidden_dim1*2, hidden_dim2, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        self.LSTM3 = nn.LSTM(hidden_dim1*2, hidden_dim3, bidirectional = True, num_layers=2, batch_first = True, dropout = 0.4)\n",
    "        #self.LSTM4 = nn.LSTM(hidden_dim3*2, hidden_dim4, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        self.fc1 = nn.Linear(hidden_dim3*2*249, 2000) \n",
    "        self.bn1 = nn.BatchNorm1d(2000)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(2000,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.drop2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(100,20)\n",
    "        self.bn3 = nn.BatchNorm1d(20)\n",
    "        self.drop3 = nn.Dropout(0.8)\n",
    "        self.fc4 = nn.Linear(20,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        x = self.conv(x)\n",
    "        if type(h) == type(None) and type(c) == type(None):\n",
    "            out, (hn, cn) = self.LSTM1(x)\n",
    "            #out, (hn, cn) = self.LSTM2(out)\n",
    "            out, (hn, cn) = self.LSTM3(out)\n",
    "            #out, (hn, cn) = self.LSTM4(out)\n",
    "        else:\n",
    "            out, (hn, cn) = self.LSTM1(x, h.detach(), c.detach())\n",
    "            #out, (hn, cn) = self.LSTM2(out, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM3(out, h.detach(), c.detach())\n",
    "            #out, (hn, cn) = self.LSTM4(out, h.detach(), c.detach())\n",
    "        #out = self.drop1(F.elu(self.bn1(self.fc1(out[:, -1, :]))))\n",
    "        out = out.permute(0,2,1)\n",
    "        out = self.drop1(F.elu(self.bn1(self.fc1(out.reshape(out.shape[0],-1)))))\n",
    "        out = self.drop2(F.elu(self.bn2(self.fc2(out))))\n",
    "        out = self.drop3(F.elu(self.bn3(self.fc3(out))))\n",
    "        out = self.fc4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 60\n",
    "hidden_dim1 = 40\n",
    "hidden_dim2 = 60\n",
    "hidden_dim3 = 80\n",
    "output_dim = 4\n",
    "model_1 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net1)\n",
    "model_2 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net2)\n",
    "model_3 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net3)\n",
    "model_4 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net4)\n",
    "model_5 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net5)\n",
    "model_6 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net6)\n",
    "model_7 = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim, conv_net7)\n",
    "list_model = [model_1, model_2, model_3, model_4, model_5, model_6, model_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training Model 1\n",
      "epoch:1   time:22.30 test_loss:6.899 test acc: 0.240\n",
      "epoch:2   time:14.79 test_loss:6.877 test acc: 0.240\n",
      "epoch:3   time:14.52 test_loss:6.844 test acc: 0.320\n",
      "epoch:4   time:14.69 test_loss:6.799 test acc: 0.300\n",
      "epoch:5   time:14.51 test_loss:6.723 test acc: 0.380\n",
      "epoch:6   time:14.68 test_loss:6.619 test acc: 0.400\n",
      "epoch:7   time:14.60 test_loss:6.495 test acc: 0.380\n",
      "epoch:8   time:14.75 test_loss:6.430 test acc: 0.320\n",
      "epoch:9   time:14.52 test_loss:6.372 test acc: 0.340\n",
      "epoch:10  time:14.70 test_loss:6.308 test acc: 0.360\n",
      "epoch:11  time:14.52 test_loss:6.268 test acc: 0.360\n",
      "epoch:12  time:14.62 test_loss:6.225 test acc: 0.380\n",
      "epoch:13  time:14.47 test_loss:6.191 test acc: 0.360\n",
      "epoch:14  time:14.66 test_loss:6.155 test acc: 0.380\n",
      "epoch:15  time:14.45 test_loss:6.126 test acc: 0.380\n",
      "epoch:16  time:14.64 test_loss:6.112 test acc: 0.320\n",
      "epoch:17  time:14.46 test_loss:6.093 test acc: 0.340\n",
      "epoch:18  time:14.62 test_loss:6.058 test acc: 0.380\n",
      "epoch:19  time:14.51 test_loss:6.024 test acc: 0.400\n",
      "epoch:20  time:14.62 test_loss:5.983 test acc: 0.440\n",
      "epoch:21  time:14.51 test_loss:5.960 test acc: 0.480\n",
      "epoch:22  time:14.61 test_loss:5.946 test acc: 0.420\n",
      "epoch:23  time:14.50 test_loss:5.891 test acc: 0.460\n",
      "epoch:24  time:14.60 test_loss:5.854 test acc: 0.460\n",
      "epoch:25  time:14.48 test_loss:5.793 test acc: 0.540\n",
      "epoch:26  time:14.61 test_loss:5.771 test acc: 0.540\n",
      "epoch:27  time:14.64 test_loss:5.750 test acc: 0.480\n",
      "epoch:28  time:14.98 test_loss:5.760 test acc: 0.540\n",
      "epoch:29  time:14.49 test_loss:5.734 test acc: 0.560\n",
      "epoch:30  time:14.65 test_loss:5.709 test acc: 0.560\n",
      "epoch:31  time:14.47 test_loss:5.704 test acc: 0.580\n",
      "epoch:32  time:14.63 test_loss:5.692 test acc: 0.560\n",
      "epoch:33  time:14.56 test_loss:5.664 test acc: 0.560\n",
      "epoch:34  time:14.69 test_loss:5.638 test acc: 0.560\n",
      "epoch:35  time:14.52 test_loss:5.629 test acc: 0.580\n",
      "epoch:36  time:14.69 test_loss:5.620 test acc: 0.560\n",
      "epoch:37  time:14.48 test_loss:5.606 test acc: 0.580\n",
      "epoch:38  time:14.82 test_loss:5.606 test acc: 0.580\n",
      "epoch:39  time:14.56 test_loss:5.572 test acc: 0.560\n",
      "epoch:40  time:14.61 test_loss:5.538 test acc: 0.560\n",
      "epoch:41  time:14.50 test_loss:5.514 test acc: 0.560\n",
      "epoch:42  time:14.65 test_loss:5.508 test acc: 0.560\n",
      "epoch:43  time:14.45 test_loss:5.528 test acc: 0.600\n",
      "epoch:44  time:14.60 test_loss:5.536 test acc: 0.580\n",
      "epoch:45  time:14.46 test_loss:5.531 test acc: 0.560\n",
      "Test accuracy of model 1:  0.56\n",
      "--------------------------------------------------\n",
      "Training Model 2\n",
      "epoch:1   time:13.75 test_loss:7.051 test acc: 0.200\n",
      "epoch:2   time:13.71 test_loss:7.034 test acc: 0.200\n",
      "epoch:3   time:13.88 test_loss:6.997 test acc: 0.200\n",
      "epoch:4   time:13.77 test_loss:6.936 test acc: 0.220\n",
      "epoch:5   time:13.98 test_loss:6.825 test acc: 0.280\n",
      "epoch:6   time:13.71 test_loss:6.689 test acc: 0.360\n",
      "epoch:7   time:13.87 test_loss:6.564 test acc: 0.380\n",
      "epoch:8   time:13.76 test_loss:6.446 test acc: 0.360\n",
      "epoch:9   time:13.92 test_loss:6.358 test acc: 0.360\n",
      "epoch:10  time:13.72 test_loss:6.291 test acc: 0.360\n",
      "epoch:11  time:13.91 test_loss:6.254 test acc: 0.360\n",
      "epoch:12  time:13.73 test_loss:6.216 test acc: 0.400\n",
      "epoch:13  time:13.93 test_loss:6.172 test acc: 0.400\n",
      "epoch:14  time:13.70 test_loss:6.141 test acc: 0.400\n",
      "epoch:15  time:13.86 test_loss:6.126 test acc: 0.400\n",
      "epoch:16  time:13.77 test_loss:6.097 test acc: 0.440\n",
      "epoch:17  time:13.90 test_loss:6.057 test acc: 0.440\n",
      "epoch:18  time:13.76 test_loss:6.021 test acc: 0.460\n",
      "epoch:19  time:13.89 test_loss:6.011 test acc: 0.460\n",
      "epoch:20  time:13.72 test_loss:5.993 test acc: 0.460\n",
      "epoch:21  time:13.89 test_loss:5.973 test acc: 0.460\n",
      "epoch:22  time:13.75 test_loss:5.940 test acc: 0.500\n",
      "epoch:23  time:13.89 test_loss:5.922 test acc: 0.480\n",
      "epoch:24  time:13.75 test_loss:5.895 test acc: 0.480\n",
      "epoch:25  time:13.92 test_loss:5.880 test acc: 0.480\n",
      "epoch:26  time:13.72 test_loss:5.878 test acc: 0.480\n",
      "epoch:27  time:13.88 test_loss:5.871 test acc: 0.440\n",
      "epoch:28  time:13.72 test_loss:5.845 test acc: 0.460\n",
      "epoch:29  time:13.88 test_loss:5.846 test acc: 0.520\n",
      "epoch:30  time:13.72 test_loss:5.844 test acc: 0.520\n",
      "epoch:31  time:13.95 test_loss:5.838 test acc: 0.500\n",
      "epoch:32  time:13.77 test_loss:5.816 test acc: 0.480\n",
      "epoch:33  time:14.03 test_loss:5.795 test acc: 0.480\n",
      "epoch:34  time:14.27 test_loss:5.814 test acc: 0.500\n",
      "epoch:35  time:14.02 test_loss:5.825 test acc: 0.500\n",
      "epoch:36  time:13.71 test_loss:5.833 test acc: 0.500\n",
      "epoch:37  time:13.87 test_loss:5.833 test acc: 0.500\n",
      "epoch:38  time:13.94 test_loss:5.854 test acc: 0.500\n",
      "epoch:39  time:13.92 test_loss:5.876 test acc: 0.520\n",
      "epoch:40  time:13.87 test_loss:5.872 test acc: 0.520\n",
      "epoch:41  time:14.35 test_loss:5.866 test acc: 0.520\n",
      "epoch:42  time:14.24 test_loss:5.879 test acc: 0.520\n",
      "epoch:43  time:15.17 test_loss:5.905 test acc: 0.520\n",
      "epoch:44  time:15.27 test_loss:5.916 test acc: 0.520\n",
      "epoch:45  time:15.33 test_loss:5.916 test acc: 0.520\n",
      "Test accuracy of model 2:  0.52\n",
      "--------------------------------------------------\n",
      "Training Model 3\n",
      "epoch:1   time:15.16 test_loss:6.921 test acc: 0.300\n",
      "epoch:2   time:14.97 test_loss:6.903 test acc: 0.300\n",
      "epoch:3   time:14.27 test_loss:6.876 test acc: 0.340\n",
      "epoch:4   time:14.29 test_loss:6.823 test acc: 0.360\n",
      "epoch:5   time:13.84 test_loss:6.736 test acc: 0.480\n",
      "epoch:6   time:14.03 test_loss:6.616 test acc: 0.480\n",
      "epoch:7   time:13.87 test_loss:6.464 test acc: 0.480\n",
      "epoch:8   time:14.17 test_loss:6.348 test acc: 0.460\n",
      "epoch:9   time:14.30 test_loss:6.273 test acc: 0.480\n",
      "epoch:10  time:14.05 test_loss:6.231 test acc: 0.480\n",
      "epoch:11  time:14.17 test_loss:6.190 test acc: 0.520\n",
      "epoch:12  time:14.06 test_loss:6.156 test acc: 0.500\n",
      "epoch:13  time:13.82 test_loss:6.121 test acc: 0.500\n",
      "epoch:14  time:14.03 test_loss:6.074 test acc: 0.520\n",
      "epoch:15  time:13.87 test_loss:6.045 test acc: 0.520\n",
      "epoch:16  time:14.03 test_loss:6.019 test acc: 0.500\n",
      "epoch:17  time:13.84 test_loss:5.999 test acc: 0.480\n",
      "epoch:18  time:14.13 test_loss:5.977 test acc: 0.520\n",
      "epoch:19  time:13.96 test_loss:5.944 test acc: 0.520\n",
      "epoch:20  time:14.06 test_loss:5.908 test acc: 0.560\n",
      "epoch:21  time:13.83 test_loss:5.881 test acc: 0.560\n",
      "epoch:22  time:14.01 test_loss:5.862 test acc: 0.560\n",
      "epoch:23  time:14.06 test_loss:5.841 test acc: 0.560\n",
      "epoch:24  time:14.16 test_loss:5.806 test acc: 0.560\n",
      "epoch:25  time:13.91 test_loss:5.783 test acc: 0.560\n",
      "epoch:26  time:14.11 test_loss:5.760 test acc: 0.500\n",
      "epoch:27  time:13.96 test_loss:5.745 test acc: 0.520\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "list_model = [model_1, model_2, model_3, model_4, model_5, model_6, model_7]\n",
    "t0 = time.time()\n",
    "for n, model in enumerate(list_model):\n",
    "    #val_acc_history = []\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum = 0.9, nesterov = True, weight_decay = 1e-3)\n",
    "    print('--------------------------------------------------')\n",
    "    print('Training Model {}'.format(n+1))\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    test_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    test_loss_history = []\n",
    "    for epoch in range(45): #Single subject\n",
    "    #for epoch in range(120):#All subjects\n",
    "        tstart = time.time()\n",
    "        for i, data in enumerate(train_loader_1):\n",
    "            \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            #inputs, labels = data\n",
    "            #inputs = convnet(inputs)\n",
    "            #inputs = torch.Tensor(inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            reg_loss = 0\n",
    "            for param in model.parameters():\n",
    "                reg_loss += nn.MSELoss(reduction='sum')(param, target = torch.zeros_like(param))\n",
    "            factor = 1e-2\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += factor*reg_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "            train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "            \n",
    "        #model.eval()\n",
    "        #train_correct, train_total = 0, 0\n",
    "        #train_loss = 0\n",
    "        #for train_data in train_loader_1:\n",
    "        #    train_inputs, train_labels = train_data\n",
    "        #    #train_inputs = convnet(train_inputs)\n",
    "        #    #train_inputs = torch.Tensor(train_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        #    train_outputs = model(train_inputs)\n",
    "        #    _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        #    train_total += train_labels.size(0)\n",
    "        #    train_correct += (train_predicted == train_labels).sum().item()\n",
    "        #    train_loss += criterion(train_outputs, train_labels).item()\n",
    "        #train_acc = train_correct / train_total\n",
    "        #train_acc_history.append(train_acc)\n",
    "        #train_loss_history.append(train_loss)\n",
    "        #    \n",
    "        ##pXtrain = model(Xtrain)\n",
    "        ##ptrain = torch.argmax(pXtrain, axis = 1)\n",
    "        ##train_acc = np.mean(ptrain.numpy() == ytrain.numpy())\n",
    "        ##train_accs.append(train_acc)\n",
    "        ##tloss = criterion(pXtrain, ytrain)\n",
    "        ##train_losses.append(tloss.item())\n",
    "        #model.eval()\n",
    "        #val_correct, val_total = 0, 0\n",
    "        #val_loss = 0\n",
    "        #for val_data in val_loader_1:\n",
    "        #    val_inputs, val_labels = val_data\n",
    "        #    #val_inputs = convnet(val_inputs)\n",
    "        #    #val_inputs = torch.Tensor(val_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        #    val_outputs = model(val_inputs)\n",
    "        #    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        #    val_total += val_labels.size(0)\n",
    "        #    val_correct += (val_predicted == val_labels).sum().item()\n",
    "        #    val_loss += criterion(val_outputs, val_labels).item()\n",
    "        #val_acc = val_correct / val_total\n",
    "        #val_acc_history.append(val_acc)\n",
    "        #val_loss_history.append(val_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        test_correct, test_total = 0, 0\n",
    "        test_loss = 0\n",
    "        for test_data in test_loader_1:\n",
    "\n",
    "            test_inputs, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "            #test_inputs, test_labels = test_data\n",
    "            #test_inputs = convnet(test_inputs)\n",
    "            #test_inputs = torch.Tensor(test_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "            test_outputs = model(test_inputs)\n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_total += test_labels.size(0)\n",
    "            test_correct += (test_predicted == test_labels).sum().item()\n",
    "            test_loss += criterion(test_outputs, test_labels).item()\n",
    "        test_acc = test_correct / test_total\n",
    "        test_acc_history.append(test_acc)\n",
    "        test_loss_history.append(test_loss)\n",
    "        \n",
    "        #pXval = model(Xval)\n",
    "        #pval = torch.argmax(pXval, axis = 1)\n",
    "        #val_acc = np.mean(pval.numpy() == yval.numpy())\n",
    "        #val_accs.append(val_acc)\n",
    "        #vloss = criterion(pXval, yval)\n",
    "        #val_losses.append(vloss.item())\n",
    "        tend = time.time()\n",
    "        #print('epoch:{:<3d} time:{:<3.2f} train_loss:{:<3.3f} train acc:{:<1.3f} val_loss:{:<3.3f} val acc:{:<1.3f} test_loss:{:<3.3f} test acc: {:<1.3f}'.format(epoch+1, \n",
    "        #        tend - tstart, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "        print('epoch:{:<3d} time:{:<3.2f} test_loss:{:<3.3f} test acc: {:<1.3f}'.format(epoch+1, tend - tstart, test_loss, test_acc))\n",
    "    print('Test accuracy of model {}: '.format(n+1),test_acc)\n",
    "device = torch.device(\"cpu\")\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_images, test_labels = test_data\n",
    "    test_predicted_list = []\n",
    "    for model in list_model:\n",
    "    #for net_best in list_best_net:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        test_outputs = model(test_images)\n",
    "        #test_outputs = net_best(test_images)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_predicted_list.append(test_predicted.numpy())\n",
    "    test_predicted_list = np.array(test_predicted_list)\n",
    "    test_predicted_result = []\n",
    "    for vote in range(np.shape(test_predicted_list)[1]):\n",
    "        test_predicted_result.append(Counter(test_predicted_list[:,vote]).most_common(1)[0][0])\n",
    "    test_predicted = torch.Tensor(test_predicted_result)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
