{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test - 769\n",
    "y_train_valid = y_train_valid - 769\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\\ny_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\\nX_test_1 = X_test[np.where(person_test==0)[0]]\\ny_test_1 = y_test[np.where(person_test==0)[0]]\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For subject 1\n",
    "'''\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1692, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid,\n",
    "                                                              test_size=0.2,shuffle=True)\n",
    "\n",
    "train_set = Dataset(X_train,y_train)\n",
    "val_set = Dataset(X_valid,y_valid)\n",
    "test_set = Dataset(X_test, y_test)\n",
    "print(X_train.shape)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=43,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=15,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=12,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(22, 40, kernel_size=(2,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(40, 60, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(60, 80, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(80, 100, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv1d(100, 120, kernel_size=(3,), stride=(2,))\n",
      "  (bn5): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=7320, out_features=300, bias=True)\n",
      "  (bn6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.8, inplace=False)\n",
      "  (fc2): Linear(in_features=300, out_features=40, bias=True)\n",
      "  (bn7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop2): Dropout(p=0.8, inplace=False)\n",
      "  (fc3): Linear(in_features=40, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#目前这个最好\n",
    "#只有FC有dropout\n",
    "# [conv-relu]*2 -> 2*2 max-pooling -> [conv-relu]*3 -> 2*2 max_pooling -> (affine-relu)*2 -> affine -> softmax\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.MaxPool1d(2,2) \n",
    "        \n",
    "        self.conv3 = nn.Conv1d(60,80,kernel_size = 3, stride = 1) \n",
    "        self.bn3 = nn.BatchNorm1d(80)\n",
    "        self.conv4 = nn.Conv1d(80,100,kernel_size = 3, stride = 1) \n",
    "        self.bn4 = nn.BatchNorm1d(100)\n",
    "        self.conv5 = nn.Conv1d(100,120,kernel_size = 3, stride = 2) #120*122\n",
    "        self.bn5 = nn.BatchNorm1d(120)\n",
    "        self.pool2 = nn.MaxPool1d(2,2) #120*61\n",
    "        \n",
    "        self.fc1 = nn.Linear(120*61, 300) # input dim , output dim\n",
    "        self.bn6 = nn.BatchNorm1d(300)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(300,40)  \n",
    "        self.bn7 = nn.BatchNorm1d(40)\n",
    "        self.drop2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(40,4)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = x.view(-1,120*61)\n",
    "        \n",
    "        x = self.drop1(F.relu(self.bn6(self.fc1(x))))\n",
    "        x = self.drop2(F.relu(self.bn7(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter1 | Loss1.9919 | TrainAcc0.0930 | val acc 0.2009\n",
      "Epoch 0 | Iter3 | Loss1.6729 | TrainAcc0.1860 | val acc 0.2600\n",
      "Epoch 0 | Iter5 | Loss1.6541 | TrainAcc0.1628 | val acc 0.2388\n",
      "Epoch 0 | Iter7 | Loss1.4611 | TrainAcc0.3488 | val acc 0.2813\n",
      "Epoch 0 | Iter9 | Loss1.6181 | TrainAcc0.1628 | val acc 0.3050\n",
      "Epoch 0 | Iter11 | Loss1.7692 | TrainAcc0.1628 | val acc 0.2411\n",
      "Epoch 0 | Iter13 | Loss1.5474 | TrainAcc0.2093 | val acc 0.2766\n",
      "Epoch 0 | Iter15 | Loss1.6855 | TrainAcc0.2558 | val acc 0.2884\n",
      "Epoch 0 | Iter17 | Loss1.6633 | TrainAcc0.1163 | val acc 0.2648\n",
      "Epoch 0 | Iter19 | Loss1.5168 | TrainAcc0.1395 | val acc 0.2577\n",
      "Epoch 0 | Iter21 | Loss1.6966 | TrainAcc0.2093 | val acc 0.2600\n",
      "Epoch 0 | Iter23 | Loss1.4779 | TrainAcc0.2326 | val acc 0.2837\n",
      "Epoch 0 | Iter25 | Loss1.4107 | TrainAcc0.2558 | val acc 0.2955\n",
      "Epoch 0 | Iter27 | Loss1.5973 | TrainAcc0.3023 | val acc 0.2766\n",
      "Epoch 0 | Iter29 | Loss1.6599 | TrainAcc0.2326 | val acc 0.2861\n",
      "Epoch 0 | Iter31 | Loss1.5194 | TrainAcc0.2558 | val acc 0.2931\n",
      "Epoch 0 | Iter33 | Loss1.3956 | TrainAcc0.3023 | val acc 0.3026\n",
      "Epoch 0 | Iter35 | Loss1.4622 | TrainAcc0.1860 | val acc 0.3168\n",
      "Epoch 0 | Iter37 | Loss1.5146 | TrainAcc0.2558 | val acc 0.3286\n",
      "Epoch 0 | Iter39 | Loss1.4499 | TrainAcc0.3333 | val acc 0.3357\n",
      "Epoch 1 | Iter1 | Loss1.3782 | TrainAcc0.2558 | val acc 0.2955\n",
      "Epoch 1 | Iter3 | Loss1.4338 | TrainAcc0.1860 | val acc 0.3310\n",
      "Epoch 1 | Iter5 | Loss1.3636 | TrainAcc0.3488 | val acc 0.3310\n",
      "Epoch 1 | Iter7 | Loss1.3408 | TrainAcc0.3953 | val acc 0.3333\n",
      "Epoch 1 | Iter9 | Loss1.5410 | TrainAcc0.1860 | val acc 0.3262\n",
      "Epoch 1 | Iter11 | Loss1.4278 | TrainAcc0.2558 | val acc 0.3121\n",
      "Epoch 1 | Iter13 | Loss1.5346 | TrainAcc0.3256 | val acc 0.3121\n",
      "Epoch 1 | Iter15 | Loss1.4188 | TrainAcc0.3721 | val acc 0.3050\n",
      "Epoch 1 | Iter17 | Loss1.5355 | TrainAcc0.2093 | val acc 0.3026\n",
      "Epoch 1 | Iter19 | Loss1.4881 | TrainAcc0.2558 | val acc 0.3191\n",
      "Epoch 1 | Iter21 | Loss1.3716 | TrainAcc0.3256 | val acc 0.3002\n",
      "Epoch 1 | Iter23 | Loss1.5157 | TrainAcc0.2326 | val acc 0.3097\n",
      "Epoch 1 | Iter25 | Loss1.4259 | TrainAcc0.3488 | val acc 0.2955\n",
      "Epoch 1 | Iter27 | Loss1.3917 | TrainAcc0.2791 | val acc 0.2908\n",
      "Epoch 1 | Iter29 | Loss1.4957 | TrainAcc0.2326 | val acc 0.3073\n",
      "Epoch 1 | Iter31 | Loss1.5289 | TrainAcc0.3256 | val acc 0.2813\n",
      "Epoch 1 | Iter33 | Loss1.3923 | TrainAcc0.2326 | val acc 0.3002\n",
      "Epoch 1 | Iter35 | Loss1.3523 | TrainAcc0.3488 | val acc 0.3073\n",
      "Epoch 1 | Iter37 | Loss1.3976 | TrainAcc0.3488 | val acc 0.3310\n",
      "Epoch 1 | Iter39 | Loss1.3746 | TrainAcc0.1333 | val acc 0.3002\n",
      "Epoch 2 | Iter1 | Loss1.3953 | TrainAcc0.3256 | val acc 0.3191\n",
      "Epoch 2 | Iter3 | Loss1.4687 | TrainAcc0.2093 | val acc 0.3097\n",
      "Epoch 2 | Iter5 | Loss1.3315 | TrainAcc0.3953 | val acc 0.3073\n",
      "Epoch 2 | Iter7 | Loss1.4884 | TrainAcc0.3023 | val acc 0.3215\n",
      "Epoch 2 | Iter9 | Loss1.3843 | TrainAcc0.2791 | val acc 0.2837\n",
      "Epoch 2 | Iter11 | Loss1.4571 | TrainAcc0.2326 | val acc 0.3026\n",
      "Epoch 2 | Iter13 | Loss1.3500 | TrainAcc0.3721 | val acc 0.2931\n",
      "Epoch 2 | Iter15 | Loss1.4168 | TrainAcc0.2791 | val acc 0.2766\n",
      "Epoch 2 | Iter17 | Loss1.2950 | TrainAcc0.3721 | val acc 0.3121\n",
      "Epoch 2 | Iter19 | Loss1.3245 | TrainAcc0.2326 | val acc 0.2931\n",
      "Epoch 2 | Iter21 | Loss1.4491 | TrainAcc0.2791 | val acc 0.3073\n",
      "Epoch 2 | Iter23 | Loss1.4224 | TrainAcc0.3256 | val acc 0.3002\n",
      "Epoch 2 | Iter25 | Loss1.4020 | TrainAcc0.3256 | val acc 0.3073\n",
      "Epoch 2 | Iter27 | Loss1.4946 | TrainAcc0.2791 | val acc 0.3050\n",
      "Epoch 2 | Iter29 | Loss1.3281 | TrainAcc0.3721 | val acc 0.3215\n",
      "Epoch 2 | Iter31 | Loss1.3691 | TrainAcc0.3488 | val acc 0.3262\n",
      "Epoch 2 | Iter33 | Loss1.3762 | TrainAcc0.3256 | val acc 0.3381\n",
      "Epoch 2 | Iter35 | Loss1.4339 | TrainAcc0.1395 | val acc 0.3191\n",
      "Epoch 2 | Iter37 | Loss1.3459 | TrainAcc0.3023 | val acc 0.3262\n",
      "Epoch 2 | Iter39 | Loss1.4753 | TrainAcc0.1333 | val acc 0.3168\n",
      "Epoch 3 | Iter1 | Loss1.3279 | TrainAcc0.3488 | val acc 0.3073\n",
      "Epoch 3 | Iter3 | Loss1.2508 | TrainAcc0.4186 | val acc 0.3050\n",
      "Epoch 3 | Iter5 | Loss1.4744 | TrainAcc0.2791 | val acc 0.2884\n",
      "Epoch 3 | Iter7 | Loss1.3850 | TrainAcc0.3953 | val acc 0.3073\n",
      "Epoch 3 | Iter9 | Loss1.3751 | TrainAcc0.3256 | val acc 0.2861\n",
      "Epoch 3 | Iter11 | Loss1.3714 | TrainAcc0.3256 | val acc 0.2979\n",
      "Epoch 3 | Iter13 | Loss1.2972 | TrainAcc0.3488 | val acc 0.2766\n",
      "Epoch 3 | Iter15 | Loss1.2921 | TrainAcc0.3256 | val acc 0.2908\n",
      "Epoch 3 | Iter17 | Loss1.4222 | TrainAcc0.3256 | val acc 0.2955\n",
      "Epoch 3 | Iter19 | Loss1.3918 | TrainAcc0.3256 | val acc 0.2979\n",
      "Epoch 3 | Iter21 | Loss1.4565 | TrainAcc0.2558 | val acc 0.3191\n",
      "Epoch 3 | Iter23 | Loss1.4600 | TrainAcc0.3256 | val acc 0.3026\n",
      "Epoch 3 | Iter25 | Loss1.3533 | TrainAcc0.2558 | val acc 0.3073\n",
      "Epoch 3 | Iter27 | Loss1.3505 | TrainAcc0.3721 | val acc 0.3641\n",
      "Epoch 3 | Iter29 | Loss1.3691 | TrainAcc0.3023 | val acc 0.3593\n",
      "Epoch 3 | Iter31 | Loss1.3390 | TrainAcc0.3488 | val acc 0.3735\n",
      "Epoch 3 | Iter33 | Loss1.3395 | TrainAcc0.2791 | val acc 0.3546\n",
      "Epoch 3 | Iter35 | Loss1.3518 | TrainAcc0.3256 | val acc 0.3735\n",
      "Epoch 3 | Iter37 | Loss1.5681 | TrainAcc0.2791 | val acc 0.3522\n",
      "Epoch 3 | Iter39 | Loss1.3832 | TrainAcc0.1333 | val acc 0.3522\n",
      "Epoch 4 | Iter1 | Loss1.3074 | TrainAcc0.4186 | val acc 0.3688\n",
      "Epoch 4 | Iter3 | Loss1.3314 | TrainAcc0.4884 | val acc 0.3570\n",
      "Epoch 4 | Iter5 | Loss1.3934 | TrainAcc0.3256 | val acc 0.3428\n",
      "Epoch 4 | Iter7 | Loss1.3426 | TrainAcc0.3488 | val acc 0.3783\n",
      "Epoch 4 | Iter9 | Loss1.3815 | TrainAcc0.3023 | val acc 0.3546\n",
      "Epoch 4 | Iter11 | Loss1.2976 | TrainAcc0.3953 | val acc 0.3806\n",
      "Epoch 4 | Iter13 | Loss1.3533 | TrainAcc0.3488 | val acc 0.3522\n",
      "Epoch 4 | Iter15 | Loss1.3937 | TrainAcc0.3953 | val acc 0.3404\n",
      "Epoch 4 | Iter17 | Loss1.3178 | TrainAcc0.3256 | val acc 0.3475\n",
      "Epoch 4 | Iter19 | Loss1.2351 | TrainAcc0.4651 | val acc 0.3664\n",
      "Epoch 4 | Iter21 | Loss1.2704 | TrainAcc0.4186 | val acc 0.3806\n",
      "Epoch 4 | Iter23 | Loss1.4618 | TrainAcc0.1860 | val acc 0.3357\n",
      "Epoch 4 | Iter25 | Loss1.3941 | TrainAcc0.3256 | val acc 0.4043\n",
      "Epoch 4 | Iter27 | Loss1.3531 | TrainAcc0.3488 | val acc 0.3853\n",
      "Epoch 4 | Iter29 | Loss1.3667 | TrainAcc0.2791 | val acc 0.3806\n",
      "Epoch 4 | Iter31 | Loss1.3893 | TrainAcc0.3256 | val acc 0.3924\n",
      "Epoch 4 | Iter33 | Loss1.3284 | TrainAcc0.3721 | val acc 0.3924\n",
      "Epoch 4 | Iter35 | Loss1.3745 | TrainAcc0.2093 | val acc 0.3806\n",
      "Epoch 4 | Iter37 | Loss1.4149 | TrainAcc0.2791 | val acc 0.3641\n",
      "Epoch 4 | Iter39 | Loss1.1787 | TrainAcc0.4000 | val acc 0.3664\n",
      "Epoch 5 | Iter1 | Loss1.2670 | TrainAcc0.4186 | val acc 0.3452\n",
      "Epoch 5 | Iter3 | Loss1.2997 | TrainAcc0.2558 | val acc 0.3853\n",
      "Epoch 5 | Iter5 | Loss1.3491 | TrainAcc0.3256 | val acc 0.3783\n",
      "Epoch 5 | Iter7 | Loss1.4182 | TrainAcc0.2791 | val acc 0.3948\n",
      "Epoch 5 | Iter9 | Loss1.3303 | TrainAcc0.3256 | val acc 0.3806\n",
      "Epoch 5 | Iter11 | Loss1.2732 | TrainAcc0.3721 | val acc 0.4066\n",
      "Epoch 5 | Iter13 | Loss1.4149 | TrainAcc0.3721 | val acc 0.4090\n",
      "Epoch 5 | Iter15 | Loss1.3142 | TrainAcc0.3023 | val acc 0.3830\n",
      "Epoch 5 | Iter17 | Loss1.2663 | TrainAcc0.3488 | val acc 0.3617\n",
      "Epoch 5 | Iter19 | Loss1.2974 | TrainAcc0.3953 | val acc 0.4043\n",
      "Epoch 5 | Iter21 | Loss1.3505 | TrainAcc0.2558 | val acc 0.4184\n",
      "Epoch 5 | Iter23 | Loss1.3830 | TrainAcc0.3023 | val acc 0.4232\n",
      "Epoch 5 | Iter25 | Loss1.3465 | TrainAcc0.3488 | val acc 0.4279\n",
      "Epoch 5 | Iter27 | Loss1.2966 | TrainAcc0.3721 | val acc 0.4113\n",
      "Epoch 5 | Iter29 | Loss1.3796 | TrainAcc0.2791 | val acc 0.3428\n",
      "Epoch 5 | Iter31 | Loss1.2998 | TrainAcc0.4186 | val acc 0.3972\n",
      "Epoch 5 | Iter33 | Loss1.2213 | TrainAcc0.2791 | val acc 0.3310\n",
      "Epoch 5 | Iter35 | Loss1.2580 | TrainAcc0.4186 | val acc 0.3452\n",
      "Epoch 5 | Iter37 | Loss1.2525 | TrainAcc0.4884 | val acc 0.3428\n",
      "Epoch 5 | Iter39 | Loss1.3870 | TrainAcc0.2667 | val acc 0.4019\n",
      "Epoch 6 | Iter1 | Loss1.3251 | TrainAcc0.3488 | val acc 0.3853\n",
      "Epoch 6 | Iter3 | Loss1.2187 | TrainAcc0.3721 | val acc 0.4208\n",
      "Epoch 6 | Iter5 | Loss1.2019 | TrainAcc0.5814 | val acc 0.4113\n",
      "Epoch 6 | Iter7 | Loss1.2085 | TrainAcc0.3488 | val acc 0.4397\n",
      "Epoch 6 | Iter9 | Loss1.2259 | TrainAcc0.5116 | val acc 0.4279\n",
      "Epoch 6 | Iter11 | Loss1.2754 | TrainAcc0.3721 | val acc 0.4350\n",
      "Epoch 6 | Iter13 | Loss1.3209 | TrainAcc0.4186 | val acc 0.4066\n",
      "Epoch 6 | Iter15 | Loss1.2729 | TrainAcc0.3256 | val acc 0.4137\n",
      "Epoch 6 | Iter17 | Loss1.2404 | TrainAcc0.3953 | val acc 0.4113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Iter19 | Loss1.2723 | TrainAcc0.3721 | val acc 0.4255\n",
      "Epoch 6 | Iter21 | Loss1.2693 | TrainAcc0.4186 | val acc 0.4184\n",
      "Epoch 6 | Iter23 | Loss1.2603 | TrainAcc0.3953 | val acc 0.4326\n",
      "Epoch 6 | Iter25 | Loss1.2670 | TrainAcc0.5116 | val acc 0.3853\n",
      "Epoch 6 | Iter27 | Loss1.2675 | TrainAcc0.3953 | val acc 0.4255\n",
      "Epoch 6 | Iter29 | Loss1.2889 | TrainAcc0.3488 | val acc 0.4184\n",
      "Epoch 6 | Iter31 | Loss1.3528 | TrainAcc0.4651 | val acc 0.4208\n",
      "Epoch 6 | Iter33 | Loss1.3524 | TrainAcc0.3953 | val acc 0.4137\n",
      "Epoch 6 | Iter35 | Loss1.2672 | TrainAcc0.4884 | val acc 0.4184\n",
      "Epoch 6 | Iter37 | Loss1.2584 | TrainAcc0.3721 | val acc 0.4255\n",
      "Epoch 6 | Iter39 | Loss1.1974 | TrainAcc0.4000 | val acc 0.4161\n",
      "Epoch 7 | Iter1 | Loss1.1803 | TrainAcc0.4651 | val acc 0.4326\n",
      "Epoch 7 | Iter3 | Loss1.1941 | TrainAcc0.4419 | val acc 0.4090\n",
      "Epoch 7 | Iter5 | Loss1.2093 | TrainAcc0.4186 | val acc 0.3877\n",
      "Epoch 7 | Iter7 | Loss1.1759 | TrainAcc0.5116 | val acc 0.4161\n",
      "Epoch 7 | Iter9 | Loss1.1541 | TrainAcc0.4186 | val acc 0.4066\n",
      "Epoch 7 | Iter11 | Loss1.2109 | TrainAcc0.4651 | val acc 0.4232\n",
      "Epoch 7 | Iter13 | Loss1.2416 | TrainAcc0.3953 | val acc 0.4208\n",
      "Epoch 7 | Iter15 | Loss1.2601 | TrainAcc0.3953 | val acc 0.3948\n",
      "Epoch 7 | Iter17 | Loss1.3084 | TrainAcc0.4186 | val acc 0.3428\n",
      "Epoch 7 | Iter19 | Loss1.2546 | TrainAcc0.4186 | val acc 0.4137\n",
      "Epoch 7 | Iter21 | Loss1.1298 | TrainAcc0.4651 | val acc 0.4161\n",
      "Epoch 7 | Iter23 | Loss1.2548 | TrainAcc0.4419 | val acc 0.3262\n",
      "Epoch 7 | Iter25 | Loss1.2937 | TrainAcc0.3721 | val acc 0.4350\n",
      "Epoch 7 | Iter27 | Loss1.2919 | TrainAcc0.4419 | val acc 0.4255\n",
      "Epoch 7 | Iter29 | Loss1.2882 | TrainAcc0.3721 | val acc 0.3877\n",
      "Epoch 7 | Iter31 | Loss1.1270 | TrainAcc0.5814 | val acc 0.4610\n",
      "Epoch 7 | Iter33 | Loss1.4260 | TrainAcc0.2791 | val acc 0.4255\n",
      "Epoch 7 | Iter35 | Loss1.1800 | TrainAcc0.5116 | val acc 0.3948\n",
      "Epoch 7 | Iter37 | Loss1.1632 | TrainAcc0.4884 | val acc 0.3948\n",
      "Epoch 7 | Iter39 | Loss1.3373 | TrainAcc0.2667 | val acc 0.3972\n",
      "Epoch 8 | Iter1 | Loss1.1463 | TrainAcc0.5349 | val acc 0.4066\n",
      "Epoch 8 | Iter3 | Loss1.1627 | TrainAcc0.4651 | val acc 0.4232\n",
      "Epoch 8 | Iter5 | Loss1.1753 | TrainAcc0.5116 | val acc 0.3664\n",
      "Epoch 8 | Iter7 | Loss1.1864 | TrainAcc0.5349 | val acc 0.3853\n",
      "Epoch 8 | Iter9 | Loss1.3262 | TrainAcc0.3721 | val acc 0.3641\n",
      "Epoch 8 | Iter11 | Loss1.2319 | TrainAcc0.4419 | val acc 0.4350\n",
      "Epoch 8 | Iter13 | Loss1.1807 | TrainAcc0.5116 | val acc 0.3735\n",
      "Epoch 8 | Iter15 | Loss1.2268 | TrainAcc0.4419 | val acc 0.3522\n",
      "Epoch 8 | Iter17 | Loss1.1767 | TrainAcc0.3953 | val acc 0.4421\n",
      "Epoch 8 | Iter19 | Loss1.2853 | TrainAcc0.3721 | val acc 0.4090\n",
      "Epoch 8 | Iter21 | Loss1.1206 | TrainAcc0.5349 | val acc 0.4279\n",
      "Epoch 8 | Iter23 | Loss1.1811 | TrainAcc0.4419 | val acc 0.4279\n",
      "Epoch 8 | Iter25 | Loss1.3643 | TrainAcc0.2791 | val acc 0.4468\n",
      "Epoch 8 | Iter27 | Loss1.1218 | TrainAcc0.4186 | val acc 0.4303\n",
      "Epoch 8 | Iter29 | Loss1.1429 | TrainAcc0.5349 | val acc 0.3972\n",
      "Epoch 8 | Iter31 | Loss1.1944 | TrainAcc0.4186 | val acc 0.4184\n",
      "Epoch 8 | Iter33 | Loss1.1475 | TrainAcc0.4651 | val acc 0.4539\n",
      "Epoch 8 | Iter35 | Loss1.1273 | TrainAcc0.5581 | val acc 0.4090\n",
      "Epoch 8 | Iter37 | Loss1.1708 | TrainAcc0.3953 | val acc 0.4161\n",
      "Epoch 8 | Iter39 | Loss1.1788 | TrainAcc0.3333 | val acc 0.4492\n",
      "Epoch 9 | Iter1 | Loss1.2450 | TrainAcc0.5116 | val acc 0.4279\n",
      "Epoch 9 | Iter3 | Loss1.0588 | TrainAcc0.6047 | val acc 0.4208\n",
      "Epoch 9 | Iter5 | Loss1.2164 | TrainAcc0.3256 | val acc 0.4303\n",
      "Epoch 9 | Iter7 | Loss1.1141 | TrainAcc0.5581 | val acc 0.4066\n",
      "Epoch 9 | Iter9 | Loss1.0757 | TrainAcc0.6047 | val acc 0.4350\n",
      "Epoch 9 | Iter11 | Loss1.0479 | TrainAcc0.5581 | val acc 0.4350\n",
      "Epoch 9 | Iter13 | Loss1.1630 | TrainAcc0.4651 | val acc 0.4444\n",
      "Epoch 9 | Iter15 | Loss1.0588 | TrainAcc0.4651 | val acc 0.4326\n",
      "Epoch 9 | Iter17 | Loss1.1255 | TrainAcc0.4419 | val acc 0.4397\n",
      "Epoch 9 | Iter19 | Loss1.1339 | TrainAcc0.4186 | val acc 0.3735\n",
      "Epoch 9 | Iter21 | Loss1.1797 | TrainAcc0.3721 | val acc 0.4232\n",
      "Epoch 9 | Iter23 | Loss1.2194 | TrainAcc0.4884 | val acc 0.3759\n",
      "Epoch 9 | Iter25 | Loss1.1177 | TrainAcc0.5814 | val acc 0.3948\n",
      "Epoch 9 | Iter27 | Loss1.2169 | TrainAcc0.4651 | val acc 0.4350\n",
      "Epoch 9 | Iter29 | Loss1.0672 | TrainAcc0.3721 | val acc 0.4090\n",
      "Epoch 9 | Iter31 | Loss1.0932 | TrainAcc0.6047 | val acc 0.4113\n",
      "Epoch 9 | Iter33 | Loss1.1641 | TrainAcc0.4884 | val acc 0.4208\n",
      "Epoch 9 | Iter35 | Loss1.1325 | TrainAcc0.5116 | val acc 0.4326\n",
      "Epoch 9 | Iter37 | Loss1.1239 | TrainAcc0.4186 | val acc 0.4232\n",
      "Epoch 9 | Iter39 | Loss0.9866 | TrainAcc0.6000 | val acc 0.4113\n",
      "Epoch 10 | Iter1 | Loss1.0583 | TrainAcc0.5814 | val acc 0.4515\n",
      "Epoch 10 | Iter3 | Loss1.0131 | TrainAcc0.6047 | val acc 0.4563\n",
      "Epoch 10 | Iter5 | Loss1.1109 | TrainAcc0.5116 | val acc 0.4303\n",
      "Epoch 10 | Iter7 | Loss0.9861 | TrainAcc0.6047 | val acc 0.4232\n",
      "Epoch 10 | Iter9 | Loss1.1614 | TrainAcc0.5116 | val acc 0.4468\n",
      "Epoch 10 | Iter11 | Loss1.1899 | TrainAcc0.4651 | val acc 0.4255\n",
      "Epoch 10 | Iter13 | Loss1.0588 | TrainAcc0.5814 | val acc 0.4539\n",
      "Epoch 10 | Iter15 | Loss1.1510 | TrainAcc0.4419 | val acc 0.4657\n",
      "Epoch 10 | Iter17 | Loss1.2920 | TrainAcc0.4186 | val acc 0.3853\n",
      "Epoch 10 | Iter19 | Loss1.1593 | TrainAcc0.4651 | val acc 0.4444\n",
      "Epoch 10 | Iter21 | Loss1.1135 | TrainAcc0.4186 | val acc 0.4468\n",
      "Epoch 10 | Iter23 | Loss1.1024 | TrainAcc0.4884 | val acc 0.4586\n",
      "Epoch 10 | Iter25 | Loss1.1672 | TrainAcc0.5581 | val acc 0.4610\n",
      "Epoch 10 | Iter27 | Loss0.9676 | TrainAcc0.6279 | val acc 0.4870\n",
      "Epoch 10 | Iter29 | Loss1.2526 | TrainAcc0.4186 | val acc 0.4255\n",
      "Epoch 10 | Iter31 | Loss1.1272 | TrainAcc0.5581 | val acc 0.4397\n",
      "Epoch 10 | Iter33 | Loss1.1087 | TrainAcc0.4884 | val acc 0.4279\n",
      "Epoch 10 | Iter35 | Loss1.2278 | TrainAcc0.5349 | val acc 0.4539\n",
      "Epoch 10 | Iter37 | Loss1.0131 | TrainAcc0.6512 | val acc 0.4468\n",
      "Epoch 10 | Iter39 | Loss1.3132 | TrainAcc0.2667 | val acc 0.4113\n",
      "Epoch 11 | Iter1 | Loss1.2696 | TrainAcc0.3721 | val acc 0.4421\n",
      "Epoch 11 | Iter3 | Loss1.0706 | TrainAcc0.5581 | val acc 0.4515\n",
      "Epoch 11 | Iter5 | Loss1.1049 | TrainAcc0.5581 | val acc 0.4444\n",
      "Epoch 11 | Iter7 | Loss0.9997 | TrainAcc0.6279 | val acc 0.4492\n",
      "Epoch 11 | Iter9 | Loss1.0692 | TrainAcc0.5116 | val acc 0.3806\n",
      "Epoch 11 | Iter11 | Loss0.9981 | TrainAcc0.5814 | val acc 0.4421\n",
      "Epoch 11 | Iter13 | Loss1.0059 | TrainAcc0.6047 | val acc 0.4610\n",
      "Epoch 11 | Iter15 | Loss0.9656 | TrainAcc0.6744 | val acc 0.4728\n",
      "Epoch 11 | Iter17 | Loss1.0412 | TrainAcc0.5581 | val acc 0.4610\n",
      "Epoch 11 | Iter19 | Loss1.1307 | TrainAcc0.5349 | val acc 0.4208\n",
      "Epoch 11 | Iter21 | Loss1.2239 | TrainAcc0.4884 | val acc 0.4374\n",
      "Epoch 11 | Iter23 | Loss1.0774 | TrainAcc0.4651 | val acc 0.4586\n",
      "Epoch 11 | Iter25 | Loss1.1649 | TrainAcc0.5349 | val acc 0.4563\n",
      "Epoch 11 | Iter27 | Loss1.0858 | TrainAcc0.4884 | val acc 0.4303\n",
      "Epoch 11 | Iter29 | Loss1.0508 | TrainAcc0.5349 | val acc 0.4634\n",
      "Epoch 11 | Iter31 | Loss1.0716 | TrainAcc0.4419 | val acc 0.4090\n",
      "Epoch 11 | Iter33 | Loss1.0371 | TrainAcc0.5349 | val acc 0.4846\n",
      "Epoch 11 | Iter35 | Loss0.9534 | TrainAcc0.5349 | val acc 0.4492\n",
      "Epoch 11 | Iter37 | Loss1.0837 | TrainAcc0.4186 | val acc 0.4823\n",
      "Epoch 11 | Iter39 | Loss0.7963 | TrainAcc0.6667 | val acc 0.4444\n",
      "Epoch 12 | Iter1 | Loss1.0951 | TrainAcc0.5814 | val acc 0.4137\n",
      "Epoch 12 | Iter3 | Loss1.0033 | TrainAcc0.4884 | val acc 0.4279\n",
      "Epoch 12 | Iter5 | Loss0.9335 | TrainAcc0.6279 | val acc 0.4350\n",
      "Epoch 12 | Iter7 | Loss1.0317 | TrainAcc0.5814 | val acc 0.4752\n",
      "Epoch 12 | Iter9 | Loss0.9462 | TrainAcc0.5814 | val acc 0.4492\n",
      "Epoch 12 | Iter11 | Loss1.2324 | TrainAcc0.5581 | val acc 0.4019\n",
      "Epoch 12 | Iter13 | Loss1.0278 | TrainAcc0.6047 | val acc 0.4634\n",
      "Epoch 12 | Iter15 | Loss1.1187 | TrainAcc0.6279 | val acc 0.4043\n",
      "Epoch 12 | Iter17 | Loss1.0421 | TrainAcc0.5814 | val acc 0.4326\n",
      "Epoch 12 | Iter19 | Loss1.1198 | TrainAcc0.6279 | val acc 0.4610\n",
      "Epoch 12 | Iter21 | Loss1.2603 | TrainAcc0.3721 | val acc 0.4326\n",
      "Epoch 12 | Iter23 | Loss1.0820 | TrainAcc0.4651 | val acc 0.4752\n",
      "Epoch 12 | Iter25 | Loss1.0418 | TrainAcc0.5814 | val acc 0.3712\n",
      "Epoch 12 | Iter27 | Loss1.0677 | TrainAcc0.5814 | val acc 0.4492\n",
      "Epoch 12 | Iter29 | Loss1.0637 | TrainAcc0.5814 | val acc 0.4279\n",
      "Epoch 12 | Iter31 | Loss1.0541 | TrainAcc0.5814 | val acc 0.3499\n",
      "Epoch 12 | Iter33 | Loss1.0841 | TrainAcc0.5814 | val acc 0.4563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Iter35 | Loss0.9588 | TrainAcc0.6512 | val acc 0.4681\n",
      "Epoch 12 | Iter37 | Loss1.0947 | TrainAcc0.4884 | val acc 0.4704\n",
      "Epoch 12 | Iter39 | Loss1.0281 | TrainAcc0.7333 | val acc 0.4704\n",
      "Epoch 13 | Iter1 | Loss0.9612 | TrainAcc0.6047 | val acc 0.4563\n",
      "Epoch 13 | Iter3 | Loss0.9357 | TrainAcc0.6279 | val acc 0.4586\n",
      "Epoch 13 | Iter5 | Loss1.1393 | TrainAcc0.5581 | val acc 0.4634\n",
      "Epoch 13 | Iter7 | Loss0.9503 | TrainAcc0.5814 | val acc 0.4539\n",
      "Epoch 13 | Iter9 | Loss0.9623 | TrainAcc0.6512 | val acc 0.4586\n",
      "Epoch 13 | Iter11 | Loss1.0225 | TrainAcc0.6047 | val acc 0.3948\n",
      "Epoch 13 | Iter13 | Loss0.8055 | TrainAcc0.6744 | val acc 0.4208\n",
      "Epoch 13 | Iter15 | Loss0.9930 | TrainAcc0.5814 | val acc 0.4515\n",
      "Epoch 13 | Iter17 | Loss0.8852 | TrainAcc0.6279 | val acc 0.4232\n",
      "Epoch 13 | Iter19 | Loss0.9262 | TrainAcc0.6279 | val acc 0.4634\n",
      "Epoch 13 | Iter21 | Loss1.0429 | TrainAcc0.5581 | val acc 0.4563\n",
      "Epoch 13 | Iter23 | Loss1.2567 | TrainAcc0.4186 | val acc 0.4610\n",
      "Epoch 13 | Iter25 | Loss1.0234 | TrainAcc0.5349 | val acc 0.4681\n",
      "Epoch 13 | Iter27 | Loss0.9888 | TrainAcc0.5581 | val acc 0.4657\n",
      "Epoch 13 | Iter29 | Loss1.0689 | TrainAcc0.4884 | val acc 0.4728\n",
      "Epoch 13 | Iter31 | Loss0.9599 | TrainAcc0.5814 | val acc 0.4634\n",
      "Epoch 13 | Iter33 | Loss0.9138 | TrainAcc0.6279 | val acc 0.4681\n",
      "Epoch 13 | Iter35 | Loss0.9556 | TrainAcc0.6512 | val acc 0.4657\n",
      "Epoch 13 | Iter37 | Loss0.9330 | TrainAcc0.5581 | val acc 0.4657\n",
      "Epoch 13 | Iter39 | Loss1.2494 | TrainAcc0.3333 | val acc 0.4610\n",
      "Epoch 14 | Iter1 | Loss1.0153 | TrainAcc0.4884 | val acc 0.4728\n",
      "Epoch 14 | Iter3 | Loss0.9461 | TrainAcc0.6977 | val acc 0.4941\n",
      "Epoch 14 | Iter5 | Loss1.0697 | TrainAcc0.4884 | val acc 0.4492\n",
      "Epoch 14 | Iter7 | Loss1.0421 | TrainAcc0.5349 | val acc 0.4232\n",
      "Epoch 14 | Iter9 | Loss1.0522 | TrainAcc0.4884 | val acc 0.3924\n",
      "Epoch 14 | Iter11 | Loss0.8959 | TrainAcc0.6977 | val acc 0.4326\n",
      "Epoch 14 | Iter13 | Loss0.9833 | TrainAcc0.6047 | val acc 0.4374\n",
      "Epoch 14 | Iter15 | Loss0.8250 | TrainAcc0.7209 | val acc 0.4468\n",
      "Epoch 14 | Iter17 | Loss0.9619 | TrainAcc0.6279 | val acc 0.4563\n",
      "Epoch 14 | Iter19 | Loss0.8874 | TrainAcc0.6977 | val acc 0.4823\n",
      "Epoch 14 | Iter21 | Loss1.1540 | TrainAcc0.3488 | val acc 0.4704\n",
      "Epoch 14 | Iter23 | Loss1.0300 | TrainAcc0.5814 | val acc 0.4586\n",
      "Epoch 14 | Iter25 | Loss1.1679 | TrainAcc0.5814 | val acc 0.4515\n",
      "Epoch 14 | Iter27 | Loss1.0074 | TrainAcc0.6512 | val acc 0.4208\n",
      "Epoch 14 | Iter29 | Loss0.9814 | TrainAcc0.6279 | val acc 0.4657\n",
      "Epoch 14 | Iter31 | Loss0.8897 | TrainAcc0.6744 | val acc 0.4894\n",
      "Epoch 14 | Iter33 | Loss0.8188 | TrainAcc0.6977 | val acc 0.4728\n",
      "Epoch 14 | Iter35 | Loss1.1251 | TrainAcc0.3953 | val acc 0.4421\n",
      "Epoch 14 | Iter37 | Loss0.8462 | TrainAcc0.6977 | val acc 0.4586\n",
      "Epoch 14 | Iter39 | Loss1.1835 | TrainAcc0.4667 | val acc 0.4563\n",
      "Epoch 15 | Iter1 | Loss0.9294 | TrainAcc0.6512 | val acc 0.4775\n",
      "Epoch 15 | Iter3 | Loss1.0408 | TrainAcc0.6512 | val acc 0.4752\n",
      "Epoch 15 | Iter5 | Loss0.9109 | TrainAcc0.5814 | val acc 0.4846\n",
      "Epoch 15 | Iter7 | Loss0.9402 | TrainAcc0.5814 | val acc 0.4350\n",
      "Epoch 15 | Iter9 | Loss0.8524 | TrainAcc0.6047 | val acc 0.4279\n",
      "Epoch 15 | Iter11 | Loss0.8087 | TrainAcc0.6744 | val acc 0.4704\n",
      "Epoch 15 | Iter13 | Loss0.7934 | TrainAcc0.6744 | val acc 0.4681\n",
      "Epoch 15 | Iter15 | Loss0.7416 | TrainAcc0.7209 | val acc 0.4752\n",
      "Epoch 15 | Iter17 | Loss0.8535 | TrainAcc0.6512 | val acc 0.4539\n",
      "Epoch 15 | Iter19 | Loss0.8942 | TrainAcc0.6512 | val acc 0.4444\n",
      "Epoch 15 | Iter21 | Loss0.8675 | TrainAcc0.5814 | val acc 0.4350\n",
      "Epoch 15 | Iter23 | Loss0.9451 | TrainAcc0.5349 | val acc 0.4350\n",
      "Epoch 15 | Iter25 | Loss0.8932 | TrainAcc0.6977 | val acc 0.4657\n",
      "Epoch 15 | Iter27 | Loss0.9763 | TrainAcc0.5581 | val acc 0.4397\n",
      "Epoch 15 | Iter29 | Loss0.9708 | TrainAcc0.6279 | val acc 0.4704\n",
      "Epoch 15 | Iter31 | Loss1.1515 | TrainAcc0.4884 | val acc 0.3712\n",
      "Epoch 15 | Iter33 | Loss0.7748 | TrainAcc0.6512 | val acc 0.4539\n",
      "Epoch 15 | Iter35 | Loss0.9728 | TrainAcc0.5349 | val acc 0.4468\n",
      "Epoch 15 | Iter37 | Loss0.8511 | TrainAcc0.6744 | val acc 0.4539\n",
      "Epoch 15 | Iter39 | Loss1.0895 | TrainAcc0.5333 | val acc 0.4043\n",
      "Epoch 16 | Iter1 | Loss1.0542 | TrainAcc0.4884 | val acc 0.4563\n",
      "Epoch 16 | Iter3 | Loss1.0685 | TrainAcc0.6047 | val acc 0.4988\n",
      "Epoch 16 | Iter5 | Loss0.9505 | TrainAcc0.4186 | val acc 0.4184\n",
      "Epoch 16 | Iter7 | Loss0.8117 | TrainAcc0.6279 | val acc 0.4444\n",
      "Epoch 16 | Iter9 | Loss0.8428 | TrainAcc0.6977 | val acc 0.4374\n",
      "Epoch 16 | Iter11 | Loss0.6865 | TrainAcc0.7674 | val acc 0.4634\n",
      "Epoch 16 | Iter13 | Loss0.7306 | TrainAcc0.6279 | val acc 0.4941\n",
      "Epoch 16 | Iter15 | Loss0.8514 | TrainAcc0.6512 | val acc 0.4894\n",
      "Epoch 16 | Iter17 | Loss0.7789 | TrainAcc0.6512 | val acc 0.4704\n",
      "Epoch 16 | Iter19 | Loss0.8901 | TrainAcc0.6047 | val acc 0.4941\n",
      "Epoch 16 | Iter21 | Loss0.8216 | TrainAcc0.5814 | val acc 0.4988\n",
      "Epoch 16 | Iter23 | Loss0.7922 | TrainAcc0.7442 | val acc 0.4728\n",
      "Epoch 16 | Iter25 | Loss0.7627 | TrainAcc0.6977 | val acc 0.4799\n",
      "Epoch 16 | Iter27 | Loss0.8216 | TrainAcc0.6977 | val acc 0.4894\n",
      "Epoch 16 | Iter29 | Loss0.9057 | TrainAcc0.5814 | val acc 0.4965\n",
      "Epoch 16 | Iter31 | Loss0.7899 | TrainAcc0.6977 | val acc 0.4255\n",
      "Epoch 16 | Iter33 | Loss0.9948 | TrainAcc0.5349 | val acc 0.4846\n",
      "Epoch 16 | Iter35 | Loss0.8455 | TrainAcc0.6279 | val acc 0.4539\n",
      "Epoch 16 | Iter37 | Loss0.8184 | TrainAcc0.5581 | val acc 0.4846\n",
      "Epoch 16 | Iter39 | Loss1.2154 | TrainAcc0.6667 | val acc 0.3333\n",
      "Epoch 17 | Iter1 | Loss0.8949 | TrainAcc0.5581 | val acc 0.3641\n",
      "Epoch 17 | Iter3 | Loss0.8006 | TrainAcc0.7209 | val acc 0.3972\n",
      "Epoch 17 | Iter5 | Loss0.7674 | TrainAcc0.7674 | val acc 0.4634\n",
      "Epoch 17 | Iter7 | Loss0.6865 | TrainAcc0.7209 | val acc 0.4657\n",
      "Epoch 17 | Iter9 | Loss0.8694 | TrainAcc0.6512 | val acc 0.4752\n",
      "Epoch 17 | Iter11 | Loss0.7630 | TrainAcc0.6977 | val acc 0.4775\n",
      "Epoch 17 | Iter13 | Loss0.8307 | TrainAcc0.6744 | val acc 0.4657\n",
      "Epoch 17 | Iter15 | Loss0.7112 | TrainAcc0.7209 | val acc 0.4752\n",
      "Epoch 17 | Iter17 | Loss0.9460 | TrainAcc0.5814 | val acc 0.4917\n",
      "Epoch 17 | Iter19 | Loss0.8743 | TrainAcc0.5814 | val acc 0.4752\n",
      "Epoch 17 | Iter21 | Loss0.6191 | TrainAcc0.7209 | val acc 0.4681\n",
      "Epoch 17 | Iter23 | Loss0.7967 | TrainAcc0.6512 | val acc 0.4704\n",
      "Epoch 17 | Iter25 | Loss0.7487 | TrainAcc0.6977 | val acc 0.4610\n",
      "Epoch 17 | Iter27 | Loss0.7174 | TrainAcc0.7674 | val acc 0.4846\n",
      "Epoch 17 | Iter29 | Loss0.6871 | TrainAcc0.7209 | val acc 0.4728\n",
      "Epoch 17 | Iter31 | Loss0.7206 | TrainAcc0.7209 | val acc 0.5012\n",
      "Epoch 17 | Iter33 | Loss0.8951 | TrainAcc0.5814 | val acc 0.4397\n",
      "Epoch 17 | Iter35 | Loss1.3328 | TrainAcc0.4884 | val acc 0.4515\n",
      "Epoch 17 | Iter37 | Loss0.7593 | TrainAcc0.6279 | val acc 0.4799\n",
      "Epoch 17 | Iter39 | Loss0.9425 | TrainAcc0.6000 | val acc 0.4397\n",
      "Epoch 18 | Iter1 | Loss0.8176 | TrainAcc0.7209 | val acc 0.4634\n",
      "Epoch 18 | Iter3 | Loss0.8345 | TrainAcc0.5814 | val acc 0.4421\n",
      "Epoch 18 | Iter5 | Loss0.6910 | TrainAcc0.6977 | val acc 0.4988\n",
      "Epoch 18 | Iter7 | Loss0.9158 | TrainAcc0.5349 | val acc 0.4468\n",
      "Epoch 18 | Iter9 | Loss0.8554 | TrainAcc0.6047 | val acc 0.4775\n",
      "Epoch 18 | Iter11 | Loss0.7213 | TrainAcc0.5814 | val acc 0.4941\n",
      "Epoch 18 | Iter13 | Loss0.8135 | TrainAcc0.6047 | val acc 0.4634\n",
      "Epoch 18 | Iter15 | Loss0.8189 | TrainAcc0.6279 | val acc 0.4374\n",
      "Epoch 18 | Iter17 | Loss0.7948 | TrainAcc0.6512 | val acc 0.4421\n",
      "Epoch 18 | Iter19 | Loss0.9519 | TrainAcc0.5581 | val acc 0.4066\n",
      "Epoch 18 | Iter21 | Loss0.6988 | TrainAcc0.6744 | val acc 0.4515\n",
      "Epoch 18 | Iter23 | Loss0.7720 | TrainAcc0.6744 | val acc 0.4846\n",
      "Epoch 18 | Iter25 | Loss0.8850 | TrainAcc0.6047 | val acc 0.4634\n",
      "Epoch 18 | Iter27 | Loss0.9087 | TrainAcc0.5349 | val acc 0.4965\n",
      "Epoch 18 | Iter29 | Loss0.7292 | TrainAcc0.7674 | val acc 0.4799\n",
      "Epoch 18 | Iter31 | Loss0.7201 | TrainAcc0.6744 | val acc 0.4941\n",
      "Epoch 18 | Iter33 | Loss0.6281 | TrainAcc0.7674 | val acc 0.4965\n",
      "Epoch 18 | Iter35 | Loss0.7285 | TrainAcc0.6279 | val acc 0.4799\n",
      "Epoch 18 | Iter37 | Loss0.7422 | TrainAcc0.6744 | val acc 0.4704\n",
      "Epoch 18 | Iter39 | Loss0.8229 | TrainAcc0.6000 | val acc 0.4752\n",
      "Epoch 19 | Iter1 | Loss0.8693 | TrainAcc0.4884 | val acc 0.4515\n",
      "Epoch 19 | Iter3 | Loss0.7152 | TrainAcc0.7209 | val acc 0.4752\n",
      "Epoch 19 | Iter5 | Loss0.7355 | TrainAcc0.7674 | val acc 0.4515\n",
      "Epoch 19 | Iter7 | Loss0.7191 | TrainAcc0.7442 | val acc 0.4752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Iter9 | Loss0.8057 | TrainAcc0.6279 | val acc 0.4492\n",
      "Epoch 19 | Iter11 | Loss0.7124 | TrainAcc0.7209 | val acc 0.4444\n",
      "Epoch 19 | Iter13 | Loss0.8416 | TrainAcc0.6279 | val acc 0.4846\n",
      "Epoch 19 | Iter15 | Loss0.7403 | TrainAcc0.6744 | val acc 0.4681\n",
      "Epoch 19 | Iter17 | Loss0.7241 | TrainAcc0.7674 | val acc 0.4846\n",
      "Epoch 19 | Iter19 | Loss0.6961 | TrainAcc0.6977 | val acc 0.4846\n",
      "Epoch 19 | Iter21 | Loss0.7358 | TrainAcc0.7674 | val acc 0.4775\n",
      "Epoch 19 | Iter23 | Loss0.8952 | TrainAcc0.6512 | val acc 0.4870\n",
      "Epoch 19 | Iter25 | Loss0.8694 | TrainAcc0.6744 | val acc 0.3924\n",
      "Epoch 19 | Iter27 | Loss0.9044 | TrainAcc0.5814 | val acc 0.4397\n",
      "Epoch 19 | Iter29 | Loss0.8216 | TrainAcc0.6279 | val acc 0.4586\n",
      "Epoch 19 | Iter31 | Loss0.7092 | TrainAcc0.6744 | val acc 0.4894\n",
      "Epoch 19 | Iter33 | Loss0.6350 | TrainAcc0.7209 | val acc 0.4965\n",
      "Epoch 19 | Iter35 | Loss0.8394 | TrainAcc0.6744 | val acc 0.4917\n",
      "Epoch 19 | Iter37 | Loss0.7641 | TrainAcc0.6512 | val acc 0.4563\n",
      "Epoch 19 | Iter39 | Loss0.7850 | TrainAcc0.5333 | val acc 0.4846\n",
      "Epoch 20 | Iter1 | Loss0.6415 | TrainAcc0.7907 | val acc 0.4563\n",
      "Epoch 20 | Iter3 | Loss0.8462 | TrainAcc0.6744 | val acc 0.4799\n",
      "Epoch 20 | Iter5 | Loss0.7600 | TrainAcc0.6512 | val acc 0.4634\n",
      "Epoch 20 | Iter7 | Loss0.6585 | TrainAcc0.7209 | val acc 0.4728\n",
      "Epoch 20 | Iter9 | Loss0.6813 | TrainAcc0.7907 | val acc 0.4704\n",
      "Epoch 20 | Iter11 | Loss0.6898 | TrainAcc0.6744 | val acc 0.4586\n",
      "Epoch 20 | Iter13 | Loss0.7447 | TrainAcc0.6512 | val acc 0.4610\n",
      "Epoch 20 | Iter15 | Loss0.7406 | TrainAcc0.6977 | val acc 0.4634\n",
      "Epoch 20 | Iter17 | Loss0.7320 | TrainAcc0.6279 | val acc 0.4326\n",
      "Epoch 20 | Iter19 | Loss0.6333 | TrainAcc0.7209 | val acc 0.4279\n",
      "Epoch 20 | Iter21 | Loss0.9724 | TrainAcc0.5349 | val acc 0.4681\n",
      "Epoch 20 | Iter23 | Loss0.7147 | TrainAcc0.7209 | val acc 0.4681\n",
      "Epoch 20 | Iter25 | Loss0.6440 | TrainAcc0.6744 | val acc 0.4539\n",
      "Epoch 20 | Iter27 | Loss0.7255 | TrainAcc0.6512 | val acc 0.4326\n",
      "Epoch 20 | Iter29 | Loss1.0264 | TrainAcc0.5116 | val acc 0.4374\n",
      "Epoch 20 | Iter31 | Loss0.8013 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 20 | Iter33 | Loss0.9740 | TrainAcc0.6279 | val acc 0.4704\n",
      "Epoch 20 | Iter35 | Loss0.7315 | TrainAcc0.6977 | val acc 0.4728\n",
      "Epoch 20 | Iter37 | Loss0.7570 | TrainAcc0.6047 | val acc 0.4775\n",
      "Epoch 20 | Iter39 | Loss0.6656 | TrainAcc0.6667 | val acc 0.4775\n",
      "Epoch 21 | Iter1 | Loss0.6241 | TrainAcc0.8140 | val acc 0.4775\n",
      "Epoch 21 | Iter3 | Loss0.7581 | TrainAcc0.6977 | val acc 0.4775\n",
      "Epoch 21 | Iter5 | Loss0.7245 | TrainAcc0.7442 | val acc 0.4752\n",
      "Epoch 21 | Iter7 | Loss0.6815 | TrainAcc0.6744 | val acc 0.4728\n",
      "Epoch 21 | Iter9 | Loss0.6209 | TrainAcc0.7209 | val acc 0.4704\n",
      "Epoch 21 | Iter11 | Loss0.6776 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 21 | Iter13 | Loss0.8146 | TrainAcc0.6512 | val acc 0.4634\n",
      "Epoch 21 | Iter15 | Loss0.7056 | TrainAcc0.6512 | val acc 0.4775\n",
      "Epoch 21 | Iter17 | Loss0.5861 | TrainAcc0.7442 | val acc 0.4704\n",
      "Epoch 21 | Iter19 | Loss0.6196 | TrainAcc0.8605 | val acc 0.4350\n",
      "Epoch 21 | Iter21 | Loss0.5564 | TrainAcc0.7442 | val acc 0.4586\n",
      "Epoch 21 | Iter23 | Loss0.6069 | TrainAcc0.6744 | val acc 0.4586\n",
      "Epoch 21 | Iter25 | Loss0.7797 | TrainAcc0.5814 | val acc 0.4563\n",
      "Epoch 21 | Iter27 | Loss0.7045 | TrainAcc0.7674 | val acc 0.4657\n",
      "Epoch 21 | Iter29 | Loss0.6696 | TrainAcc0.7674 | val acc 0.4775\n",
      "Epoch 21 | Iter31 | Loss0.6152 | TrainAcc0.7674 | val acc 0.5154\n",
      "Epoch 21 | Iter33 | Loss0.7348 | TrainAcc0.6512 | val acc 0.4846\n",
      "Epoch 21 | Iter35 | Loss0.6625 | TrainAcc0.7442 | val acc 0.4279\n",
      "Epoch 21 | Iter37 | Loss0.9297 | TrainAcc0.5581 | val acc 0.4610\n",
      "Epoch 21 | Iter39 | Loss1.0987 | TrainAcc0.6000 | val acc 0.4161\n",
      "Epoch 22 | Iter1 | Loss0.6158 | TrainAcc0.6977 | val acc 0.4374\n",
      "Epoch 22 | Iter3 | Loss0.7841 | TrainAcc0.6512 | val acc 0.4374\n",
      "Epoch 22 | Iter5 | Loss0.7533 | TrainAcc0.6744 | val acc 0.4515\n",
      "Epoch 22 | Iter7 | Loss0.7007 | TrainAcc0.6047 | val acc 0.4634\n",
      "Epoch 22 | Iter9 | Loss0.6922 | TrainAcc0.7209 | val acc 0.4657\n",
      "Epoch 22 | Iter11 | Loss0.5654 | TrainAcc0.7442 | val acc 0.4563\n",
      "Epoch 22 | Iter13 | Loss0.6630 | TrainAcc0.6512 | val acc 0.4917\n",
      "Epoch 22 | Iter15 | Loss0.6672 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 22 | Iter17 | Loss0.9139 | TrainAcc0.6279 | val acc 0.4704\n",
      "Epoch 22 | Iter19 | Loss0.7091 | TrainAcc0.7209 | val acc 0.4846\n",
      "Epoch 22 | Iter21 | Loss0.6568 | TrainAcc0.6977 | val acc 0.4752\n",
      "Epoch 22 | Iter23 | Loss0.7386 | TrainAcc0.7442 | val acc 0.4846\n",
      "Epoch 22 | Iter25 | Loss0.5933 | TrainAcc0.7442 | val acc 0.4539\n",
      "Epoch 22 | Iter27 | Loss0.7284 | TrainAcc0.7674 | val acc 0.4728\n",
      "Epoch 22 | Iter29 | Loss0.6956 | TrainAcc0.6512 | val acc 0.4586\n",
      "Epoch 22 | Iter31 | Loss0.7048 | TrainAcc0.6512 | val acc 0.4563\n",
      "Epoch 22 | Iter33 | Loss0.7465 | TrainAcc0.5349 | val acc 0.4397\n",
      "Epoch 22 | Iter35 | Loss0.6846 | TrainAcc0.7442 | val acc 0.4137\n",
      "Epoch 22 | Iter37 | Loss0.7459 | TrainAcc0.6279 | val acc 0.4539\n",
      "Epoch 22 | Iter39 | Loss0.8374 | TrainAcc0.6667 | val acc 0.4515\n",
      "Epoch 23 | Iter1 | Loss0.6836 | TrainAcc0.6744 | val acc 0.4492\n",
      "Epoch 23 | Iter3 | Loss0.5921 | TrainAcc0.7442 | val acc 0.4421\n",
      "Epoch 23 | Iter5 | Loss0.7192 | TrainAcc0.6512 | val acc 0.4610\n",
      "Epoch 23 | Iter7 | Loss0.5584 | TrainAcc0.6977 | val acc 0.4586\n",
      "Epoch 23 | Iter9 | Loss0.6355 | TrainAcc0.7674 | val acc 0.4397\n",
      "Epoch 23 | Iter11 | Loss0.6199 | TrainAcc0.7442 | val acc 0.4350\n",
      "Epoch 23 | Iter13 | Loss0.8595 | TrainAcc0.7442 | val acc 0.4657\n",
      "Epoch 23 | Iter15 | Loss0.5859 | TrainAcc0.7442 | val acc 0.4444\n",
      "Epoch 23 | Iter17 | Loss0.4974 | TrainAcc0.8140 | val acc 0.4634\n",
      "Epoch 23 | Iter19 | Loss0.5725 | TrainAcc0.8605 | val acc 0.4563\n",
      "Epoch 23 | Iter21 | Loss0.6582 | TrainAcc0.6977 | val acc 0.4681\n",
      "Epoch 23 | Iter23 | Loss0.7821 | TrainAcc0.6512 | val acc 0.4728\n",
      "Epoch 23 | Iter25 | Loss0.6477 | TrainAcc0.6744 | val acc 0.4515\n",
      "Epoch 23 | Iter27 | Loss0.6430 | TrainAcc0.7209 | val acc 0.4704\n",
      "Epoch 23 | Iter29 | Loss0.4752 | TrainAcc0.6977 | val acc 0.4681\n",
      "Epoch 23 | Iter31 | Loss0.6376 | TrainAcc0.7209 | val acc 0.4894\n",
      "Epoch 23 | Iter33 | Loss0.6385 | TrainAcc0.7907 | val acc 0.4728\n",
      "Epoch 23 | Iter35 | Loss0.6932 | TrainAcc0.6977 | val acc 0.4326\n",
      "Epoch 23 | Iter37 | Loss0.7088 | TrainAcc0.6744 | val acc 0.4515\n",
      "Epoch 23 | Iter39 | Loss0.6879 | TrainAcc0.6667 | val acc 0.4421\n",
      "Epoch 24 | Iter1 | Loss0.7176 | TrainAcc0.5814 | val acc 0.4374\n",
      "Epoch 24 | Iter3 | Loss0.5802 | TrainAcc0.7442 | val acc 0.4586\n",
      "Epoch 24 | Iter5 | Loss0.6604 | TrainAcc0.7907 | val acc 0.4444\n",
      "Epoch 24 | Iter7 | Loss0.6477 | TrainAcc0.6279 | val acc 0.4468\n",
      "Epoch 24 | Iter9 | Loss0.6030 | TrainAcc0.7442 | val acc 0.4634\n",
      "Epoch 24 | Iter11 | Loss0.6232 | TrainAcc0.7209 | val acc 0.4468\n",
      "Epoch 24 | Iter13 | Loss0.5290 | TrainAcc0.8605 | val acc 0.4634\n",
      "Epoch 24 | Iter15 | Loss0.5966 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 24 | Iter17 | Loss0.5155 | TrainAcc0.7209 | val acc 0.4704\n",
      "Epoch 24 | Iter19 | Loss0.7190 | TrainAcc0.7209 | val acc 0.4421\n",
      "Epoch 24 | Iter21 | Loss0.7807 | TrainAcc0.6512 | val acc 0.4681\n",
      "Epoch 24 | Iter23 | Loss0.7158 | TrainAcc0.7442 | val acc 0.4775\n",
      "Epoch 24 | Iter25 | Loss0.5932 | TrainAcc0.6744 | val acc 0.4917\n",
      "Epoch 24 | Iter27 | Loss0.5514 | TrainAcc0.6977 | val acc 0.4586\n",
      "Epoch 24 | Iter29 | Loss0.6542 | TrainAcc0.7674 | val acc 0.4397\n",
      "Epoch 24 | Iter31 | Loss0.6675 | TrainAcc0.7209 | val acc 0.4492\n",
      "Epoch 24 | Iter33 | Loss0.5742 | TrainAcc0.7442 | val acc 0.4326\n",
      "Epoch 24 | Iter35 | Loss0.5835 | TrainAcc0.7442 | val acc 0.4681\n",
      "Epoch 24 | Iter37 | Loss0.7522 | TrainAcc0.6977 | val acc 0.4326\n",
      "Epoch 24 | Iter39 | Loss0.8965 | TrainAcc0.5333 | val acc 0.4350\n",
      "Epoch 25 | Iter1 | Loss0.4909 | TrainAcc0.7442 | val acc 0.4492\n",
      "Epoch 25 | Iter3 | Loss0.7425 | TrainAcc0.5814 | val acc 0.4421\n",
      "Epoch 25 | Iter5 | Loss0.5466 | TrainAcc0.8372 | val acc 0.4515\n",
      "Epoch 25 | Iter7 | Loss0.6295 | TrainAcc0.6744 | val acc 0.4279\n",
      "Epoch 25 | Iter9 | Loss0.6515 | TrainAcc0.7674 | val acc 0.4515\n",
      "Epoch 25 | Iter11 | Loss0.5457 | TrainAcc0.7674 | val acc 0.4681\n",
      "Epoch 25 | Iter13 | Loss0.5780 | TrainAcc0.7442 | val acc 0.4728\n",
      "Epoch 25 | Iter15 | Loss0.5037 | TrainAcc0.7907 | val acc 0.4515\n",
      "Epoch 25 | Iter17 | Loss0.4713 | TrainAcc0.7674 | val acc 0.4492\n",
      "Epoch 25 | Iter19 | Loss0.4733 | TrainAcc0.7907 | val acc 0.4704\n",
      "Epoch 25 | Iter21 | Loss0.8104 | TrainAcc0.6512 | val acc 0.4326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Iter23 | Loss0.8304 | TrainAcc0.7209 | val acc 0.4610\n",
      "Epoch 25 | Iter25 | Loss0.6233 | TrainAcc0.7209 | val acc 0.4515\n",
      "Epoch 25 | Iter27 | Loss0.5521 | TrainAcc0.8372 | val acc 0.4515\n",
      "Epoch 25 | Iter29 | Loss0.4394 | TrainAcc0.7674 | val acc 0.4444\n",
      "Epoch 25 | Iter31 | Loss0.5497 | TrainAcc0.7209 | val acc 0.4444\n",
      "Epoch 25 | Iter33 | Loss0.5283 | TrainAcc0.8140 | val acc 0.4326\n",
      "Epoch 25 | Iter35 | Loss0.5106 | TrainAcc0.7442 | val acc 0.4232\n",
      "Epoch 25 | Iter37 | Loss0.5748 | TrainAcc0.8140 | val acc 0.3877\n",
      "Epoch 25 | Iter39 | Loss0.8438 | TrainAcc0.6667 | val acc 0.4468\n",
      "Epoch 26 | Iter1 | Loss0.6174 | TrainAcc0.7442 | val acc 0.4515\n",
      "Epoch 26 | Iter3 | Loss0.7152 | TrainAcc0.6512 | val acc 0.4657\n",
      "Epoch 26 | Iter5 | Loss0.6068 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 26 | Iter7 | Loss0.4938 | TrainAcc0.8605 | val acc 0.4468\n",
      "Epoch 26 | Iter9 | Loss0.7932 | TrainAcc0.6744 | val acc 0.4586\n",
      "Epoch 26 | Iter11 | Loss0.4744 | TrainAcc0.7209 | val acc 0.4303\n",
      "Epoch 26 | Iter13 | Loss0.5551 | TrainAcc0.7674 | val acc 0.4515\n",
      "Epoch 26 | Iter15 | Loss0.5364 | TrainAcc0.7209 | val acc 0.4374\n",
      "Epoch 26 | Iter17 | Loss0.7260 | TrainAcc0.7209 | val acc 0.4515\n",
      "Epoch 26 | Iter19 | Loss0.5922 | TrainAcc0.7674 | val acc 0.4492\n",
      "Epoch 26 | Iter21 | Loss0.4925 | TrainAcc0.8140 | val acc 0.4232\n",
      "Epoch 26 | Iter23 | Loss0.9769 | TrainAcc0.6279 | val acc 0.4586\n",
      "Epoch 26 | Iter25 | Loss0.7105 | TrainAcc0.7442 | val acc 0.4255\n",
      "Epoch 26 | Iter27 | Loss0.5728 | TrainAcc0.8605 | val acc 0.4610\n",
      "Epoch 26 | Iter29 | Loss0.6172 | TrainAcc0.7209 | val acc 0.4704\n",
      "Epoch 26 | Iter31 | Loss0.6037 | TrainAcc0.6744 | val acc 0.4870\n",
      "Epoch 26 | Iter33 | Loss0.5239 | TrainAcc0.8372 | val acc 0.4610\n",
      "Epoch 26 | Iter35 | Loss0.5360 | TrainAcc0.6977 | val acc 0.4657\n",
      "Epoch 26 | Iter37 | Loss0.6726 | TrainAcc0.6977 | val acc 0.4704\n",
      "Epoch 26 | Iter39 | Loss0.6052 | TrainAcc0.8667 | val acc 0.4161\n",
      "Epoch 27 | Iter1 | Loss0.7927 | TrainAcc0.7907 | val acc 0.4634\n",
      "Epoch 27 | Iter3 | Loss0.8291 | TrainAcc0.5581 | val acc 0.4681\n",
      "Epoch 27 | Iter5 | Loss0.8451 | TrainAcc0.6047 | val acc 0.4279\n",
      "Epoch 27 | Iter7 | Loss0.6616 | TrainAcc0.6512 | val acc 0.4657\n",
      "Epoch 27 | Iter9 | Loss0.6130 | TrainAcc0.7209 | val acc 0.4870\n",
      "Epoch 27 | Iter11 | Loss0.5168 | TrainAcc0.7442 | val acc 0.5035\n",
      "Epoch 27 | Iter13 | Loss0.6316 | TrainAcc0.7209 | val acc 0.5035\n",
      "Epoch 27 | Iter15 | Loss0.6129 | TrainAcc0.7674 | val acc 0.4657\n",
      "Epoch 27 | Iter17 | Loss0.5606 | TrainAcc0.7674 | val acc 0.4799\n",
      "Epoch 27 | Iter19 | Loss0.8147 | TrainAcc0.6512 | val acc 0.4421\n",
      "Epoch 27 | Iter21 | Loss0.7239 | TrainAcc0.6279 | val acc 0.4775\n",
      "Epoch 27 | Iter23 | Loss0.5085 | TrainAcc0.8140 | val acc 0.4823\n",
      "Epoch 27 | Iter25 | Loss0.5604 | TrainAcc0.6512 | val acc 0.4397\n",
      "Epoch 27 | Iter27 | Loss0.5304 | TrainAcc0.8140 | val acc 0.4279\n",
      "Epoch 27 | Iter29 | Loss0.5417 | TrainAcc0.8372 | val acc 0.4515\n",
      "Epoch 27 | Iter31 | Loss0.5877 | TrainAcc0.7442 | val acc 0.4586\n",
      "Epoch 27 | Iter33 | Loss0.5997 | TrainAcc0.8140 | val acc 0.4586\n",
      "Epoch 27 | Iter35 | Loss0.6020 | TrainAcc0.6744 | val acc 0.4468\n",
      "Epoch 27 | Iter37 | Loss0.7069 | TrainAcc0.6279 | val acc 0.4232\n",
      "Epoch 27 | Iter39 | Loss0.7786 | TrainAcc0.5333 | val acc 0.4374\n",
      "Epoch 28 | Iter1 | Loss0.4924 | TrainAcc0.8140 | val acc 0.4421\n",
      "Epoch 28 | Iter3 | Loss0.5662 | TrainAcc0.7209 | val acc 0.4586\n",
      "Epoch 28 | Iter5 | Loss0.7164 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 28 | Iter7 | Loss0.7425 | TrainAcc0.7209 | val acc 0.4775\n",
      "Epoch 28 | Iter9 | Loss0.5283 | TrainAcc0.7442 | val acc 0.4846\n",
      "Epoch 28 | Iter11 | Loss0.6622 | TrainAcc0.7209 | val acc 0.4610\n",
      "Epoch 28 | Iter13 | Loss0.5256 | TrainAcc0.8372 | val acc 0.4657\n",
      "Epoch 28 | Iter15 | Loss0.5598 | TrainAcc0.6977 | val acc 0.4823\n",
      "Epoch 28 | Iter17 | Loss0.5648 | TrainAcc0.8372 | val acc 0.4775\n",
      "Epoch 28 | Iter19 | Loss0.4804 | TrainAcc0.8140 | val acc 0.4657\n",
      "Epoch 28 | Iter21 | Loss0.5853 | TrainAcc0.7209 | val acc 0.4728\n",
      "Epoch 28 | Iter23 | Loss0.5891 | TrainAcc0.7209 | val acc 0.4563\n",
      "Epoch 28 | Iter25 | Loss0.5653 | TrainAcc0.7907 | val acc 0.4492\n",
      "Epoch 28 | Iter27 | Loss0.7244 | TrainAcc0.6279 | val acc 0.4444\n",
      "Epoch 28 | Iter29 | Loss0.6237 | TrainAcc0.6512 | val acc 0.4279\n",
      "Epoch 28 | Iter31 | Loss0.7342 | TrainAcc0.6977 | val acc 0.4279\n",
      "Epoch 28 | Iter33 | Loss0.5292 | TrainAcc0.8605 | val acc 0.4184\n",
      "Epoch 28 | Iter35 | Loss0.6966 | TrainAcc0.7209 | val acc 0.4350\n",
      "Epoch 28 | Iter37 | Loss0.5360 | TrainAcc0.7209 | val acc 0.4184\n",
      "Epoch 28 | Iter39 | Loss0.7367 | TrainAcc0.8667 | val acc 0.4397\n",
      "Epoch 29 | Iter1 | Loss0.7017 | TrainAcc0.7907 | val acc 0.4421\n",
      "Epoch 29 | Iter3 | Loss0.5299 | TrainAcc0.7442 | val acc 0.4444\n",
      "Epoch 29 | Iter5 | Loss0.5022 | TrainAcc0.8372 | val acc 0.4374\n",
      "Epoch 29 | Iter7 | Loss0.6973 | TrainAcc0.6977 | val acc 0.4468\n",
      "Epoch 29 | Iter9 | Loss0.9528 | TrainAcc0.5814 | val acc 0.4374\n",
      "Epoch 29 | Iter11 | Loss0.4774 | TrainAcc0.8140 | val acc 0.4397\n",
      "Epoch 29 | Iter13 | Loss0.6540 | TrainAcc0.7442 | val acc 0.4279\n",
      "Epoch 29 | Iter15 | Loss0.5335 | TrainAcc0.7442 | val acc 0.4066\n",
      "Epoch 29 | Iter17 | Loss0.6235 | TrainAcc0.8372 | val acc 0.4232\n",
      "Epoch 29 | Iter19 | Loss0.5214 | TrainAcc0.7209 | val acc 0.4161\n",
      "Epoch 29 | Iter21 | Loss0.6326 | TrainAcc0.7907 | val acc 0.4421\n",
      "Epoch 29 | Iter23 | Loss0.5370 | TrainAcc0.8837 | val acc 0.4775\n",
      "Epoch 29 | Iter25 | Loss0.4326 | TrainAcc0.8837 | val acc 0.4775\n",
      "Epoch 29 | Iter27 | Loss0.5722 | TrainAcc0.7674 | val acc 0.4752\n",
      "Epoch 29 | Iter29 | Loss0.6358 | TrainAcc0.6047 | val acc 0.4846\n",
      "Epoch 29 | Iter31 | Loss0.5711 | TrainAcc0.7907 | val acc 0.4917\n",
      "Epoch 29 | Iter33 | Loss0.5880 | TrainAcc0.7442 | val acc 0.5083\n",
      "Epoch 29 | Iter35 | Loss0.6022 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 29 | Iter37 | Loss0.4872 | TrainAcc0.8837 | val acc 0.4704\n",
      "Epoch 29 | Iter39 | Loss0.6921 | TrainAcc0.7333 | val acc 0.4586\n",
      "Epoch 30 | Iter1 | Loss0.5797 | TrainAcc0.8140 | val acc 0.4468\n",
      "Epoch 30 | Iter3 | Loss0.5263 | TrainAcc0.8605 | val acc 0.4681\n",
      "Epoch 30 | Iter5 | Loss0.5297 | TrainAcc0.8372 | val acc 0.4870\n",
      "Epoch 30 | Iter7 | Loss0.6320 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 30 | Iter9 | Loss0.5744 | TrainAcc0.6512 | val acc 0.4752\n",
      "Epoch 30 | Iter11 | Loss0.5155 | TrainAcc0.7442 | val acc 0.4634\n",
      "Epoch 30 | Iter13 | Loss0.6301 | TrainAcc0.7209 | val acc 0.4303\n",
      "Epoch 30 | Iter15 | Loss0.4837 | TrainAcc0.7674 | val acc 0.4634\n",
      "Epoch 30 | Iter17 | Loss0.7441 | TrainAcc0.7674 | val acc 0.4634\n",
      "Epoch 30 | Iter19 | Loss0.7236 | TrainAcc0.6279 | val acc 0.4752\n",
      "Epoch 30 | Iter21 | Loss0.4579 | TrainAcc0.8372 | val acc 0.4610\n",
      "Epoch 30 | Iter23 | Loss0.4873 | TrainAcc0.8372 | val acc 0.4515\n",
      "Epoch 30 | Iter25 | Loss0.4940 | TrainAcc0.7907 | val acc 0.4657\n",
      "Epoch 30 | Iter27 | Loss0.5832 | TrainAcc0.7907 | val acc 0.4586\n",
      "Epoch 30 | Iter29 | Loss0.5127 | TrainAcc0.7674 | val acc 0.4634\n",
      "Epoch 30 | Iter31 | Loss0.5440 | TrainAcc0.7209 | val acc 0.4515\n",
      "Epoch 30 | Iter33 | Loss0.5798 | TrainAcc0.7907 | val acc 0.4586\n",
      "Epoch 30 | Iter35 | Loss0.5662 | TrainAcc0.7442 | val acc 0.4634\n",
      "Epoch 30 | Iter37 | Loss0.5425 | TrainAcc0.7209 | val acc 0.4681\n",
      "Epoch 30 | Iter39 | Loss0.4280 | TrainAcc0.7333 | val acc 0.4657\n",
      "Epoch 31 | Iter1 | Loss0.6691 | TrainAcc0.6744 | val acc 0.4704\n",
      "Epoch 31 | Iter3 | Loss0.4108 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 31 | Iter5 | Loss0.4714 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 31 | Iter7 | Loss0.7056 | TrainAcc0.6279 | val acc 0.4539\n",
      "Epoch 31 | Iter9 | Loss0.6488 | TrainAcc0.6977 | val acc 0.4634\n",
      "Epoch 31 | Iter11 | Loss0.4767 | TrainAcc0.7442 | val acc 0.4823\n",
      "Epoch 31 | Iter13 | Loss0.5331 | TrainAcc0.7674 | val acc 0.4657\n",
      "Epoch 31 | Iter15 | Loss0.4665 | TrainAcc0.8372 | val acc 0.4468\n",
      "Epoch 31 | Iter17 | Loss0.3738 | TrainAcc0.8605 | val acc 0.4444\n",
      "Epoch 31 | Iter19 | Loss0.4067 | TrainAcc0.9070 | val acc 0.4539\n",
      "Epoch 31 | Iter21 | Loss0.4343 | TrainAcc0.8140 | val acc 0.4515\n",
      "Epoch 31 | Iter23 | Loss0.5457 | TrainAcc0.6977 | val acc 0.4704\n",
      "Epoch 31 | Iter25 | Loss0.6317 | TrainAcc0.6977 | val acc 0.4350\n",
      "Epoch 31 | Iter27 | Loss0.5192 | TrainAcc0.8837 | val acc 0.4563\n",
      "Epoch 31 | Iter29 | Loss0.5145 | TrainAcc0.7674 | val acc 0.4468\n",
      "Epoch 31 | Iter31 | Loss0.4834 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 31 | Iter33 | Loss0.4637 | TrainAcc0.7442 | val acc 0.4515\n",
      "Epoch 31 | Iter35 | Loss0.5891 | TrainAcc0.6047 | val acc 0.4421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Iter37 | Loss0.5132 | TrainAcc0.8140 | val acc 0.4326\n",
      "Epoch 31 | Iter39 | Loss0.5745 | TrainAcc0.6667 | val acc 0.4586\n",
      "Epoch 32 | Iter1 | Loss0.4741 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 32 | Iter3 | Loss0.4699 | TrainAcc0.7907 | val acc 0.4610\n",
      "Epoch 32 | Iter5 | Loss0.4119 | TrainAcc0.8605 | val acc 0.4704\n",
      "Epoch 32 | Iter7 | Loss0.5662 | TrainAcc0.7674 | val acc 0.4492\n",
      "Epoch 32 | Iter9 | Loss0.4505 | TrainAcc0.8140 | val acc 0.4823\n",
      "Epoch 32 | Iter11 | Loss0.4386 | TrainAcc0.8140 | val acc 0.4799\n",
      "Epoch 32 | Iter13 | Loss0.5157 | TrainAcc0.7674 | val acc 0.4704\n",
      "Epoch 32 | Iter15 | Loss0.4845 | TrainAcc0.8605 | val acc 0.4374\n",
      "Epoch 32 | Iter17 | Loss0.3617 | TrainAcc0.8837 | val acc 0.4184\n",
      "Epoch 32 | Iter19 | Loss0.5681 | TrainAcc0.7442 | val acc 0.4326\n",
      "Epoch 32 | Iter21 | Loss0.4080 | TrainAcc0.8372 | val acc 0.4539\n",
      "Epoch 32 | Iter23 | Loss0.5687 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 32 | Iter25 | Loss0.7081 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 32 | Iter27 | Loss0.4702 | TrainAcc0.8372 | val acc 0.4161\n",
      "Epoch 32 | Iter29 | Loss0.4984 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 32 | Iter31 | Loss0.4851 | TrainAcc0.8372 | val acc 0.4539\n",
      "Epoch 32 | Iter33 | Loss0.5956 | TrainAcc0.8140 | val acc 0.4634\n",
      "Epoch 32 | Iter35 | Loss0.6025 | TrainAcc0.7442 | val acc 0.4515\n",
      "Epoch 32 | Iter37 | Loss0.5345 | TrainAcc0.7907 | val acc 0.4634\n",
      "Epoch 32 | Iter39 | Loss0.4294 | TrainAcc0.7333 | val acc 0.4634\n",
      "Epoch 33 | Iter1 | Loss0.2737 | TrainAcc0.9070 | val acc 0.4468\n",
      "Epoch 33 | Iter3 | Loss0.5739 | TrainAcc0.7442 | val acc 0.4539\n",
      "Epoch 33 | Iter5 | Loss0.6029 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 33 | Iter7 | Loss0.5455 | TrainAcc0.8140 | val acc 0.4634\n",
      "Epoch 33 | Iter9 | Loss0.6209 | TrainAcc0.7674 | val acc 0.4681\n",
      "Epoch 33 | Iter11 | Loss0.4764 | TrainAcc0.7209 | val acc 0.4468\n",
      "Epoch 33 | Iter13 | Loss0.7025 | TrainAcc0.7674 | val acc 0.4704\n",
      "Epoch 33 | Iter15 | Loss0.4528 | TrainAcc0.8605 | val acc 0.4775\n",
      "Epoch 33 | Iter17 | Loss0.5637 | TrainAcc0.7674 | val acc 0.4775\n",
      "Epoch 33 | Iter19 | Loss0.5690 | TrainAcc0.7907 | val acc 0.4870\n",
      "Epoch 33 | Iter21 | Loss0.5006 | TrainAcc0.7209 | val acc 0.4515\n",
      "Epoch 33 | Iter23 | Loss0.4776 | TrainAcc0.7442 | val acc 0.4539\n",
      "Epoch 33 | Iter25 | Loss0.4974 | TrainAcc0.8837 | val acc 0.4704\n",
      "Epoch 33 | Iter27 | Loss0.3983 | TrainAcc0.9070 | val acc 0.4586\n",
      "Epoch 33 | Iter29 | Loss0.4140 | TrainAcc0.8837 | val acc 0.4515\n",
      "Epoch 33 | Iter31 | Loss0.3691 | TrainAcc0.8837 | val acc 0.4539\n",
      "Epoch 33 | Iter33 | Loss0.5046 | TrainAcc0.8140 | val acc 0.4303\n",
      "Epoch 33 | Iter35 | Loss0.4764 | TrainAcc0.8605 | val acc 0.4657\n",
      "Epoch 33 | Iter37 | Loss0.4669 | TrainAcc0.8605 | val acc 0.4492\n",
      "Epoch 33 | Iter39 | Loss0.5685 | TrainAcc0.7333 | val acc 0.4208\n",
      "Epoch 34 | Iter1 | Loss0.4558 | TrainAcc0.7907 | val acc 0.4326\n",
      "Epoch 34 | Iter3 | Loss0.4080 | TrainAcc0.8372 | val acc 0.4255\n",
      "Epoch 34 | Iter5 | Loss0.5405 | TrainAcc0.7907 | val acc 0.4421\n",
      "Epoch 34 | Iter7 | Loss0.5387 | TrainAcc0.8140 | val acc 0.4397\n",
      "Epoch 34 | Iter9 | Loss0.5303 | TrainAcc0.8140 | val acc 0.4326\n",
      "Epoch 34 | Iter11 | Loss0.4416 | TrainAcc0.8372 | val acc 0.4563\n",
      "Epoch 34 | Iter13 | Loss0.3638 | TrainAcc0.9302 | val acc 0.4586\n",
      "Epoch 34 | Iter15 | Loss0.4558 | TrainAcc0.8605 | val acc 0.4515\n",
      "Epoch 34 | Iter17 | Loss0.6051 | TrainAcc0.7209 | val acc 0.4681\n",
      "Epoch 34 | Iter19 | Loss0.5965 | TrainAcc0.7674 | val acc 0.4799\n",
      "Epoch 34 | Iter21 | Loss0.5008 | TrainAcc0.8140 | val acc 0.4846\n",
      "Epoch 34 | Iter23 | Loss0.5364 | TrainAcc0.7907 | val acc 0.4704\n",
      "Epoch 34 | Iter25 | Loss0.4556 | TrainAcc0.8140 | val acc 0.4610\n",
      "Epoch 34 | Iter27 | Loss0.4955 | TrainAcc0.7674 | val acc 0.4894\n",
      "Epoch 34 | Iter29 | Loss0.3857 | TrainAcc0.7907 | val acc 0.4775\n",
      "Epoch 34 | Iter31 | Loss0.4488 | TrainAcc0.7907 | val acc 0.4563\n",
      "Epoch 34 | Iter33 | Loss0.4317 | TrainAcc0.8140 | val acc 0.4610\n",
      "Epoch 34 | Iter35 | Loss0.6441 | TrainAcc0.7209 | val acc 0.4704\n",
      "Epoch 34 | Iter37 | Loss0.5333 | TrainAcc0.7442 | val acc 0.4681\n",
      "Epoch 34 | Iter39 | Loss0.3801 | TrainAcc0.8667 | val acc 0.4704\n",
      "Epoch 35 | Iter1 | Loss0.5137 | TrainAcc0.7907 | val acc 0.4208\n",
      "Epoch 35 | Iter3 | Loss0.6195 | TrainAcc0.7674 | val acc 0.4303\n",
      "Epoch 35 | Iter5 | Loss0.3892 | TrainAcc0.8140 | val acc 0.4255\n",
      "Epoch 35 | Iter7 | Loss0.5045 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 35 | Iter9 | Loss0.3883 | TrainAcc0.8140 | val acc 0.4728\n",
      "Epoch 35 | Iter11 | Loss0.4946 | TrainAcc0.8605 | val acc 0.4823\n",
      "Epoch 35 | Iter13 | Loss0.7606 | TrainAcc0.6512 | val acc 0.4634\n",
      "Epoch 35 | Iter15 | Loss0.6035 | TrainAcc0.7442 | val acc 0.4823\n",
      "Epoch 35 | Iter17 | Loss0.3760 | TrainAcc0.8837 | val acc 0.4563\n",
      "Epoch 35 | Iter19 | Loss0.5790 | TrainAcc0.7674 | val acc 0.4704\n",
      "Epoch 35 | Iter21 | Loss0.3806 | TrainAcc0.9070 | val acc 0.4681\n",
      "Epoch 35 | Iter23 | Loss0.3838 | TrainAcc0.8605 | val acc 0.4586\n",
      "Epoch 35 | Iter25 | Loss0.6729 | TrainAcc0.7907 | val acc 0.4728\n",
      "Epoch 35 | Iter27 | Loss0.5940 | TrainAcc0.6977 | val acc 0.4539\n",
      "Epoch 35 | Iter29 | Loss0.5528 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 35 | Iter31 | Loss0.4435 | TrainAcc0.8372 | val acc 0.4799\n",
      "Epoch 35 | Iter33 | Loss0.5146 | TrainAcc0.7442 | val acc 0.4397\n",
      "Epoch 35 | Iter35 | Loss0.4000 | TrainAcc0.8605 | val acc 0.4515\n",
      "Epoch 35 | Iter37 | Loss0.5307 | TrainAcc0.7442 | val acc 0.4634\n",
      "Epoch 35 | Iter39 | Loss1.4676 | TrainAcc0.8000 | val acc 0.3783\n",
      "Epoch 36 | Iter1 | Loss0.5824 | TrainAcc0.7674 | val acc 0.4468\n",
      "Epoch 36 | Iter3 | Loss0.7009 | TrainAcc0.7907 | val acc 0.4563\n",
      "Epoch 36 | Iter5 | Loss0.3161 | TrainAcc0.9302 | val acc 0.4657\n",
      "Epoch 36 | Iter7 | Loss0.5445 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 36 | Iter9 | Loss0.8510 | TrainAcc0.6744 | val acc 0.4704\n",
      "Epoch 36 | Iter11 | Loss0.4819 | TrainAcc0.7907 | val acc 0.4634\n",
      "Epoch 36 | Iter13 | Loss0.6966 | TrainAcc0.6977 | val acc 0.4492\n",
      "Epoch 36 | Iter15 | Loss0.5983 | TrainAcc0.7442 | val acc 0.4610\n",
      "Epoch 36 | Iter17 | Loss0.4899 | TrainAcc0.7907 | val acc 0.4586\n",
      "Epoch 36 | Iter19 | Loss0.6819 | TrainAcc0.6512 | val acc 0.4704\n",
      "Epoch 36 | Iter21 | Loss0.4385 | TrainAcc0.8140 | val acc 0.4657\n",
      "Epoch 36 | Iter23 | Loss0.5708 | TrainAcc0.7674 | val acc 0.4752\n",
      "Epoch 36 | Iter25 | Loss0.5174 | TrainAcc0.7674 | val acc 0.4941\n",
      "Epoch 36 | Iter27 | Loss0.4400 | TrainAcc0.7442 | val acc 0.4657\n",
      "Epoch 36 | Iter29 | Loss0.6799 | TrainAcc0.6047 | val acc 0.4515\n",
      "Epoch 36 | Iter31 | Loss0.5095 | TrainAcc0.7674 | val acc 0.4539\n",
      "Epoch 36 | Iter33 | Loss0.5380 | TrainAcc0.7442 | val acc 0.4563\n",
      "Epoch 36 | Iter35 | Loss0.4659 | TrainAcc0.8140 | val acc 0.4657\n",
      "Epoch 36 | Iter37 | Loss0.3843 | TrainAcc0.8605 | val acc 0.4728\n",
      "Epoch 36 | Iter39 | Loss0.4855 | TrainAcc0.7333 | val acc 0.4586\n",
      "Epoch 37 | Iter1 | Loss0.2832 | TrainAcc0.9070 | val acc 0.4610\n",
      "Epoch 37 | Iter3 | Loss0.6641 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 37 | Iter5 | Loss0.4054 | TrainAcc0.7907 | val acc 0.4634\n",
      "Epoch 37 | Iter7 | Loss0.4638 | TrainAcc0.7907 | val acc 0.4917\n",
      "Epoch 37 | Iter9 | Loss0.4793 | TrainAcc0.7674 | val acc 0.4846\n",
      "Epoch 37 | Iter11 | Loss0.2944 | TrainAcc0.9070 | val acc 0.4917\n",
      "Epoch 37 | Iter13 | Loss0.6594 | TrainAcc0.6977 | val acc 0.4539\n",
      "Epoch 37 | Iter15 | Loss0.3911 | TrainAcc0.8837 | val acc 0.4799\n",
      "Epoch 37 | Iter17 | Loss0.4597 | TrainAcc0.7907 | val acc 0.4681\n",
      "Epoch 37 | Iter19 | Loss0.5243 | TrainAcc0.7674 | val acc 0.4799\n",
      "Epoch 37 | Iter21 | Loss0.3761 | TrainAcc0.8605 | val acc 0.4397\n",
      "Epoch 37 | Iter23 | Loss0.3592 | TrainAcc0.8837 | val acc 0.4657\n",
      "Epoch 37 | Iter25 | Loss0.4694 | TrainAcc0.8605 | val acc 0.4752\n",
      "Epoch 37 | Iter27 | Loss0.6051 | TrainAcc0.7674 | val acc 0.4704\n",
      "Epoch 37 | Iter29 | Loss0.4211 | TrainAcc0.7442 | val acc 0.4728\n",
      "Epoch 37 | Iter31 | Loss0.6287 | TrainAcc0.7674 | val acc 0.4775\n",
      "Epoch 37 | Iter33 | Loss0.4580 | TrainAcc0.7907 | val acc 0.4515\n",
      "Epoch 37 | Iter35 | Loss0.5197 | TrainAcc0.7442 | val acc 0.4326\n",
      "Epoch 37 | Iter37 | Loss0.4420 | TrainAcc0.8605 | val acc 0.4279\n",
      "Epoch 37 | Iter39 | Loss0.4808 | TrainAcc0.8000 | val acc 0.4657\n",
      "Epoch 38 | Iter1 | Loss0.4285 | TrainAcc0.7907 | val acc 0.4728\n",
      "Epoch 38 | Iter3 | Loss0.4052 | TrainAcc0.8605 | val acc 0.4728\n",
      "Epoch 38 | Iter5 | Loss0.4705 | TrainAcc0.7442 | val acc 0.4681\n",
      "Epoch 38 | Iter7 | Loss0.5893 | TrainAcc0.7674 | val acc 0.4563\n",
      "Epoch 38 | Iter9 | Loss0.4426 | TrainAcc0.7674 | val acc 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Iter11 | Loss0.3565 | TrainAcc0.8837 | val acc 0.4444\n",
      "Epoch 38 | Iter13 | Loss0.4126 | TrainAcc0.8605 | val acc 0.4492\n",
      "Epoch 38 | Iter15 | Loss0.5079 | TrainAcc0.8837 | val acc 0.4681\n",
      "Epoch 38 | Iter17 | Loss0.4920 | TrainAcc0.7674 | val acc 0.4752\n",
      "Epoch 38 | Iter19 | Loss0.3581 | TrainAcc0.9070 | val acc 0.4515\n",
      "Epoch 38 | Iter21 | Loss0.4272 | TrainAcc0.7442 | val acc 0.4586\n",
      "Epoch 38 | Iter23 | Loss0.4663 | TrainAcc0.8140 | val acc 0.4515\n",
      "Epoch 38 | Iter25 | Loss0.4619 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 38 | Iter27 | Loss0.4370 | TrainAcc0.8140 | val acc 0.4610\n",
      "Epoch 38 | Iter29 | Loss0.4622 | TrainAcc0.7907 | val acc 0.4610\n",
      "Epoch 38 | Iter31 | Loss0.5280 | TrainAcc0.7907 | val acc 0.4752\n",
      "Epoch 38 | Iter33 | Loss0.7073 | TrainAcc0.6744 | val acc 0.4492\n",
      "Epoch 38 | Iter35 | Loss0.6025 | TrainAcc0.7674 | val acc 0.4184\n",
      "Epoch 38 | Iter37 | Loss0.7894 | TrainAcc0.6512 | val acc 0.4397\n",
      "Epoch 38 | Iter39 | Loss1.2270 | TrainAcc0.6000 | val acc 0.3641\n",
      "Epoch 39 | Iter1 | Loss0.5007 | TrainAcc0.8140 | val acc 0.4941\n",
      "Epoch 39 | Iter3 | Loss0.5146 | TrainAcc0.8372 | val acc 0.4846\n",
      "Epoch 39 | Iter5 | Loss0.6918 | TrainAcc0.7907 | val acc 0.4586\n",
      "Epoch 39 | Iter7 | Loss0.3650 | TrainAcc0.8140 | val acc 0.4492\n",
      "Epoch 39 | Iter9 | Loss0.5381 | TrainAcc0.7907 | val acc 0.4444\n",
      "Epoch 39 | Iter11 | Loss0.4702 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 39 | Iter13 | Loss0.6149 | TrainAcc0.7442 | val acc 0.4586\n",
      "Epoch 39 | Iter15 | Loss0.4548 | TrainAcc0.8372 | val acc 0.4468\n",
      "Epoch 39 | Iter17 | Loss0.6289 | TrainAcc0.7674 | val acc 0.4610\n",
      "Epoch 39 | Iter19 | Loss0.3420 | TrainAcc0.8372 | val acc 0.4492\n",
      "Epoch 39 | Iter21 | Loss0.4944 | TrainAcc0.8372 | val acc 0.4515\n",
      "Epoch 39 | Iter23 | Loss0.4969 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 39 | Iter25 | Loss0.4902 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 39 | Iter27 | Loss0.3623 | TrainAcc0.8140 | val acc 0.4492\n",
      "Epoch 39 | Iter29 | Loss0.5253 | TrainAcc0.7209 | val acc 0.4752\n",
      "Epoch 39 | Iter31 | Loss0.4476 | TrainAcc0.8140 | val acc 0.4681\n",
      "Epoch 39 | Iter33 | Loss0.4256 | TrainAcc0.7674 | val acc 0.4421\n",
      "Epoch 39 | Iter35 | Loss0.4684 | TrainAcc0.7674 | val acc 0.4515\n",
      "Epoch 39 | Iter37 | Loss0.4273 | TrainAcc0.8140 | val acc 0.4586\n",
      "Epoch 39 | Iter39 | Loss0.8979 | TrainAcc0.6667 | val acc 0.4113\n",
      "Epoch 40 | Iter1 | Loss0.4127 | TrainAcc0.8605 | val acc 0.4610\n",
      "Epoch 40 | Iter3 | Loss0.4895 | TrainAcc0.7907 | val acc 0.4823\n",
      "Epoch 40 | Iter5 | Loss0.6646 | TrainAcc0.8372 | val acc 0.4728\n",
      "Epoch 40 | Iter7 | Loss0.5426 | TrainAcc0.8140 | val acc 0.4634\n",
      "Epoch 40 | Iter9 | Loss0.4980 | TrainAcc0.7674 | val acc 0.4326\n",
      "Epoch 40 | Iter11 | Loss0.4177 | TrainAcc0.7907 | val acc 0.4303\n",
      "Epoch 40 | Iter13 | Loss0.3934 | TrainAcc0.8140 | val acc 0.4586\n",
      "Epoch 40 | Iter15 | Loss0.4225 | TrainAcc0.8605 | val acc 0.4704\n",
      "Epoch 40 | Iter17 | Loss0.5211 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 40 | Iter19 | Loss0.8915 | TrainAcc0.7209 | val acc 0.4374\n",
      "Epoch 40 | Iter21 | Loss0.7706 | TrainAcc0.6977 | val acc 0.4397\n",
      "Epoch 40 | Iter23 | Loss0.6377 | TrainAcc0.6744 | val acc 0.4634\n",
      "Epoch 40 | Iter25 | Loss0.3567 | TrainAcc0.8605 | val acc 0.4823\n",
      "Epoch 40 | Iter27 | Loss0.5226 | TrainAcc0.7442 | val acc 0.4752\n",
      "Epoch 40 | Iter29 | Loss0.3812 | TrainAcc0.9070 | val acc 0.4752\n",
      "Epoch 40 | Iter31 | Loss0.4912 | TrainAcc0.8605 | val acc 0.4657\n",
      "Epoch 40 | Iter33 | Loss0.2892 | TrainAcc0.9535 | val acc 0.4634\n",
      "Epoch 40 | Iter35 | Loss0.4027 | TrainAcc0.9070 | val acc 0.4681\n",
      "Epoch 40 | Iter37 | Loss0.3173 | TrainAcc0.8837 | val acc 0.4752\n",
      "Epoch 40 | Iter39 | Loss0.1693 | TrainAcc0.9333 | val acc 0.4563\n",
      "Epoch 41 | Iter1 | Loss0.3367 | TrainAcc0.8605 | val acc 0.4586\n",
      "Epoch 41 | Iter3 | Loss0.3281 | TrainAcc0.8605 | val acc 0.4586\n",
      "Epoch 41 | Iter5 | Loss0.4400 | TrainAcc0.8372 | val acc 0.4539\n",
      "Epoch 41 | Iter7 | Loss0.5011 | TrainAcc0.8140 | val acc 0.4539\n",
      "Epoch 41 | Iter9 | Loss0.3969 | TrainAcc0.7674 | val acc 0.4539\n",
      "Epoch 41 | Iter11 | Loss0.4883 | TrainAcc0.7907 | val acc 0.4444\n",
      "Epoch 41 | Iter13 | Loss0.6090 | TrainAcc0.8140 | val acc 0.4421\n",
      "Epoch 41 | Iter15 | Loss0.4967 | TrainAcc0.7442 | val acc 0.4397\n",
      "Epoch 41 | Iter17 | Loss0.4599 | TrainAcc0.9070 | val acc 0.4421\n",
      "Epoch 41 | Iter19 | Loss0.5670 | TrainAcc0.7674 | val acc 0.4823\n",
      "Epoch 41 | Iter21 | Loss0.4506 | TrainAcc0.7674 | val acc 0.4610\n",
      "Epoch 41 | Iter23 | Loss0.3888 | TrainAcc0.8605 | val acc 0.4681\n",
      "Epoch 41 | Iter25 | Loss0.5652 | TrainAcc0.6977 | val acc 0.4634\n",
      "Epoch 41 | Iter27 | Loss0.2445 | TrainAcc1.0000 | val acc 0.4586\n",
      "Epoch 41 | Iter29 | Loss0.4989 | TrainAcc0.8372 | val acc 0.4374\n",
      "Epoch 41 | Iter31 | Loss0.4022 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 41 | Iter33 | Loss0.4047 | TrainAcc0.8140 | val acc 0.4681\n",
      "Epoch 41 | Iter35 | Loss0.3805 | TrainAcc0.8605 | val acc 0.4728\n",
      "Epoch 41 | Iter37 | Loss0.4576 | TrainAcc0.7907 | val acc 0.4728\n",
      "Epoch 41 | Iter39 | Loss0.7801 | TrainAcc0.8000 | val acc 0.4894\n",
      "Epoch 42 | Iter1 | Loss0.5666 | TrainAcc0.7442 | val acc 0.4704\n",
      "Epoch 42 | Iter3 | Loss0.3167 | TrainAcc0.9070 | val acc 0.4728\n",
      "Epoch 42 | Iter5 | Loss0.3947 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 42 | Iter7 | Loss0.3248 | TrainAcc0.8837 | val acc 0.4823\n",
      "Epoch 42 | Iter9 | Loss0.3357 | TrainAcc0.8837 | val acc 0.4634\n",
      "Epoch 42 | Iter11 | Loss0.4328 | TrainAcc0.8140 | val acc 0.4823\n",
      "Epoch 42 | Iter13 | Loss0.3802 | TrainAcc0.8837 | val acc 0.4799\n",
      "Epoch 42 | Iter15 | Loss0.3371 | TrainAcc0.8140 | val acc 0.4752\n",
      "Epoch 42 | Iter17 | Loss0.4024 | TrainAcc0.8837 | val acc 0.4704\n",
      "Epoch 42 | Iter19 | Loss0.3525 | TrainAcc0.8605 | val acc 0.4657\n",
      "Epoch 42 | Iter21 | Loss0.5348 | TrainAcc0.7674 | val acc 0.4586\n",
      "Epoch 42 | Iter23 | Loss0.6451 | TrainAcc0.7209 | val acc 0.4515\n",
      "Epoch 42 | Iter25 | Loss0.5349 | TrainAcc0.7674 | val acc 0.4823\n",
      "Epoch 42 | Iter27 | Loss0.3605 | TrainAcc0.8140 | val acc 0.4681\n",
      "Epoch 42 | Iter29 | Loss0.3866 | TrainAcc0.8605 | val acc 0.4539\n",
      "Epoch 42 | Iter31 | Loss0.3570 | TrainAcc0.8837 | val acc 0.4468\n",
      "Epoch 42 | Iter33 | Loss0.4968 | TrainAcc0.7674 | val acc 0.5035\n",
      "Epoch 42 | Iter35 | Loss0.3895 | TrainAcc0.8372 | val acc 0.4988\n",
      "Epoch 42 | Iter37 | Loss0.5218 | TrainAcc0.7674 | val acc 0.4846\n",
      "Epoch 42 | Iter39 | Loss0.4687 | TrainAcc0.8000 | val acc 0.4279\n",
      "Epoch 43 | Iter1 | Loss0.3566 | TrainAcc0.8605 | val acc 0.4704\n",
      "Epoch 43 | Iter3 | Loss0.5275 | TrainAcc0.8372 | val acc 0.4704\n",
      "Epoch 43 | Iter5 | Loss0.4510 | TrainAcc0.8140 | val acc 0.4917\n",
      "Epoch 43 | Iter7 | Loss0.3321 | TrainAcc0.8605 | val acc 0.4752\n",
      "Epoch 43 | Iter9 | Loss0.3537 | TrainAcc0.8837 | val acc 0.4775\n",
      "Epoch 43 | Iter11 | Loss0.6915 | TrainAcc0.7907 | val acc 0.4657\n",
      "Epoch 43 | Iter13 | Loss0.3669 | TrainAcc0.8372 | val acc 0.4704\n",
      "Epoch 43 | Iter15 | Loss0.3964 | TrainAcc0.8837 | val acc 0.4799\n",
      "Epoch 43 | Iter17 | Loss0.4520 | TrainAcc0.8605 | val acc 0.4894\n",
      "Epoch 43 | Iter19 | Loss0.4601 | TrainAcc0.8372 | val acc 0.4775\n",
      "Epoch 43 | Iter21 | Loss0.4339 | TrainAcc0.8372 | val acc 0.4468\n",
      "Epoch 43 | Iter23 | Loss0.4882 | TrainAcc0.7442 | val acc 0.4657\n",
      "Epoch 43 | Iter25 | Loss0.3496 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 43 | Iter27 | Loss0.3889 | TrainAcc0.8140 | val acc 0.4681\n",
      "Epoch 43 | Iter29 | Loss0.3122 | TrainAcc0.8605 | val acc 0.4657\n",
      "Epoch 43 | Iter31 | Loss0.4896 | TrainAcc0.8140 | val acc 0.4775\n",
      "Epoch 43 | Iter33 | Loss0.4388 | TrainAcc0.8605 | val acc 0.4704\n",
      "Epoch 43 | Iter35 | Loss0.4083 | TrainAcc0.8605 | val acc 0.4752\n",
      "Epoch 43 | Iter37 | Loss0.4278 | TrainAcc0.8605 | val acc 0.4634\n",
      "Epoch 43 | Iter39 | Loss0.7924 | TrainAcc0.7333 | val acc 0.4421\n",
      "Epoch 44 | Iter1 | Loss0.2983 | TrainAcc0.9535 | val acc 0.4681\n",
      "Epoch 44 | Iter3 | Loss0.4268 | TrainAcc0.8605 | val acc 0.4704\n",
      "Epoch 44 | Iter5 | Loss0.4060 | TrainAcc0.8605 | val acc 0.4799\n",
      "Epoch 44 | Iter7 | Loss0.3694 | TrainAcc0.7907 | val acc 0.4846\n",
      "Epoch 44 | Iter9 | Loss0.3237 | TrainAcc0.8605 | val acc 0.5035\n",
      "Epoch 44 | Iter11 | Loss0.7809 | TrainAcc0.8605 | val acc 0.4894\n",
      "Epoch 44 | Iter13 | Loss0.2522 | TrainAcc0.8837 | val acc 0.4704\n",
      "Epoch 44 | Iter15 | Loss0.5851 | TrainAcc0.7674 | val acc 0.4799\n",
      "Epoch 44 | Iter17 | Loss0.3429 | TrainAcc0.8837 | val acc 0.4846\n",
      "Epoch 44 | Iter19 | Loss0.5185 | TrainAcc0.8372 | val acc 0.4492\n",
      "Epoch 44 | Iter21 | Loss0.2716 | TrainAcc0.9070 | val acc 0.4823\n",
      "Epoch 44 | Iter23 | Loss0.5563 | TrainAcc0.7442 | val acc 0.5035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Iter25 | Loss0.6303 | TrainAcc0.8605 | val acc 0.4941\n",
      "Epoch 44 | Iter27 | Loss0.4104 | TrainAcc0.7674 | val acc 0.4917\n",
      "Epoch 44 | Iter29 | Loss0.4760 | TrainAcc0.8605 | val acc 0.4917\n",
      "Epoch 44 | Iter31 | Loss0.3939 | TrainAcc0.8837 | val acc 0.4988\n",
      "Epoch 44 | Iter33 | Loss0.3298 | TrainAcc0.9302 | val acc 0.5083\n",
      "Epoch 44 | Iter35 | Loss0.5192 | TrainAcc0.7674 | val acc 0.4917\n",
      "Epoch 44 | Iter37 | Loss0.6391 | TrainAcc0.7209 | val acc 0.5130\n",
      "Epoch 44 | Iter39 | Loss0.3632 | TrainAcc0.8667 | val acc 0.4681\n",
      "Epoch 45 | Iter1 | Loss0.3845 | TrainAcc0.8605 | val acc 0.4728\n",
      "Epoch 45 | Iter3 | Loss0.4658 | TrainAcc0.8140 | val acc 0.4634\n",
      "Epoch 45 | Iter5 | Loss0.3887 | TrainAcc0.8140 | val acc 0.4823\n",
      "Epoch 45 | Iter7 | Loss0.2841 | TrainAcc0.9535 | val acc 0.5059\n",
      "Epoch 45 | Iter9 | Loss0.3636 | TrainAcc0.8605 | val acc 0.4965\n",
      "Epoch 45 | Iter11 | Loss0.3230 | TrainAcc0.8605 | val acc 0.4870\n",
      "Epoch 45 | Iter13 | Loss0.8673 | TrainAcc0.6977 | val acc 0.5106\n",
      "Epoch 45 | Iter15 | Loss0.7052 | TrainAcc0.6512 | val acc 0.4704\n",
      "Epoch 45 | Iter17 | Loss0.4522 | TrainAcc0.8605 | val acc 0.4728\n",
      "Epoch 45 | Iter19 | Loss0.4351 | TrainAcc0.8140 | val acc 0.4917\n",
      "Epoch 45 | Iter21 | Loss0.3636 | TrainAcc0.8372 | val acc 0.4799\n",
      "Epoch 45 | Iter23 | Loss0.2909 | TrainAcc0.9535 | val acc 0.4799\n",
      "Epoch 45 | Iter25 | Loss0.3173 | TrainAcc0.9070 | val acc 0.4870\n",
      "Epoch 45 | Iter27 | Loss0.4962 | TrainAcc0.8140 | val acc 0.4823\n",
      "Epoch 45 | Iter29 | Loss0.3403 | TrainAcc0.8837 | val acc 0.4846\n",
      "Epoch 45 | Iter31 | Loss0.4110 | TrainAcc0.8372 | val acc 0.4941\n",
      "Epoch 45 | Iter33 | Loss0.3687 | TrainAcc0.9302 | val acc 0.4917\n",
      "Epoch 45 | Iter35 | Loss0.4261 | TrainAcc0.8372 | val acc 0.4870\n",
      "Epoch 45 | Iter37 | Loss0.4493 | TrainAcc0.8372 | val acc 0.4634\n",
      "Epoch 45 | Iter39 | Loss0.9404 | TrainAcc0.6000 | val acc 0.4681\n",
      "Epoch 46 | Iter1 | Loss0.3460 | TrainAcc0.8837 | val acc 0.4634\n",
      "Epoch 46 | Iter3 | Loss0.4082 | TrainAcc0.8140 | val acc 0.4704\n",
      "Epoch 46 | Iter5 | Loss0.5242 | TrainAcc0.7209 | val acc 0.4917\n",
      "Epoch 46 | Iter7 | Loss0.4082 | TrainAcc0.7907 | val acc 0.4894\n",
      "Epoch 46 | Iter9 | Loss0.3156 | TrainAcc0.9070 | val acc 0.4846\n",
      "Epoch 46 | Iter11 | Loss0.3286 | TrainAcc0.9070 | val acc 0.4775\n",
      "Epoch 46 | Iter13 | Loss0.3954 | TrainAcc0.8372 | val acc 0.4799\n",
      "Epoch 46 | Iter15 | Loss0.4056 | TrainAcc0.8140 | val acc 0.4799\n",
      "Epoch 46 | Iter17 | Loss0.6082 | TrainAcc0.6744 | val acc 0.4515\n",
      "Epoch 46 | Iter19 | Loss0.4513 | TrainAcc0.8372 | val acc 0.4704\n",
      "Epoch 46 | Iter21 | Loss0.4598 | TrainAcc0.8605 | val acc 0.4799\n",
      "Epoch 46 | Iter23 | Loss0.2862 | TrainAcc0.8837 | val acc 0.4634\n",
      "Epoch 46 | Iter25 | Loss0.5194 | TrainAcc0.8140 | val acc 0.4965\n",
      "Epoch 46 | Iter27 | Loss0.4621 | TrainAcc0.7442 | val acc 0.4823\n",
      "Epoch 46 | Iter29 | Loss0.3423 | TrainAcc0.9070 | val acc 0.4846\n",
      "Epoch 46 | Iter31 | Loss0.3498 | TrainAcc0.7907 | val acc 0.4917\n",
      "Epoch 46 | Iter33 | Loss0.3582 | TrainAcc0.8605 | val acc 0.4846\n",
      "Epoch 46 | Iter35 | Loss0.4516 | TrainAcc0.8140 | val acc 0.4988\n",
      "Epoch 46 | Iter37 | Loss0.3922 | TrainAcc0.7907 | val acc 0.4799\n",
      "Epoch 46 | Iter39 | Loss0.3769 | TrainAcc0.8000 | val acc 0.4539\n",
      "Epoch 47 | Iter1 | Loss0.3891 | TrainAcc0.8372 | val acc 0.4775\n",
      "Epoch 47 | Iter3 | Loss0.3497 | TrainAcc0.8140 | val acc 0.4775\n",
      "Epoch 47 | Iter5 | Loss0.7018 | TrainAcc0.7674 | val acc 0.5012\n",
      "Epoch 47 | Iter7 | Loss0.3578 | TrainAcc0.9070 | val acc 0.4917\n",
      "Epoch 47 | Iter9 | Loss0.3265 | TrainAcc0.9070 | val acc 0.5035\n",
      "Epoch 47 | Iter11 | Loss0.4685 | TrainAcc0.8605 | val acc 0.4775\n",
      "Epoch 47 | Iter13 | Loss0.3801 | TrainAcc0.8372 | val acc 0.4941\n",
      "Epoch 47 | Iter15 | Loss0.5243 | TrainAcc0.7674 | val acc 0.4823\n",
      "Epoch 47 | Iter17 | Loss0.4575 | TrainAcc0.7907 | val acc 0.4846\n",
      "Epoch 47 | Iter19 | Loss0.3255 | TrainAcc0.9070 | val acc 0.4917\n",
      "Epoch 47 | Iter21 | Loss0.3000 | TrainAcc0.8837 | val acc 0.4917\n",
      "Epoch 47 | Iter23 | Loss0.5635 | TrainAcc0.7674 | val acc 0.4468\n",
      "Epoch 47 | Iter25 | Loss0.3862 | TrainAcc0.8372 | val acc 0.4681\n",
      "Epoch 47 | Iter27 | Loss0.2677 | TrainAcc0.8837 | val acc 0.4539\n",
      "Epoch 47 | Iter29 | Loss0.4778 | TrainAcc0.7674 | val acc 0.4728\n",
      "Epoch 47 | Iter31 | Loss0.3187 | TrainAcc0.9070 | val acc 0.4728\n",
      "Epoch 47 | Iter33 | Loss0.2984 | TrainAcc0.9302 | val acc 0.4752\n",
      "Epoch 47 | Iter35 | Loss0.5082 | TrainAcc0.7674 | val acc 0.4752\n",
      "Epoch 47 | Iter37 | Loss0.4357 | TrainAcc0.8372 | val acc 0.4704\n",
      "Epoch 47 | Iter39 | Loss0.4563 | TrainAcc0.8667 | val acc 0.4539\n",
      "Epoch 48 | Iter1 | Loss0.5508 | TrainAcc0.6977 | val acc 0.4799\n",
      "Epoch 48 | Iter3 | Loss0.3434 | TrainAcc0.8837 | val acc 0.4752\n",
      "Epoch 48 | Iter5 | Loss0.2343 | TrainAcc0.9767 | val acc 0.4704\n",
      "Epoch 48 | Iter7 | Loss0.5608 | TrainAcc0.7907 | val acc 0.4610\n",
      "Epoch 48 | Iter9 | Loss0.3167 | TrainAcc0.8837 | val acc 0.4657\n",
      "Epoch 48 | Iter11 | Loss0.3160 | TrainAcc0.9302 | val acc 0.4657\n",
      "Epoch 48 | Iter13 | Loss0.4611 | TrainAcc0.8605 | val acc 0.4634\n",
      "Epoch 48 | Iter15 | Loss0.3074 | TrainAcc0.9302 | val acc 0.4894\n",
      "Epoch 48 | Iter17 | Loss0.2814 | TrainAcc0.9302 | val acc 0.4775\n",
      "Epoch 48 | Iter19 | Loss0.4056 | TrainAcc0.8605 | val acc 0.4870\n",
      "Epoch 48 | Iter21 | Loss0.3580 | TrainAcc0.8605 | val acc 0.4799\n",
      "Epoch 48 | Iter23 | Loss0.3672 | TrainAcc0.8140 | val acc 0.4752\n",
      "Epoch 48 | Iter25 | Loss0.3966 | TrainAcc0.8605 | val acc 0.4775\n",
      "Epoch 48 | Iter27 | Loss0.3708 | TrainAcc0.8605 | val acc 0.4586\n",
      "Epoch 48 | Iter29 | Loss0.3038 | TrainAcc0.8837 | val acc 0.4681\n",
      "Epoch 48 | Iter31 | Loss0.4225 | TrainAcc0.8605 | val acc 0.4610\n",
      "Epoch 48 | Iter33 | Loss0.2796 | TrainAcc0.8837 | val acc 0.4657\n",
      "Epoch 48 | Iter35 | Loss0.3137 | TrainAcc0.9302 | val acc 0.4704\n",
      "Epoch 48 | Iter37 | Loss0.4803 | TrainAcc0.7442 | val acc 0.4657\n",
      "Epoch 48 | Iter39 | Loss0.3770 | TrainAcc0.8667 | val acc 0.4610\n",
      "Test accuracy is:  0.5033860045146726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12db4a358>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "for epoch in range(49):\n",
    "    for i , data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        if i % 2 == 1:\n",
    "            net.eval()\n",
    "            val_correct, val_total = 0, 0 \n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data\n",
    "                val_outputs = net(val_images)\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (val_predicted == val_labels).sum().item()\n",
    "            val_acc = val_correct / val_total\n",
    "            print('Epoch {} | Iter{} | Loss{:.4f} | TrainAcc{:.4f} | val acc {:.4f}'.format(\n",
    "                epoch, i , loss, train_acc, val_acc))\n",
    "            #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "    net.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    for train_data in train_loader:\n",
    "        train_inputs, train_labels = train_data\n",
    "        train_outputs = net(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    val_correct, val_total = 0, 0\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data\n",
    "        val_outputs = net(val_images)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    #if val_acc == max(val_acc_history):\n",
    "    #    net_best = Net()\n",
    "    #    net_best.load_state_dict(net.state_dict())\n",
    "        \n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader:\n",
    "    test_images, test_labels = test_data\n",
    "    test_outputs = net(test_images)\n",
    "    #test_outputs = net_best(test_images)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)\n",
    "plt.plot(train_acc_history,)\n",
    "plt.plot(val_acc_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train_acc','val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training Net 1\n",
      "Epoch 0 | Iter1 | Loss1.4155 | val acc 0.2340\n",
      "Epoch 0 | Iter3 | Loss1.8619 | val acc 0.2270\n",
      "Epoch 0 | Iter5 | Loss1.3685 | val acc 0.2388\n",
      "Epoch 0 | Iter7 | Loss1.5422 | val acc 0.2317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-30196b2d8baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mval_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-9a3ff9081247>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m61\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/2020 winter ucla/ece 247/project/.env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net_1 = Net()\n",
    "net_2 = Net()\n",
    "net_3 = Net()\n",
    "net_4 = Net()\n",
    "net_5 = Net()\n",
    "net_6 = Net()\n",
    "net_7 = Net()\n",
    "list_net = [net_1, net_2, net_3, net_4, net_5, net_6, net_7]\n",
    "list_best_net = [Net(), Net(), Net(), Net(), Net(), Net(), Net()]\n",
    "for n,net in enumerate(list_net):\n",
    "    #val_acc_history = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)\n",
    "    print('--------------------------------------------------')\n",
    "    print('Training Net {}'.format(n+1))\n",
    "    for epoch in range(35):\n",
    "        for i , data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 2 == 1:\n",
    "                net.eval()\n",
    "                val_correct, val_total = 0, 0 \n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data\n",
    "                    val_outputs = net(val_images)\n",
    "                    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                    val_total += val_labels.size(0)\n",
    "                    val_correct += (val_predicted == val_labels).sum().item()\n",
    "                val_acc = val_correct / val_total\n",
    "                print('Epoch {} | Iter{} | Loss{:.4f} | val acc {:.4f}'.format(\n",
    "                    epoch, i , loss, val_acc))\n",
    "                #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "        #val_correct, val_total = 0, 0\n",
    "        #for val_data in val_loader_1:\n",
    "        #    val_images, val_labels = val_data\n",
    "        #    val_outputs = net(val_images)\n",
    "        #    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        #    val_total += val_labels.size(0)\n",
    "        #    val_correct += (val_predicted == val_labels).sum().item()\n",
    "        #val_acc = val_correct / val_total\n",
    "        #val_acc_history.append(val_acc)\n",
    "        #if val_acc == max(val_acc_history):\n",
    "        #    list_best_net[n] = Net()\n",
    "        #    list_best_net[n].load_state_dict(net.state_dict())\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader:\n",
    "    test_images, test_labels = test_data\n",
    "    test_predicted_list = []\n",
    "    for net in list_net:\n",
    "    #for net_best in list_best_net:\n",
    "        test_outputs = net(test_images)\n",
    "        #test_outputs = net_best(test_images)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_predicted_list.append(test_predicted.numpy())\n",
    "    test_predicted_list = np.array(test_predicted_list)\n",
    "    test_predicted_result = []\n",
    "    for vote in range(np.shape(test_predicted_list)[1]):\n",
    "        test_predicted_result.append(Counter(test_predicted_list[:,vote]).most_common(1)[0][0])\n",
    "    test_predicted = torch.Tensor(test_predicted_result)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  20  40  80 110]\n",
      " [ 30  50  45  60  90]]\n",
      "[[ 10  20  40  80 110  10  20  40  80]\n",
      " [ 30  50  45  60  90  30  50  45  60]]\n",
      "[30 80]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[10, 20, 40, 80, 110],[30,50,45,60,90]])\n",
    "print(b)\n",
    "c = np.array([[10, 20, 40, 80],[30,50,45,60]])\n",
    "d = np.append(b,c, axis=1)\n",
    "print(d)\n",
    "print((d[:,0] + d[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   15.   20.   30.   40.   60.   80.   95.  110.  110. ]\n",
      " [ 30.   40.   50.   47.5  45.   52.5  60.   75.   90.   90. ]]\n"
     ]
    }
   ],
   "source": [
    "def double_ax1(a):\n",
    "    result = np.zeros((a.shape[0],a.shape[1] * 2))\n",
    "    b = np.reshape(a[:,-1],(a.shape[0],1))\n",
    "    aMod = np.concatenate((a,b),axis = 1)\n",
    "    for i in range(a.shape[1]):\n",
    "        ave = (aMod[:,i] + aMod[:,i+1]) / 2\n",
    "        result[:,2 * i] = aMod[:,i]\n",
    "        result[:, 2*i + 1] = ave\n",
    "    return result\n",
    "    \n",
    "arr = np.array([[10, 20, 40, 80, 110],[30,50,45,60,90]])\n",
    "x = double_ax1(arr)\n",
    "print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[10, 20, 40, 80, 110],[30,50,45,60,90]])\n",
    "print(a.shape)\n",
    "result = np.zeros((a.shape[0],a.shape[1] * 2))\n",
    "print(a[:,-1])\n",
    "b = np.reshape(a[:,-1],(a.shape[0],1))\n",
    "aMod = np.concatenate((a,b),axis = 1)\n",
    "print(aMod)\n",
    "for i in range(a.shape[1]):\n",
    "    ave = (aMod[:,i] + aMod[:,i+1]) / 2\n",
    "    result[:,2 * i] = aMod[:,i]\n",
    "    result[:, 2*i + 1] = ave\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
