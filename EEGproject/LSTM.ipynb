{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./project/X_test.npy\")\n",
    "y_test = np.load(\"./project/y_test.npy\")\n",
    "person_train_valid = np.load(\"./project/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./project/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./project/y_train_valid.npy\")\n",
    "person_test = np.load(\"./project/person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([111.,   0.,   0., 127.,   0.,   0.,  96.,   0.,   0., 109.]),\n",
       " array([769. , 769.3, 769.6, 769.9, 770.2, 770.5, 770.8, 771.1, 771.4,\n",
       "        771.7, 772. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train_valid)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#无downsample预处理过程\n",
    "# For subject 1\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True)\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "X_train_1 = X_train_1.transpose(0,2,1)\n",
    "X_valid_1 = X_valid_1.transpose(0,2,1)\n",
    "X_test_1 = X_test_1.transpose(0,2,1)\n",
    "train_set_1 = Dataset(X_train_1,y_train_1)\n",
    "val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "torch.Size([32, 1000, 22]) torch.Size([32])\n",
      "torch.Size([32, 1000, 22]) torch.Size([32])\n",
      "torch.Size([32, 1000, 22]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_1.shape[0])\n",
    "for i, data in enumerate(train_loader_1):\n",
    "    print(data[0].shape, data[1].shape)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 22, 500)\n",
      "(378,)\n",
      "(96, 22, 500)\n",
      "(50, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "#包含嵘哥的downsample预处理过程\n",
    "# for one subject\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True)\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "num_time = X_train_valid.shape[2]\n",
    "sample_1 = list(np.arange(0,num_time,2))\n",
    "sample_2 = list(np.arange(1,num_time,2))\n",
    "\n",
    "X_train_1 = X_train[:,:,sample_1]\n",
    "X_train_2 = X_train[:,:,sample_2]\n",
    "\n",
    "X_val_1 = X_valid[:,:,sample_1]\n",
    "X_val_2 = X_valid[:,:,sample_2]\n",
    "\n",
    "X_test_s1 = X_test_1[:,:,sample_1]\n",
    "X_test_s2 = X_test_1[:,:,sample_2]\n",
    "\n",
    "X_train_s = np.concatenate((X_train_1,X_train_2), axis=0)\n",
    "y_train_s = np.concatenate((y_train,y_train), axis=0)\n",
    "\n",
    "X_val_s = np.concatenate((X_val_1,X_val_2), axis=0)\n",
    "y_val_s = np.concatenate((y_valid,y_valid), axis=0)\n",
    "\n",
    "#person_train_s = np.concatenate((person_train_valid,person_train_valid), axis=0)\n",
    "\n",
    "#X_test_s = np.concatenate((X_test_s1,X_test_s2), axis=0)\n",
    "X_test_s = X_test_s1\n",
    "#y_test_s = np.concatenate((y_test,y_test), axis=0)\n",
    "y_test_s = y_test_1\n",
    "#person_test_s = np.concatenate((person_test,person_test), axis=0)\n",
    "#person_test_s = person_test\n",
    "print(X_train_s.shape)\n",
    "print(y_train_s.shape)\n",
    "print(X_val_s.shape)\n",
    "print(X_test_s.shape)\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "X_train_s = X_train_s.transpose(0,2,1)\n",
    "X_val_s = X_val_s.transpose(0,2,1)\n",
    "X_test_s = X_test_s.transpose(0,2,1)\n",
    "train_set_1 = Dataset(X_train_s,y_train_s)\n",
    "val_set_1 = Dataset(X_val_s,y_val_s)\n",
    "test_set_1 = Dataset(X_test_s, y_test_s)\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "torch.Size([32, 500, 22]) torch.Size([32])\n",
      "torch.Size([32, 500, 22]) torch.Size([32])\n",
      "torch.Size([32, 500, 22]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s.shape[0])\n",
    "for i, data in enumerate(train_loader_1):\n",
    "    print(data[0].shape, data[1].shape)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(22, 40, kernel_size=(2,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(40, 60, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(60, 80, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(80, 100, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv1d(100, 120, kernel_size=(3,), stride=(2,))\n",
      "  (bn5): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=7320, out_features=300, bias=True)\n",
      "  (bn6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.8, inplace=False)\n",
      "  (fc2): Linear(in_features=300, out_features=40, bias=True)\n",
      "  (bn7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop2): Dropout(p=0.8, inplace=False)\n",
      "  (fc3): Linear(in_features=40, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#和CNN.ipynb中一样的结构，这里想训练出一个较好的CNN并且提取前两层作为之后的LSTM之前用来提取特征的工具\n",
    "# [conv-relu]*2 -> 2*2 max-pooling -> [conv-relu]*3 -> 2*2 max_pooling -> (affine-relu)*2 -> affine -> softmax\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.MaxPool1d(2,2) \n",
    "        \n",
    "        self.conv3 = nn.Conv1d(60,80,kernel_size = 3, stride = 1) \n",
    "        self.bn3 = nn.BatchNorm1d(80)\n",
    "        self.conv4 = nn.Conv1d(80,100,kernel_size = 3, stride = 1) \n",
    "        self.bn4 = nn.BatchNorm1d(100)\n",
    "        self.conv5 = nn.Conv1d(100,120,kernel_size = 3, stride = 2) #120*122\n",
    "        self.bn5 = nn.BatchNorm1d(120)\n",
    "        self.pool2 = nn.MaxPool1d(2,2) #120*61\n",
    "        \n",
    "        self.fc1 = nn.Linear(120*61, 300) # input dim , output dim\n",
    "        self.bn6 = nn.BatchNorm1d(300)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(300,40)  \n",
    "        self.bn7 = nn.BatchNorm1d(40)\n",
    "        self.drop2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(40,4)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = torch.Tensor(x.numpy().transpose(0,2,1))\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = x.view(-1,120*61)\n",
    "        \n",
    "        x = self.drop1(F.relu(self.bn6(self.fc1(x))))\n",
    "        x = self.drop2(F.relu(self.bn7(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter1 | Loss1.6201 | TrainAcc0.1250 | val acc 0.3750\n",
      "Epoch 0 | Iter3 | Loss1.3951 | TrainAcc0.3438 | val acc 0.3750\n",
      "Epoch 0 | Iter5 | Loss1.4615 | TrainAcc0.3793 | val acc 0.3750\n",
      "Epoch 1 | Iter1 | Loss1.4310 | TrainAcc0.2188 | val acc 0.3750\n",
      "Epoch 1 | Iter3 | Loss1.3499 | TrainAcc0.3438 | val acc 0.3750\n",
      "Epoch 1 | Iter5 | Loss1.6441 | TrainAcc0.2069 | val acc 0.3750\n",
      "Epoch 2 | Iter1 | Loss1.2853 | TrainAcc0.4688 | val acc 0.3750\n",
      "Epoch 2 | Iter3 | Loss1.2487 | TrainAcc0.3750 | val acc 0.3750\n",
      "Epoch 2 | Iter5 | Loss1.2691 | TrainAcc0.4483 | val acc 0.3125\n",
      "Epoch 3 | Iter1 | Loss1.3575 | TrainAcc0.4688 | val acc 0.3333\n",
      "Epoch 3 | Iter3 | Loss1.3721 | TrainAcc0.2188 | val acc 0.3333\n",
      "Epoch 3 | Iter5 | Loss1.4464 | TrainAcc0.2414 | val acc 0.3958\n",
      "Epoch 4 | Iter1 | Loss1.3905 | TrainAcc0.3438 | val acc 0.2500\n",
      "Epoch 4 | Iter3 | Loss1.6627 | TrainAcc0.4062 | val acc 0.2500\n",
      "Epoch 4 | Iter5 | Loss1.0573 | TrainAcc0.4828 | val acc 0.2292\n",
      "Epoch 5 | Iter1 | Loss1.0601 | TrainAcc0.5938 | val acc 0.2292\n",
      "Epoch 5 | Iter3 | Loss1.3128 | TrainAcc0.3125 | val acc 0.2083\n",
      "Epoch 5 | Iter5 | Loss1.0372 | TrainAcc0.6207 | val acc 0.2292\n",
      "Epoch 6 | Iter1 | Loss1.1131 | TrainAcc0.5938 | val acc 0.2292\n",
      "Epoch 6 | Iter3 | Loss1.1172 | TrainAcc0.5625 | val acc 0.2917\n",
      "Epoch 6 | Iter5 | Loss1.1418 | TrainAcc0.5172 | val acc 0.3125\n",
      "Epoch 7 | Iter1 | Loss1.1024 | TrainAcc0.5625 | val acc 0.3542\n",
      "Epoch 7 | Iter3 | Loss1.1880 | TrainAcc0.4062 | val acc 0.4375\n",
      "Epoch 7 | Iter5 | Loss1.1840 | TrainAcc0.4483 | val acc 0.3958\n",
      "Epoch 8 | Iter1 | Loss1.2224 | TrainAcc0.3438 | val acc 0.3958\n",
      "Epoch 8 | Iter3 | Loss1.0331 | TrainAcc0.5938 | val acc 0.3542\n",
      "Epoch 8 | Iter5 | Loss1.1035 | TrainAcc0.3793 | val acc 0.3750\n",
      "Epoch 9 | Iter1 | Loss0.9552 | TrainAcc0.6875 | val acc 0.4167\n",
      "Epoch 9 | Iter3 | Loss1.1768 | TrainAcc0.5000 | val acc 0.4375\n",
      "Epoch 9 | Iter5 | Loss1.0164 | TrainAcc0.5172 | val acc 0.4583\n",
      "Epoch 10 | Iter1 | Loss0.9924 | TrainAcc0.5312 | val acc 0.4375\n",
      "Epoch 10 | Iter3 | Loss0.8437 | TrainAcc0.7188 | val acc 0.3542\n",
      "Epoch 10 | Iter5 | Loss1.0407 | TrainAcc0.5517 | val acc 0.3958\n",
      "Epoch 11 | Iter1 | Loss0.9059 | TrainAcc0.6875 | val acc 0.3542\n",
      "Epoch 11 | Iter3 | Loss0.8968 | TrainAcc0.6562 | val acc 0.3958\n",
      "Epoch 11 | Iter5 | Loss0.9376 | TrainAcc0.5517 | val acc 0.3958\n",
      "Epoch 12 | Iter1 | Loss0.8892 | TrainAcc0.6250 | val acc 0.3333\n",
      "Epoch 12 | Iter3 | Loss1.0148 | TrainAcc0.5625 | val acc 0.3542\n",
      "Epoch 12 | Iter5 | Loss0.7908 | TrainAcc0.7241 | val acc 0.3750\n",
      "Epoch 13 | Iter1 | Loss1.0173 | TrainAcc0.6250 | val acc 0.3750\n",
      "Epoch 13 | Iter3 | Loss0.7523 | TrainAcc0.8125 | val acc 0.3750\n",
      "Epoch 13 | Iter5 | Loss1.0200 | TrainAcc0.5517 | val acc 0.3958\n",
      "Epoch 14 | Iter1 | Loss0.8567 | TrainAcc0.6875 | val acc 0.4583\n",
      "Epoch 14 | Iter3 | Loss0.9328 | TrainAcc0.5312 | val acc 0.4375\n",
      "Epoch 14 | Iter5 | Loss0.8794 | TrainAcc0.6207 | val acc 0.4583\n",
      "Epoch 15 | Iter1 | Loss0.9156 | TrainAcc0.5938 | val acc 0.3958\n",
      "Epoch 15 | Iter3 | Loss0.7673 | TrainAcc0.6562 | val acc 0.4375\n",
      "Epoch 15 | Iter5 | Loss0.7497 | TrainAcc0.7586 | val acc 0.4792\n",
      "Epoch 16 | Iter1 | Loss0.8337 | TrainAcc0.7812 | val acc 0.3958\n",
      "Epoch 16 | Iter3 | Loss0.7417 | TrainAcc0.7812 | val acc 0.4167\n",
      "Epoch 16 | Iter5 | Loss0.8379 | TrainAcc0.6207 | val acc 0.3958\n",
      "Epoch 17 | Iter1 | Loss0.6920 | TrainAcc0.7812 | val acc 0.4583\n",
      "Epoch 17 | Iter3 | Loss0.7822 | TrainAcc0.7500 | val acc 0.5000\n",
      "Epoch 17 | Iter5 | Loss0.6621 | TrainAcc0.7931 | val acc 0.5625\n",
      "Epoch 18 | Iter1 | Loss0.7429 | TrainAcc0.7500 | val acc 0.5000\n",
      "Epoch 18 | Iter3 | Loss0.7542 | TrainAcc0.7812 | val acc 0.5417\n",
      "Epoch 18 | Iter5 | Loss0.7934 | TrainAcc0.6552 | val acc 0.5208\n",
      "Epoch 19 | Iter1 | Loss0.7546 | TrainAcc0.6875 | val acc 0.4792\n",
      "Epoch 19 | Iter3 | Loss0.7485 | TrainAcc0.7500 | val acc 0.4792\n",
      "Epoch 19 | Iter5 | Loss0.7571 | TrainAcc0.6897 | val acc 0.5000\n",
      "Epoch 20 | Iter1 | Loss0.6981 | TrainAcc0.7500 | val acc 0.5625\n",
      "Epoch 20 | Iter3 | Loss0.8538 | TrainAcc0.6562 | val acc 0.4792\n",
      "Epoch 20 | Iter5 | Loss0.5833 | TrainAcc0.8621 | val acc 0.5000\n",
      "Epoch 21 | Iter1 | Loss0.8062 | TrainAcc0.6562 | val acc 0.4792\n",
      "Epoch 21 | Iter3 | Loss0.5443 | TrainAcc0.8438 | val acc 0.4792\n",
      "Epoch 21 | Iter5 | Loss0.6143 | TrainAcc0.7931 | val acc 0.4375\n",
      "Epoch 22 | Iter1 | Loss0.6596 | TrainAcc0.8438 | val acc 0.4167\n",
      "Epoch 22 | Iter3 | Loss0.7350 | TrainAcc0.6250 | val acc 0.4792\n",
      "Epoch 22 | Iter5 | Loss0.6372 | TrainAcc0.8276 | val acc 0.4375\n",
      "Epoch 23 | Iter1 | Loss0.6258 | TrainAcc0.8438 | val acc 0.5000\n",
      "Epoch 23 | Iter3 | Loss0.7422 | TrainAcc0.6875 | val acc 0.5000\n",
      "Epoch 23 | Iter5 | Loss0.6233 | TrainAcc0.8276 | val acc 0.5417\n",
      "Epoch 24 | Iter1 | Loss0.6940 | TrainAcc0.7812 | val acc 0.4375\n",
      "Epoch 24 | Iter3 | Loss0.7637 | TrainAcc0.6562 | val acc 0.5000\n",
      "Epoch 24 | Iter5 | Loss0.4639 | TrainAcc0.7931 | val acc 0.5208\n",
      "Epoch 25 | Iter1 | Loss0.6696 | TrainAcc0.7500 | val acc 0.5000\n",
      "Epoch 25 | Iter3 | Loss0.5798 | TrainAcc0.8750 | val acc 0.5000\n",
      "Epoch 25 | Iter5 | Loss0.4775 | TrainAcc0.8966 | val acc 0.5417\n",
      "Epoch 26 | Iter1 | Loss0.6567 | TrainAcc0.8125 | val acc 0.5000\n",
      "Epoch 26 | Iter3 | Loss0.5595 | TrainAcc0.7188 | val acc 0.5417\n",
      "Epoch 26 | Iter5 | Loss0.6617 | TrainAcc0.7241 | val acc 0.5625\n",
      "Epoch 27 | Iter1 | Loss0.4737 | TrainAcc0.9375 | val acc 0.6250\n",
      "Epoch 27 | Iter3 | Loss0.7107 | TrainAcc0.7500 | val acc 0.2500\n",
      "Epoch 27 | Iter5 | Loss0.6274 | TrainAcc0.6897 | val acc 0.4583\n",
      "Epoch 28 | Iter1 | Loss0.5396 | TrainAcc0.7812 | val acc 0.5000\n",
      "Epoch 28 | Iter3 | Loss0.6174 | TrainAcc0.7188 | val acc 0.5208\n",
      "Epoch 28 | Iter5 | Loss0.6409 | TrainAcc0.6897 | val acc 0.5417\n",
      "Epoch 29 | Iter1 | Loss0.6021 | TrainAcc0.8438 | val acc 0.5417\n",
      "Epoch 29 | Iter3 | Loss0.5066 | TrainAcc0.8750 | val acc 0.6042\n",
      "Epoch 29 | Iter5 | Loss0.4188 | TrainAcc0.9310 | val acc 0.5417\n",
      "Test accuracy is:  0.52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a5a4935f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)\n",
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "for epoch in range(30):\n",
    "    for i , data in enumerate(train_loader_1, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        if i % 2 == 1:\n",
    "            net.eval()\n",
    "            val_correct, val_total = 0, 0 \n",
    "            for val_data in val_loader_1:\n",
    "                val_images, val_labels = val_data\n",
    "                val_outputs = net(val_images)\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (val_predicted == val_labels).sum().item()\n",
    "            val_acc = val_correct / val_total\n",
    "            print('Epoch {} | Iter{} | Loss{:.4f} | TrainAcc{:.4f} | val acc {:.4f}'.format(\n",
    "                epoch, i , loss, train_acc, val_acc))\n",
    "            #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "    net.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    for train_data in train_loader_1:\n",
    "        train_inputs, train_labels = train_data\n",
    "        train_outputs = net(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    val_correct, val_total = 0, 0\n",
    "    for val_data in val_loader_1:\n",
    "        val_images, val_labels = val_data\n",
    "        val_outputs = net(val_images)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    #if val_acc == max(val_acc_history):\n",
    "    #    net_best = Net()\n",
    "    #    net_best.load_state_dict(net.state_dict())\n",
    "        \n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_inputs, test_labels = test_data\n",
    "    \n",
    "    test_outputs = net(test_inputs)\n",
    "    #test_outputs = net_best(test_images)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)\n",
    "plt.plot(train_acc_history,)\n",
    "plt.plot(val_acc_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train_acc','val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个只包含上面的CNN的前两层的class\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()  # initial the model\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.MaxPool1d(2,2) \n",
    " \n",
    "    def forward(self,x):\n",
    "        x = torch.Tensor(x.numpy().transpose(0,2,1))\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
    "        x = torch.Tensor(x.detach().numpy().transpose(0,2,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#把已经train了的CNN的前两层提取出来，作为之后的LSTM之前用来提取特征的工具\n",
    "convnet = ConvNet()\n",
    "pretrained_dict = net.state_dict()\n",
    "convnet_dict = convnet.state_dict()\n",
    "pretrained_dict = {k:v for k,v in pretrained_dict.items() if k in convnet_dict}\n",
    "convnet_dict.update(pretrained_dict)\n",
    "convnet.load_state_dict(convnet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两层CNN + 三层LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        #self.conv = convnet  #这个是用已经训练过得到的CNN\n",
    "        self.conv = ConvNet()  #这个是用没有训练过的CNN\n",
    "        self.LSTM1 = nn.LSTM(input_dim, hidden_dim1, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        self.LSTM2 = nn.LSTM(hidden_dim1*2, hidden_dim2, bidirectional = True, batch_first = True)\n",
    "        self.LSTM3 = nn.LSTM(hidden_dim2*2, hidden_dim3, bidirectional = True, batch_first = True)\n",
    "        self.fc1 = nn.Linear(hidden_dim3*2*124, 1000) #要取决于用那种数据，249对应未处理的数据，124对应嵘哥的downsample数据（嵘哥ds！）\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        self.drop1 = nn.Dropout(0.9)\n",
    "        self.fc2 = nn.Linear(1000,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        x = self.conv(x)\n",
    "        if type(h) == type(None) and type(c) == type(None):\n",
    "            out, (hn, cn) = self.LSTM1(x)\n",
    "            out, (hn, cn) = self.LSTM2(out)\n",
    "            out, (hn, cn) = self.LSTM3(out)\n",
    "        else:\n",
    "            out, (hn, cn) = self.LSTM1(x, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM2(out, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM3(out, h.detach(), c.detach())\n",
    "        #out = self.drop1(F.relu(self.bn1(self.fc1(out[:, -1, :]))))\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(out.reshape(out.shape[0],-1)))))\n",
    "        out = self.drop1(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两层CNN + 两层LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        #self.conv = convnet  #这个是用已经训练过得到的CNN\n",
    "        self.conv = ConvNet()  #这个是用没有训练过的CNN\n",
    "        self.LSTM1 = nn.LSTM(input_dim, hidden_dim1, bidirectional = True, num_layers = 2, batch_first = True, dropout = 0)\n",
    "        self.LSTM2 = nn.LSTM(hidden_dim1*2, hidden_dim2, bidirectional = True, num_layers = 2, batch_first = True, dropout = 0.6)\n",
    "        self.fc1 = nn.Linear(hidden_dim2*2*124, 1000)  #要取决于用那种数据，249对应未处理的数据，124对应嵘哥的downsample数据（嵘哥ds！）\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(1000,100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        x = self.conv(x)\n",
    "        if type(h) == type(None) and type(c) == type(None):\n",
    "            out, (hn, cn) = self.LSTM1(x)\n",
    "            out, (hn, cn) = self.LSTM2(out)\n",
    "        else:\n",
    "            out, (hn, cn) = self.LSTM1(x, h.detach(), c.detach())\n",
    "            out, (hn, cn) = self.LSTM2(out, h.detach(), c.detach())\n",
    "        #out = self.drop1(F.relu(self.bn1(self.fc1(out[:, -1, :]))))\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(out.reshape(out.shape[0],-1)))))\n",
    "        out = self.drop1(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两层CNN + 一层LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        #self.conv = convnet  #这个是用已经训练过得到的CNN\n",
    "        self.conv = ConvNet()  #这个是用没有训练过的CNN\n",
    "        self.LSTM = nn.LSTM(input_dim, hidden_dim, bidirectional = True, num_layers=1, batch_first = True, dropout = 0)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2*124, 1000)\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(1000,4)\n",
    "    \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if type(h) == type(None) and type(c) == type(None):\n",
    "            out, (hn, cn) = self.LSTM(x)\n",
    "        else:\n",
    "            out, (hn, cn) = self.LSTM(x, h.detach(), c.detach())\n",
    "        #out = self.drop1(F.relu(self.bn1(self.fc1(out[:, -1, :]))))\n",
    "        out = self.drop1(F.relu(self.bn1(self.fc1(out.reshape(out.shape[0],-1)))))\n",
    "        out = self.fc2(out)\n",
    "         \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 60\n",
    "hidden_dim = 40\n",
    "output_dim = 4\n",
    "model = LSTM(input_dim, hidden_dim, output_dim)\n",
    "#model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),alpha = 0.99, lr=0.001, weight_decay = 0.01)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 60\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 40\n",
    "output_dim = 4\n",
    "model = LSTM(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),alpha = 0.99, lr=0.001, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 60\n",
    "hidden_dim1 = 40\n",
    "hidden_dim2 = 40\n",
    "hidden_dim3 = 40\n",
    "output_dim = 4\n",
    "model = LSTM(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),alpha = 0.99, lr=0.001, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "t0 = time.time()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    tstart = time.time()\n",
    "    for i, data in enumerate(train_loader_1):\n",
    "        inputs, labels = data\n",
    "        #inputs = convnet(inputs)\n",
    "        #inputs = torch.Tensor(inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "    model.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    train_loss = 0\n",
    "    for train_data in train_loader_1:\n",
    "        train_inputs, train_labels = train_data\n",
    "        #train_inputs = convnet(train_inputs)\n",
    "        #train_inputs = torch.Tensor(train_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        train_outputs = model(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "        train_loss += criterion(train_outputs, train_labels).item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append(train_loss)\n",
    "        \n",
    "    #pXtrain = model(Xtrain)\n",
    "    #ptrain = torch.argmax(pXtrain, axis = 1)\n",
    "    #train_acc = np.mean(ptrain.numpy() == ytrain.numpy())\n",
    "    #train_accs.append(train_acc)\n",
    "    #tloss = criterion(pXtrain, ytrain)\n",
    "    #train_losses.append(tloss.item())\n",
    "    \n",
    "    val_correct, val_total = 0, 0\n",
    "    val_loss = 0\n",
    "    for val_data in val_loader_1:\n",
    "        val_inputs, val_labels = val_data\n",
    "        #val_inputs = convnet(val_inputs)\n",
    "        #val_inputs = torch.Tensor(val_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        val_outputs = model(val_inputs)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "        val_loss += criterion(val_outputs, val_labels).item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    val_loss_history.append(val_loss)\n",
    "    \n",
    "    #pXval = model(Xval)\n",
    "    #pval = torch.argmax(pXval, axis = 1)\n",
    "    #val_acc = np.mean(pval.numpy() == yval.numpy())\n",
    "    #val_accs.append(val_acc)\n",
    "    #vloss = criterion(pXval, yval)\n",
    "    #val_losses.append(vloss.item())\n",
    "    tend = time.time()\n",
    "    print('epoch: {:<3d}    time: {:<3.2f}    train_loss: {:<3.3f}    train acc: {:<1.3f}    val_loss: {:<3.3f}    val acc: {:<1.3f}'.format(epoch+1, \n",
    "            tend - tstart, train_loss, train_acc, val_loss, val_acc))\n",
    "time_total = time.time() - t0\n",
    "print('Total time: {:4.3f} seconds, average time per epoch: {:4.3f}'.format(time_total, time_total / num_epochs))\n",
    "\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_inputs, test_labels = test_data\n",
    "    #test_inputs = convnet(test_inputs)\n",
    "    #test_inputs = torch.Tensor(test_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "    test_outputs = model(test_inputs)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.title('training and validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.title('loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
