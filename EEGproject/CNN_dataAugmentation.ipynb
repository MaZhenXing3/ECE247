{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test - 769\n",
    "y_train_valid = y_train_valid - 769\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把最后一个axis变两倍， 500 -> 1000\n",
    "def double_ax2(a):\n",
    "    result = np.zeros((a.shape[0],a.shape[1],a.shape[2] * 2))\n",
    "    b = np.reshape(a[:,:,-1],(a.shape[0],a.shape[1],1))\n",
    "    aMod = np.concatenate((a,b),axis = 2)\n",
    "    for i in range(a.shape[2]):\n",
    "        ave = (aMod[:,:,i] + aMod[:,:,i+1]) / 2\n",
    "        result[:,:,2 * i] = aMod[:,:,i]\n",
    "        result[:,:,2*i + 1] = ave\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#无downsample预处理过程\n",
    "# For subject 1\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True,stratify=y_train_valid_1)\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_set_1 = Dataset(X_train_1,y_train_1)\n",
    "val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# upsample 预处理后\\n\\nX_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\\ny_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\\n\\n\\nX_test_1 = X_test[np.where(person_test==0)[0]]\\ny_test_1 = y_test[np.where(person_test==0)[0]]\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\\n                                                              test_size=0.2,shuffle=True,stratify=y_train_valid_1)\\n\\n\\nprint(X_train_1.shape)\\n\\n\\nnum_time = X_train_1.shape[2]\\nsample_1 = list(np.arange(0,num_time,2))\\nsample_2 = list(np.arange(1,num_time,2))\\n\\nX_tr_1 = X_train_1[:,:,sample_1]\\nX_tr_2 = X_train_1[:,:,sample_2]\\n#X_test_s1 = X_test[:,:,sample_1]\\n#X_test_s2 = X_test[:,:,sample_2]\\nprint('X_tr_1,  ',X_tr_1.shape)\\n\\n#X_train_s = X_tr_1   # 这个只用了两组中的一组\\nX_train_s = np.concatenate((X_tr_1,X_tr_2), axis=0)  # 这个是两组都加进去， N 变成 N*3\\n#y_train_s = y_train_1  # 这个只用了两组中的一组\\ny_train_s = np.concatenate((y_train_1,y_train_1), axis=0) # 这个是两组都加进去， N 变成 N*3\\nprint('X_train_s  ',X_train_s.shape)\\nX_train_s_x2 = double_ax2(X_train_s)\\nprint(X_train_s_x2.shape)\\nX_train_s = X_train_s_x2\\n#X_train_s = np.concatenate((X_train_1,X_train_s_x2), axis=0)\\nprint(X_train_s.shape)\\n\\ny_train_s = y_train_s\\n#y_train_s = np.concatenate((y_train_1,y_train_s), axis=0)\\nprint(y_train_s.shape)\\n\\n#person_train_valid_s = np.concatenate((person_train_valid,person_train_valid,person_train_valid), axis=0)\\n#person_test_s = person_test\\n#X_test_s = np.concatenate((X_test_s1,X_test_s2), axis=0)\\nX_test_s = X_test_1\\n#X_test_s1\\n#y_test_s = np.concatenate((y_test,y_test), axis=0)\\ny_test_s = y_test_1\\n#y_test\\n#person_test_s = np.concatenate((person_test,person_test), axis=0)\\n\\nprint(X_train_s.shape)\\nprint(y_train_s.shape)\\nprint(X_test_s.shape)\\n#print(person_train_s.shape)\\n#print(person_test.shape)\\n\\ntrain_set_1 = Dataset(X_train_s,y_train_s)\\nval_set_1 = Dataset(X_valid_1,y_valid_1)\\ntest_set_1 = Dataset(X_test_1, y_test_1)\\ntrain_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\\nval_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\\ntest_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=True)\\n\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# upsample 预处理后\n",
    "\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]]\n",
    "\n",
    "\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True,stratify=y_train_valid_1)\n",
    "\n",
    "\n",
    "print(X_train_1.shape)\n",
    "\n",
    "\n",
    "num_time = X_train_1.shape[2]\n",
    "sample_1 = list(np.arange(0,num_time,2))\n",
    "sample_2 = list(np.arange(1,num_time,2))\n",
    "\n",
    "X_tr_1 = X_train_1[:,:,sample_1]\n",
    "X_tr_2 = X_train_1[:,:,sample_2]\n",
    "#X_test_s1 = X_test[:,:,sample_1]\n",
    "#X_test_s2 = X_test[:,:,sample_2]\n",
    "print('X_tr_1,  ',X_tr_1.shape)\n",
    "\n",
    "#X_train_s = X_tr_1   # 这个只用了两组中的一组\n",
    "X_train_s = np.concatenate((X_tr_1,X_tr_2), axis=0)  # 这个是两组都加进去， N 变成 N*3\n",
    "#y_train_s = y_train_1  # 这个只用了两组中的一组\n",
    "y_train_s = np.concatenate((y_train_1,y_train_1), axis=0) # 这个是两组都加进去， N 变成 N*3\n",
    "print('X_train_s  ',X_train_s.shape)\n",
    "X_train_s_x2 = double_ax2(X_train_s)\n",
    "print(X_train_s_x2.shape)\n",
    "X_train_s = X_train_s_x2\n",
    "#X_train_s = np.concatenate((X_train_1,X_train_s_x2), axis=0)\n",
    "print(X_train_s.shape)\n",
    "\n",
    "y_train_s = y_train_s\n",
    "#y_train_s = np.concatenate((y_train_1,y_train_s), axis=0)\n",
    "print(y_train_s.shape)\n",
    "\n",
    "#person_train_valid_s = np.concatenate((person_train_valid,person_train_valid,person_train_valid), axis=0)\n",
    "#person_test_s = person_test\n",
    "#X_test_s = np.concatenate((X_test_s1,X_test_s2), axis=0)\n",
    "X_test_s = X_test_1\n",
    "#X_test_s1\n",
    "#y_test_s = np.concatenate((y_test,y_test), axis=0)\n",
    "y_test_s = y_test_1\n",
    "#y_test\n",
    "#person_test_s = np.concatenate((person_test,person_test), axis=0)\n",
    "\n",
    "print(X_train_s.shape)\n",
    "print(y_train_s.shape)\n",
    "print(X_test_s.shape)\n",
    "#print(person_train_s.shape)\n",
    "#print(person_test.shape)\n",
    "\n",
    "train_set_1 = Dataset(X_train_s,y_train_s)\n",
    "val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=32,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=8,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=10,shuffle=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Conv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class ConvTranspose(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(ConvTranspose, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        base = 22\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            Conv(22, base, 3, stride=2, padding=1),\n",
    "            Conv(base, 2*base, 3, padding=1),\n",
    "            #Conv(2*base, 2*base, 3, stride=2, padding=1),\n",
    "            #Conv(2*base, 2*base, 3, padding=1),\n",
    "            Conv(2*base, 2*base, 3, stride=2, padding=1),\n",
    "            Conv(2*base, 4*base, 3, padding=1),\n",
    "            Conv(4*base, 4*base, 3, stride=2, padding=1),\n",
    "            Conv(4*base, 4*base, 3, padding=1),\n",
    "            Conv(4*base, 4*base, 3, stride=2, padding=1),\n",
    "            nn.Conv1d(4*base, 64*base, 8),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.encoder_mu = nn.Conv1d(64*base, 32*base,1)\n",
    "        self.encoder_logvar = nn.Conv1d(64*base, 32*base,1)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(32*base, 64*base, 1),\n",
    "            ConvTranspose(64*base, 4*base, 8),\n",
    "            Conv(4*base, 4*base, 3, padding=1),\n",
    "            ConvTranspose(4*base, 4*base, 3, stride=2, padding=1),\n",
    "            Conv(4*base, 4*base, 3, padding=1),\n",
    "            ConvTranspose(4*base, 4*base, 4, stride=2, padding=1),\n",
    "            Conv(4*base, 2*base, 3, padding=1),\n",
    "            ConvTranspose(2*base, 2*base, 3, stride=2, padding=0),\n",
    "            #Conv(2*base, 2*base, 3, padding=1),\n",
    "            #ConvTranspose(2*base, 2*base, 3, stride=2, padding=1),\n",
    "            Conv(2*base, base, 3, padding=1),\n",
    "            ConvTranspose(base, base, 3, stride=2, padding=0),\n",
    "            nn.Conv1d(base, 22, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.encoder_mu(x), self.encoder_logvar(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目前这个最好\n",
    "#只有FC有dropout\n",
    "# [conv-relu]*2 -> 2*2 max-pooling -> [conv-relu]*3 -> 2*2 max_pooling -> (affine-relu)*2 -> affine -> softmax\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.vae = VAE()\n",
    "        self.conv1 = nn.Conv1d(22,40,kernel_size = 2,stride = 2) \n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.conv2 = nn.Conv1d(40,60,kernel_size = 3,stride = 1) \n",
    "        self.bn2 = nn.BatchNorm1d(60) \n",
    "        self.pool1 = nn.MaxPool1d(2,2) \n",
    "        \n",
    "        self.conv3 = nn.Conv1d(60,80,kernel_size = 3, stride = 1) \n",
    "        self.bn3 = nn.BatchNorm1d(80)\n",
    "        self.conv4 = nn.Conv1d(80,100,kernel_size = 3, stride = 1) \n",
    "        self.bn4 = nn.BatchNorm1d(100)\n",
    "        self.conv5 = nn.Conv1d(100,120,kernel_size = 3, stride = 2) #120*122\n",
    "        self.bn5 = nn.BatchNorm1d(120)\n",
    "        self.pool2 = nn.MaxPool1d(2,2) #120*61\n",
    "        \n",
    "        self.fc1 = nn.Linear(120*61, 300) # input dim , output dim\n",
    "        self.bn6 = nn.BatchNorm1d(300)\n",
    "        self.drop1 = nn.Dropout(0.8)\n",
    "        self.fc2 = nn.Linear(300,4)  \n",
    "        self.bn7 = nn.BatchNorm1d(40)\n",
    "        self.drop2 = nn.Dropout(0.8)\n",
    "        self.fc3 = nn.Linear(40,4)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = self.vae(x)[0]\n",
    "        #print(x.shape)\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = x.view(-1,120*61)\n",
    "        \n",
    "        x = self.drop1(F.relu(self.bn6(self.fc1(x))))\n",
    "        #x = self.drop2(F.relu(self.bn7(self.fc2(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (vae): VAE(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(22, 22, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(22, 44, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (2): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(44, 44, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(44, 88, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (4): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 88, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 88, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (6): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 88, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (7): Conv1d(88, 1408, kernel_size=(8,), stride=(1,))\n",
      "      (8): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (encoder_mu): Conv1d(1408, 704, kernel_size=(1,), stride=(1,))\n",
      "    (encoder_logvar): Conv1d(1408, 704, kernel_size=(1,), stride=(1,))\n",
      "    (decoder): Sequential(\n",
      "      (0): Conv1d(704, 1408, kernel_size=(1,), stride=(1,))\n",
      "      (1): ConvTranspose(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvTranspose1d(1408, 88, kernel_size=(8,), stride=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (2): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 88, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (3): ConvTranspose(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvTranspose1d(88, 88, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (4): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 88, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (5): ConvTranspose(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvTranspose1d(88, 88, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (6): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(88, 44, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (7): ConvTranspose(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvTranspose1d(44, 44, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (8): Conv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv1d(44, 22, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (9): ConvTranspose(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvTranspose1d(22, 22, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "      (10): Conv1d(22, 22, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (11): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv1d(22, 40, kernel_size=(2,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(40, 60, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(60, 80, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(80, 100, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv1d(100, 120, kernel_size=(3,), stride=(2,))\n",
      "  (bn5): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=7320, out_features=300, bias=True)\n",
      "  (bn6): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.8, inplace=False)\n",
      "  (fc2): Linear(in_features=300, out_features=4, bias=True)\n",
      "  (bn7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop2): Dropout(p=0.8, inplace=False)\n",
      "  (fc3): Linear(in_features=40, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr = 0.001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "test_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1      time: 9.22    train_loss: 8.332    train acc: 0.249    val_loss: 8.329    val acc: 0.250   test_loss: 6.938    test acc: 0.240\n",
      "epoch: 2      time: 8.84    train_loss: 8.344    train acc: 0.249    val_loss: 8.344    val acc: 0.250   test_loss: 6.960    test acc: 0.240\n",
      "epoch: 3      time: 8.84    train_loss: 8.404    train acc: 0.249    val_loss: 8.409    val acc: 0.250   test_loss: 7.043    test acc: 0.240\n",
      "epoch: 4      time: 8.89    train_loss: 8.578    train acc: 0.249    val_loss: 8.576    val acc: 0.250   test_loss: 7.232    test acc: 0.240\n",
      "epoch: 5      time: 8.93    train_loss: 8.744    train acc: 0.249    val_loss: 8.797    val acc: 0.250   test_loss: 7.405    test acc: 0.240\n",
      "epoch: 6      time: 9.07    train_loss: 8.692    train acc: 0.249    val_loss: 8.733    val acc: 0.250   test_loss: 7.327    test acc: 0.240\n",
      "epoch: 7      time: 9.37    train_loss: 8.672    train acc: 0.169    val_loss: 8.524    val acc: 0.271   test_loss: 7.364    test acc: 0.280\n",
      "epoch: 8      time: 9.44    train_loss: 8.686    train acc: 0.265    val_loss: 8.815    val acc: 0.146   test_loss: 7.546    test acc: 0.220\n",
      "epoch: 9      time: 9.45    train_loss: 9.070    train acc: 0.259    val_loss: 9.538    val acc: 0.250   test_loss: 7.867    test acc: 0.220\n",
      "epoch: 10     time: 9.34    train_loss: 9.301    train acc: 0.222    val_loss: 8.726    val acc: 0.271   test_loss: 7.720    test acc: 0.220\n",
      "epoch: 11     time: 9.43    train_loss: 10.011    train acc: 0.238    val_loss: 10.731    val acc: 0.167   test_loss: 8.658    test acc: 0.180\n",
      "epoch: 12     time: 9.77    train_loss: 9.281    train acc: 0.238    val_loss: 8.774    val acc: 0.375   test_loss: 8.469    test acc: 0.180\n",
      "epoch: 13     time: 9.10    train_loss: 8.938    train acc: 0.291    val_loss: 8.922    val acc: 0.250   test_loss: 7.985    test acc: 0.200\n",
      "epoch: 14     time: 9.01    train_loss: 9.166    train acc: 0.270    val_loss: 9.041    val acc: 0.333   test_loss: 7.781    test acc: 0.260\n",
      "epoch: 15     time: 9.34    train_loss: 9.811    train acc: 0.280    val_loss: 10.173    val acc: 0.292   test_loss: 8.502    test acc: 0.280\n",
      "epoch: 16     time: 9.11    train_loss: 10.134    train acc: 0.286    val_loss: 11.190    val acc: 0.271   test_loss: 8.671    test acc: 0.280\n",
      "epoch: 17     time: 9.11    train_loss: 10.217    train acc: 0.280    val_loss: 10.027    val acc: 0.250   test_loss: 8.763    test acc: 0.200\n",
      "epoch: 18     time: 9.76    train_loss: 9.108    train acc: 0.280    val_loss: 9.843    val acc: 0.250   test_loss: 7.641    test acc: 0.380\n",
      "epoch: 19     time: 9.36    train_loss: 8.539    train acc: 0.328    val_loss: 9.372    val acc: 0.250   test_loss: 8.001    test acc: 0.220\n",
      "epoch: 20     time: 9.21    train_loss: 8.084    train acc: 0.386    val_loss: 8.899    val acc: 0.250   test_loss: 7.854    test acc: 0.300\n",
      "epoch: 21     time: 9.11    train_loss: 7.964    train acc: 0.381    val_loss: 8.809    val acc: 0.333   test_loss: 7.540    test acc: 0.280\n",
      "epoch: 22     time: 9.31    train_loss: 7.667    train acc: 0.397    val_loss: 8.375    val acc: 0.312   test_loss: 7.279    test acc: 0.320\n",
      "epoch: 23     time: 9.13    train_loss: 7.531    train acc: 0.397    val_loss: 8.219    val acc: 0.354   test_loss: 7.123    test acc: 0.320\n",
      "epoch: 24     time: 8.95    train_loss: 7.271    train acc: 0.418    val_loss: 7.648    val acc: 0.396   test_loss: 6.754    test acc: 0.400\n",
      "epoch: 25     time: 9.45    train_loss: 7.112    train acc: 0.429    val_loss: 7.963    val acc: 0.292   test_loss: 7.621    test acc: 0.300\n",
      "epoch: 26     time: 9.06    train_loss: 6.849    train acc: 0.466    val_loss: 8.087    val acc: 0.375   test_loss: 7.127    test acc: 0.360\n",
      "epoch: 27     time: 9.11    train_loss: 6.829    train acc: 0.460    val_loss: 8.034    val acc: 0.354   test_loss: 7.191    test acc: 0.380\n",
      "epoch: 28     time: 8.91    train_loss: 6.199    train acc: 0.603    val_loss: 7.711    val acc: 0.354   test_loss: 6.877    test acc: 0.320\n",
      "epoch: 29     time: 8.90    train_loss: 5.847    train acc: 0.630    val_loss: 7.098    val acc: 0.333   test_loss: 6.380    test acc: 0.340\n",
      "epoch: 30     time: 8.89    train_loss: 5.648    train acc: 0.598    val_loss: 6.605    val acc: 0.396   test_loss: 6.461    test acc: 0.400\n",
      "epoch: 31     time: 8.86    train_loss: 5.204    train acc: 0.624    val_loss: 6.565    val acc: 0.396   test_loss: 6.466    test acc: 0.400\n",
      "epoch: 32     time: 9.10    train_loss: 5.032    train acc: 0.656    val_loss: 6.521    val acc: 0.458   test_loss: 6.316    test acc: 0.320\n",
      "epoch: 33     time: 8.96    train_loss: 4.766    train acc: 0.683    val_loss: 6.346    val acc: 0.479   test_loss: 6.114    test acc: 0.400\n",
      "epoch: 34     time: 8.89    train_loss: 4.360    train acc: 0.714    val_loss: 6.641    val acc: 0.500   test_loss: 6.136    test acc: 0.400\n",
      "epoch: 35     time: 8.84    train_loss: 4.140    train acc: 0.767    val_loss: 7.243    val acc: 0.438   test_loss: 6.058    test acc: 0.380\n",
      "epoch: 36     time: 8.85    train_loss: 3.714    train acc: 0.783    val_loss: 6.414    val acc: 0.417   test_loss: 5.940    test acc: 0.480\n",
      "epoch: 37     time: 8.86    train_loss: 3.840    train acc: 0.762    val_loss: 6.214    val acc: 0.583   test_loss: 6.122    test acc: 0.400\n",
      "epoch: 38     time: 8.88    train_loss: 3.422    train acc: 0.794    val_loss: 6.522    val acc: 0.500   test_loss: 6.559    test acc: 0.480\n",
      "epoch: 39     time: 8.93    train_loss: 3.231    train acc: 0.831    val_loss: 6.941    val acc: 0.542   test_loss: 6.167    test acc: 0.500\n",
      "epoch: 40     time: 8.85    train_loss: 3.442    train acc: 0.788    val_loss: 6.598    val acc: 0.500   test_loss: 6.662    test acc: 0.440\n",
      "epoch: 41     time: 8.84    train_loss: 2.615    train acc: 0.852    val_loss: 6.227    val acc: 0.500   test_loss: 6.656    test acc: 0.480\n",
      "epoch: 42     time: 8.85    train_loss: 2.885    train acc: 0.825    val_loss: 7.270    val acc: 0.500   test_loss: 6.549    test acc: 0.480\n",
      "epoch: 43     time: 8.86    train_loss: 2.055    train acc: 0.894    val_loss: 7.075    val acc: 0.562   test_loss: 7.130    test acc: 0.440\n",
      "epoch: 44     time: 8.86    train_loss: 2.037    train acc: 0.915    val_loss: 6.063    val acc: 0.646   test_loss: 6.491    test acc: 0.520\n",
      "epoch: 45     time: 8.87    train_loss: 1.815    train acc: 0.926    val_loss: 7.251    val acc: 0.458   test_loss: 6.607    test acc: 0.480\n",
      "epoch: 46     time: 8.85    train_loss: 1.261    train acc: 0.958    val_loss: 7.099    val acc: 0.542   test_loss: 6.763    test acc: 0.440\n",
      "epoch: 47     time: 8.82    train_loss: 1.402    train acc: 0.926    val_loss: 7.740    val acc: 0.479   test_loss: 7.041    test acc: 0.540\n",
      "epoch: 48     time: 8.85    train_loss: 2.068    train acc: 0.857    val_loss: 8.269    val acc: 0.458   test_loss: 7.551    test acc: 0.360\n",
      "epoch: 49     time: 8.92    train_loss: 0.846    train acc: 0.984    val_loss: 9.014    val acc: 0.417   test_loss: 7.225    test acc: 0.480\n",
      "epoch: 50     time: 8.84    train_loss: 0.668    train acc: 0.995    val_loss: 8.772    val acc: 0.500   test_loss: 7.841    test acc: 0.500\n",
      "epoch: 51     time: 8.92    train_loss: 0.524    train acc: 1.000    val_loss: 8.904    val acc: 0.438   test_loss: 7.774    test acc: 0.520\n",
      "epoch: 52     time: 8.84    train_loss: 0.423    train acc: 0.995    val_loss: 7.856    val acc: 0.542   test_loss: 7.843    test acc: 0.540\n",
      "epoch: 53     time: 8.87    train_loss: 0.354    train acc: 1.000    val_loss: 8.787    val acc: 0.479   test_loss: 6.970    test acc: 0.520\n",
      "epoch: 54     time: 8.89    train_loss: 0.262    train acc: 1.000    val_loss: 9.683    val acc: 0.438   test_loss: 6.921    test acc: 0.580\n",
      "epoch: 55     time: 8.88    train_loss: 0.220    train acc: 1.000    val_loss: 8.583    val acc: 0.479   test_loss: 7.587    test acc: 0.560\n",
      "epoch: 56     time: 8.89    train_loss: 0.264    train acc: 1.000    val_loss: 8.558    val acc: 0.500   test_loss: 6.847    test acc: 0.520\n",
      "epoch: 57     time: 8.87    train_loss: 0.172    train acc: 1.000    val_loss: 9.388    val acc: 0.438   test_loss: 8.066    test acc: 0.500\n",
      "epoch: 58     time: 8.90    train_loss: 0.147    train acc: 1.000    val_loss: 9.783    val acc: 0.458   test_loss: 8.528    test acc: 0.500\n",
      "epoch: 59     time: 8.85    train_loss: 0.119    train acc: 1.000    val_loss: 8.629    val acc: 0.458   test_loss: 7.454    test acc: 0.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60     time: 8.84    train_loss: 0.106    train acc: 1.000    val_loss: 9.161    val acc: 0.500   test_loss: 8.440    test acc: 0.500\n",
      "epoch: 61     time: 8.91    train_loss: 0.112    train acc: 1.000    val_loss: 8.665    val acc: 0.521   test_loss: 8.282    test acc: 0.500\n",
      "epoch: 62     time: 8.88    train_loss: 0.089    train acc: 1.000    val_loss: 10.706    val acc: 0.417   test_loss: 8.988    test acc: 0.560\n",
      "epoch: 63     time: 8.89    train_loss: 0.087    train acc: 1.000    val_loss: 9.113    val acc: 0.542   test_loss: 8.301    test acc: 0.540\n",
      "epoch: 64     time: 8.88    train_loss: 0.095    train acc: 1.000    val_loss: 9.617    val acc: 0.438   test_loss: 7.625    test acc: 0.620\n",
      "epoch: 65     time: 8.90    train_loss: 0.139    train acc: 1.000    val_loss: 9.152    val acc: 0.438   test_loss: 8.166    test acc: 0.540\n",
      "epoch: 66     time: 8.90    train_loss: 0.086    train acc: 1.000    val_loss: 9.505    val acc: 0.500   test_loss: 8.561    test acc: 0.520\n",
      "epoch: 67     time: 8.85    train_loss: 0.096    train acc: 1.000    val_loss: 9.532    val acc: 0.521   test_loss: 9.564    test acc: 0.420\n",
      "epoch: 68     time: 8.88    train_loss: 0.099    train acc: 1.000    val_loss: 9.947    val acc: 0.542   test_loss: 9.280    test acc: 0.500\n",
      "epoch: 69     time: 8.86    train_loss: 0.078    train acc: 1.000    val_loss: 8.538    val acc: 0.521   test_loss: 8.236    test acc: 0.540\n",
      "epoch: 70     time: 8.85    train_loss: 0.133    train acc: 1.000    val_loss: 9.571    val acc: 0.521   test_loss: 10.037    test acc: 0.520\n",
      "epoch: 71     time: 8.84    train_loss: 0.077    train acc: 1.000    val_loss: 9.928    val acc: 0.500   test_loss: 8.428    test acc: 0.580\n",
      "epoch: 72     time: 8.89    train_loss: 0.058    train acc: 1.000    val_loss: 10.816    val acc: 0.438   test_loss: 7.968    test acc: 0.480\n",
      "epoch: 73     time: 8.86    train_loss: 0.083    train acc: 1.000    val_loss: 11.226    val acc: 0.354   test_loss: 8.483    test acc: 0.520\n",
      "epoch: 74     time: 8.85    train_loss: 0.053    train acc: 1.000    val_loss: 11.356    val acc: 0.479   test_loss: 9.214    test acc: 0.500\n",
      "epoch: 75     time: 8.86    train_loss: 0.044    train acc: 1.000    val_loss: 11.292    val acc: 0.375   test_loss: 8.729    test acc: 0.520\n",
      "epoch: 76     time: 8.88    train_loss: 0.045    train acc: 1.000    val_loss: 10.076    val acc: 0.396   test_loss: 9.034    test acc: 0.520\n",
      "epoch: 77     time: 8.84    train_loss: 0.042    train acc: 1.000    val_loss: 10.271    val acc: 0.458   test_loss: 9.862    test acc: 0.460\n",
      "epoch: 78     time: 9.17    train_loss: 0.037    train acc: 1.000    val_loss: 10.525    val acc: 0.500   test_loss: 8.317    test acc: 0.480\n",
      "epoch: 79     time: 8.90    train_loss: 0.054    train acc: 1.000    val_loss: 11.080    val acc: 0.562   test_loss: 9.232    test acc: 0.500\n",
      "epoch: 80     time: 8.87    train_loss: 0.042    train acc: 1.000    val_loss: 11.182    val acc: 0.500   test_loss: 8.682    test acc: 0.580\n",
      "epoch: 81     time: 8.88    train_loss: 0.033    train acc: 1.000    val_loss: 10.021    val acc: 0.417   test_loss: 8.686    test acc: 0.500\n",
      "epoch: 82     time: 8.95    train_loss: 0.047    train acc: 1.000    val_loss: 9.978    val acc: 0.438   test_loss: 7.814    test acc: 0.540\n",
      "epoch: 83     time: 8.87    train_loss: 0.025    train acc: 1.000    val_loss: 9.766    val acc: 0.438   test_loss: 8.513    test acc: 0.500\n",
      "epoch: 84     time: 8.88    train_loss: 0.029    train acc: 1.000    val_loss: 9.983    val acc: 0.479   test_loss: 8.265    test acc: 0.540\n",
      "epoch: 85     time: 8.93    train_loss: 0.022    train acc: 1.000    val_loss: 9.442    val acc: 0.479   test_loss: 8.663    test acc: 0.500\n",
      "epoch: 86     time: 8.88    train_loss: 0.024    train acc: 1.000    val_loss: 9.666    val acc: 0.458   test_loss: 8.592    test acc: 0.580\n",
      "epoch: 87     time: 8.88    train_loss: 0.027    train acc: 1.000    val_loss: 9.491    val acc: 0.500   test_loss: 8.081    test acc: 0.540\n",
      "epoch: 88     time: 8.88    train_loss: 0.023    train acc: 1.000    val_loss: 10.932    val acc: 0.417   test_loss: 8.391    test acc: 0.580\n",
      "epoch: 89     time: 8.88    train_loss: 0.020    train acc: 1.000    val_loss: 10.466    val acc: 0.500   test_loss: 8.238    test acc: 0.560\n",
      "epoch: 90     time: 8.85    train_loss: 0.019    train acc: 1.000    val_loss: 11.257    val acc: 0.458   test_loss: 8.679    test acc: 0.520\n",
      "epoch: 91     time: 8.87    train_loss: 0.019    train acc: 1.000    val_loss: 9.979    val acc: 0.479   test_loss: 7.943    test acc: 0.600\n",
      "epoch: 92     time: 8.91    train_loss: 0.026    train acc: 1.000    val_loss: 9.592    val acc: 0.438   test_loss: 8.244    test acc: 0.560\n",
      "epoch: 93     time: 8.89    train_loss: 0.024    train acc: 1.000    val_loss: 9.958    val acc: 0.458   test_loss: 8.955    test acc: 0.520\n",
      "epoch: 94     time: 8.92    train_loss: 0.021    train acc: 1.000    val_loss: 10.557    val acc: 0.417   test_loss: 8.694    test acc: 0.540\n",
      "epoch: 95     time: 9.07    train_loss: 0.015    train acc: 1.000    val_loss: 10.986    val acc: 0.500   test_loss: 8.481    test acc: 0.520\n",
      "epoch: 96     time: 9.00    train_loss: 0.014    train acc: 1.000    val_loss: 10.772    val acc: 0.479   test_loss: 8.376    test acc: 0.540\n",
      "epoch: 97     time: 8.99    train_loss: 0.016    train acc: 1.000    val_loss: 9.865    val acc: 0.521   test_loss: 8.037    test acc: 0.600\n",
      "epoch: 98     time: 9.05    train_loss: 0.013    train acc: 1.000    val_loss: 10.169    val acc: 0.438   test_loss: 8.974    test acc: 0.560\n",
      "epoch: 99     time: 9.04    train_loss: 0.018    train acc: 1.000    val_loss: 12.232    val acc: 0.396   test_loss: 9.161    test acc: 0.540\n",
      "epoch: 100    time: 9.00    train_loss: 0.015    train acc: 1.000    val_loss: 9.794    val acc: 0.458   test_loss: 9.531    test acc: 0.560\n",
      "epoch: 101    time: 9.00    train_loss: 0.015    train acc: 1.000    val_loss: 10.068    val acc: 0.500   test_loss: 8.672    test acc: 0.500\n",
      "epoch: 102    time: 9.00    train_loss: 0.014    train acc: 1.000    val_loss: 10.538    val acc: 0.438   test_loss: 8.395    test acc: 0.620\n",
      "epoch: 103    time: 9.06    train_loss: 0.011    train acc: 1.000    val_loss: 11.311    val acc: 0.417   test_loss: 8.974    test acc: 0.540\n",
      "epoch: 104    time: 9.02    train_loss: 0.011    train acc: 1.000    val_loss: 9.555    val acc: 0.479   test_loss: 9.175    test acc: 0.540\n",
      "epoch: 105    time: 9.07    train_loss: 0.011    train acc: 1.000    val_loss: 10.981    val acc: 0.500   test_loss: 9.165    test acc: 0.520\n",
      "epoch: 106    time: 9.01    train_loss: 0.011    train acc: 1.000    val_loss: 11.700    val acc: 0.479   test_loss: 8.602    test acc: 0.540\n",
      "epoch: 107    time: 8.88    train_loss: 0.009    train acc: 1.000    val_loss: 11.561    val acc: 0.438   test_loss: 9.661    test acc: 0.500\n",
      "epoch: 108    time: 8.91    train_loss: 0.010    train acc: 1.000    val_loss: 9.728    val acc: 0.500   test_loss: 8.592    test acc: 0.540\n",
      "epoch: 109    time: 8.87    train_loss: 0.010    train acc: 1.000    val_loss: 10.469    val acc: 0.479   test_loss: 8.637    test acc: 0.500\n",
      "epoch: 110    time: 8.87    train_loss: 0.010    train acc: 1.000    val_loss: 10.845    val acc: 0.438   test_loss: 8.684    test acc: 0.540\n",
      "epoch: 111    time: 8.87    train_loss: 0.009    train acc: 1.000    val_loss: 9.951    val acc: 0.521   test_loss: 8.347    test acc: 0.580\n",
      "epoch: 112    time: 8.87    train_loss: 0.009    train acc: 1.000    val_loss: 12.233    val acc: 0.417   test_loss: 9.116    test acc: 0.560\n",
      "epoch: 113    time: 8.91    train_loss: 0.010    train acc: 1.000    val_loss: 10.292    val acc: 0.500   test_loss: 9.797    test acc: 0.560\n",
      "epoch: 114    time: 8.86    train_loss: 0.016    train acc: 1.000    val_loss: 11.545    val acc: 0.458   test_loss: 8.704    test acc: 0.500\n",
      "epoch: 115    time: 8.87    train_loss: 0.019    train acc: 1.000    val_loss: 9.881    val acc: 0.500   test_loss: 8.846    test acc: 0.520\n",
      "epoch: 116    time: 8.88    train_loss: 0.016    train acc: 1.000    val_loss: 10.135    val acc: 0.458   test_loss: 8.959    test acc: 0.500\n",
      "epoch: 117    time: 9.00    train_loss: 0.011    train acc: 1.000    val_loss: 10.661    val acc: 0.562   test_loss: 8.858    test acc: 0.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118    time: 9.07    train_loss: 0.011    train acc: 1.000    val_loss: 11.307    val acc: 0.479   test_loss: 9.719    test acc: 0.480\n",
      "epoch: 119    time: 8.99    train_loss: 0.013    train acc: 1.000    val_loss: 10.575    val acc: 0.458   test_loss: 9.827    test acc: 0.480\n",
      "epoch: 120    time: 9.01    train_loss: 0.009    train acc: 1.000    val_loss: 10.077    val acc: 0.542   test_loss: 9.004    test acc: 0.500\n",
      "epoch: 121    time: 8.87    train_loss: 0.010    train acc: 1.000    val_loss: 10.751    val acc: 0.521   test_loss: 8.907    test acc: 0.560\n",
      "epoch: 122    time: 8.95    train_loss: 0.009    train acc: 1.000    val_loss: 10.258    val acc: 0.479   test_loss: 8.454    test acc: 0.580\n",
      "epoch: 123    time: 8.93    train_loss: 0.009    train acc: 1.000    val_loss: 10.623    val acc: 0.458   test_loss: 8.964    test acc: 0.480\n",
      "epoch: 124    time: 8.90    train_loss: 0.010    train acc: 1.000    val_loss: 10.561    val acc: 0.458   test_loss: 8.732    test acc: 0.520\n",
      "epoch: 125    time: 8.90    train_loss: 0.009    train acc: 1.000    val_loss: 11.743    val acc: 0.479   test_loss: 8.792    test acc: 0.520\n",
      "Total time: 1121.739 seconds, average time per epoch: 8.974\n",
      "Test accuracy is:  0.52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "num_epochs = 125\n",
    "for epoch in range(num_epochs):\n",
    "    tstart = time.time()\n",
    "    for i, data in enumerate(train_loader_1):\n",
    "        inputs, labels = data\n",
    "        #inputs = convnet(inputs)\n",
    "        #inputs = torch.Tensor(inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "    model.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    train_loss = 0\n",
    "    for train_data in train_loader_1:\n",
    "        train_inputs, train_labels = train_data\n",
    "        #train_inputs = convnet(train_inputs)\n",
    "        #train_inputs = torch.Tensor(train_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        train_outputs = model(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "        train_loss += criterion(train_outputs, train_labels).item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append(train_loss)\n",
    "        \n",
    "    #pXtrain = model(Xtrain)\n",
    "    #ptrain = torch.argmax(pXtrain, axis = 1)\n",
    "    #train_acc = np.mean(ptrain.numpy() == ytrain.numpy())\n",
    "    #train_accs.append(train_acc)\n",
    "    #tloss = criterion(pXtrain, ytrain)\n",
    "    #train_losses.append(tloss.item())\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    val_loss = 0\n",
    "    for val_data in val_loader_1:\n",
    "        val_inputs, val_labels = val_data\n",
    "        #val_inputs = convnet(val_inputs)\n",
    "        #val_inputs = torch.Tensor(val_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        val_outputs = model(val_inputs)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "        val_loss += criterion(val_outputs, val_labels).item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    val_loss_history.append(val_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    test_correct, test_total = 0, 0\n",
    "    test_loss = 0\n",
    "    for test_data in test_loader_1:\n",
    "        test_inputs, test_labels = test_data\n",
    "        #test_inputs = convnet(test_inputs)\n",
    "        #test_inputs = torch.Tensor(test_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "        test_outputs = model(test_inputs)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_total += test_labels.size(0)\n",
    "        test_correct += (test_predicted == test_labels).sum().item()\n",
    "        test_loss += criterion(test_outputs, test_labels).item()\n",
    "    test_acc = test_correct / test_total\n",
    "    test_acc_history.append(test_acc)\n",
    "    test_loss_history.append(test_loss)\n",
    "    \n",
    "    #pXval = model(Xval)\n",
    "    #pval = torch.argmax(pXval, axis = 1)\n",
    "    #val_acc = np.mean(pval.numpy() == yval.numpy())\n",
    "    #val_accs.append(val_acc)\n",
    "    #vloss = criterion(pXval, yval)\n",
    "    #val_losses.append(vloss.item())\n",
    "    tend = time.time()\n",
    "    print('epoch: {:<3d}    time: {:<3.2f}    train_loss: {:<3.3f}    train acc: {:<1.3f}    val_loss: {:<3.3f}    val acc: {:<1.3f}   test_loss: {:<3.3f}    test acc: {:<1.3f}'.format(epoch+1, \n",
    "            tend - tstart, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "time_total = time.time() - t0\n",
    "print('Total time: {:4.3f} seconds, average time per epoch: {:4.3f}'.format(time_total, time_total / num_epochs))\n",
    "model.eval()\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_inputs, test_labels = test_data\n",
    "    #test_inputs = convnet(test_inputs)\n",
    "    #test_inputs = torch.Tensor(test_inputs.detach().numpy().transpose(0,2,1)) #249*60\n",
    "    test_outputs = model(test_inputs)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  0.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test accuracy is: ',test_acc)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.title('training and validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(val_loss_history)\n",
    "plt.title('loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training Net 1\n",
      "Epoch 0 | Iter1 | Loss1.6369 | val acc 0.3750\n",
      "Epoch 0 | Iter3 | Loss1.7491 | val acc 0.3750\n",
      "Epoch 0 | Iter5 | Loss1.8225 | val acc 0.3750\n",
      "Epoch 0 | Iter7 | Loss1.8248 | val acc 0.3125\n",
      "Epoch 0 | Iter9 | Loss1.5488 | val acc 0.2917\n",
      "Epoch 0 | Iter11 | Loss1.5226 | val acc 0.2708\n",
      "Epoch 0 | Iter13 | Loss1.4853 | val acc 0.3333\n",
      "Epoch 0 | Iter15 | Loss1.5834 | val acc 0.3542\n",
      "Epoch 0 | Iter17 | Loss1.4572 | val acc 0.3958\n",
      "Epoch 1 | Iter1 | Loss1.5596 | val acc 0.3333\n",
      "Epoch 1 | Iter3 | Loss1.1818 | val acc 0.3125\n",
      "Epoch 1 | Iter5 | Loss1.4253 | val acc 0.3542\n",
      "Epoch 1 | Iter7 | Loss1.3930 | val acc 0.3125\n",
      "Epoch 1 | Iter9 | Loss1.5970 | val acc 0.3333\n",
      "Epoch 1 | Iter11 | Loss1.2510 | val acc 0.3958\n",
      "Epoch 1 | Iter13 | Loss1.2624 | val acc 0.3542\n",
      "Epoch 1 | Iter15 | Loss1.3322 | val acc 0.3750\n",
      "Epoch 1 | Iter17 | Loss1.4076 | val acc 0.3542\n",
      "Epoch 2 | Iter1 | Loss1.3967 | val acc 0.1875\n",
      "Epoch 2 | Iter3 | Loss1.2543 | val acc 0.3125\n",
      "Epoch 2 | Iter5 | Loss1.3571 | val acc 0.3542\n",
      "Epoch 2 | Iter7 | Loss1.3306 | val acc 0.1667\n",
      "Epoch 2 | Iter9 | Loss1.2435 | val acc 0.4167\n",
      "Epoch 2 | Iter11 | Loss1.3009 | val acc 0.3542\n",
      "Epoch 2 | Iter13 | Loss1.2956 | val acc 0.4167\n",
      "Epoch 2 | Iter15 | Loss1.3772 | val acc 0.3750\n",
      "Epoch 2 | Iter17 | Loss1.1079 | val acc 0.5000\n",
      "Epoch 3 | Iter1 | Loss1.4524 | val acc 0.4375\n",
      "Epoch 3 | Iter3 | Loss1.2592 | val acc 0.3958\n",
      "Epoch 3 | Iter5 | Loss1.2334 | val acc 0.4167\n",
      "Epoch 3 | Iter7 | Loss1.2399 | val acc 0.4375\n",
      "Epoch 3 | Iter9 | Loss1.0138 | val acc 0.4167\n",
      "Epoch 3 | Iter11 | Loss1.2410 | val acc 0.4375\n",
      "Epoch 3 | Iter13 | Loss1.3444 | val acc 0.4583\n",
      "Epoch 3 | Iter15 | Loss1.1512 | val acc 0.4792\n",
      "Epoch 3 | Iter17 | Loss1.1845 | val acc 0.4583\n",
      "Epoch 4 | Iter1 | Loss1.1648 | val acc 0.5000\n",
      "Epoch 4 | Iter3 | Loss1.2036 | val acc 0.5000\n",
      "Epoch 4 | Iter5 | Loss0.9639 | val acc 0.5208\n",
      "Epoch 4 | Iter7 | Loss1.2148 | val acc 0.5417\n",
      "Epoch 4 | Iter9 | Loss1.1119 | val acc 0.5208\n",
      "Epoch 4 | Iter11 | Loss1.0405 | val acc 0.5417\n",
      "Epoch 4 | Iter13 | Loss1.1847 | val acc 0.5000\n",
      "Epoch 4 | Iter15 | Loss0.9595 | val acc 0.4583\n",
      "Epoch 4 | Iter17 | Loss1.1057 | val acc 0.6042\n",
      "Epoch 5 | Iter1 | Loss1.1952 | val acc 0.5208\n",
      "Epoch 5 | Iter3 | Loss1.0136 | val acc 0.5833\n",
      "Epoch 5 | Iter5 | Loss0.8894 | val acc 0.5417\n",
      "Epoch 5 | Iter7 | Loss1.0051 | val acc 0.5625\n",
      "Epoch 5 | Iter9 | Loss0.9376 | val acc 0.5625\n",
      "Epoch 5 | Iter11 | Loss1.0286 | val acc 0.5417\n",
      "Epoch 5 | Iter13 | Loss0.9191 | val acc 0.4583\n",
      "Epoch 5 | Iter15 | Loss0.8606 | val acc 0.5833\n",
      "Epoch 5 | Iter17 | Loss0.9597 | val acc 0.5833\n",
      "Epoch 6 | Iter1 | Loss1.0255 | val acc 0.4792\n",
      "Epoch 6 | Iter3 | Loss0.8867 | val acc 0.4167\n",
      "Epoch 6 | Iter5 | Loss1.0140 | val acc 0.4167\n",
      "Epoch 6 | Iter7 | Loss1.1010 | val acc 0.5625\n",
      "Epoch 6 | Iter9 | Loss0.9115 | val acc 0.6250\n",
      "Epoch 6 | Iter11 | Loss0.9063 | val acc 0.5625\n",
      "Epoch 6 | Iter13 | Loss0.8348 | val acc 0.5417\n",
      "Epoch 6 | Iter15 | Loss0.8816 | val acc 0.6042\n",
      "Epoch 6 | Iter17 | Loss0.8402 | val acc 0.5833\n",
      "Epoch 7 | Iter1 | Loss0.9318 | val acc 0.6042\n",
      "Epoch 7 | Iter3 | Loss0.8325 | val acc 0.6042\n",
      "Epoch 7 | Iter5 | Loss0.8468 | val acc 0.5417\n",
      "Epoch 7 | Iter7 | Loss0.8081 | val acc 0.5625\n",
      "Epoch 7 | Iter9 | Loss0.9019 | val acc 0.6250\n",
      "Epoch 7 | Iter11 | Loss0.7744 | val acc 0.5833\n",
      "Epoch 7 | Iter13 | Loss0.9538 | val acc 0.6042\n",
      "Epoch 7 | Iter15 | Loss0.8233 | val acc 0.6458\n",
      "Epoch 7 | Iter17 | Loss0.9270 | val acc 0.5833\n",
      "Epoch 8 | Iter1 | Loss0.8048 | val acc 0.6250\n",
      "Epoch 8 | Iter3 | Loss0.7388 | val acc 0.6250\n",
      "Epoch 8 | Iter5 | Loss0.8438 | val acc 0.4792\n",
      "Epoch 8 | Iter7 | Loss0.7591 | val acc 0.4792\n",
      "Epoch 8 | Iter9 | Loss0.7488 | val acc 0.5417\n",
      "Epoch 8 | Iter11 | Loss0.7089 | val acc 0.5417\n",
      "Epoch 8 | Iter13 | Loss0.7197 | val acc 0.5625\n",
      "Epoch 8 | Iter15 | Loss0.7788 | val acc 0.5417\n",
      "Epoch 8 | Iter17 | Loss0.6119 | val acc 0.4792\n",
      "Epoch 9 | Iter1 | Loss0.7585 | val acc 0.5208\n",
      "Epoch 9 | Iter3 | Loss0.6162 | val acc 0.5208\n",
      "Epoch 9 | Iter5 | Loss0.7870 | val acc 0.5417\n",
      "Epoch 9 | Iter7 | Loss0.7040 | val acc 0.6458\n",
      "Epoch 9 | Iter9 | Loss0.7251 | val acc 0.6667\n",
      "Epoch 9 | Iter11 | Loss0.6889 | val acc 0.6458\n",
      "Epoch 9 | Iter13 | Loss0.6250 | val acc 0.5208\n",
      "Epoch 9 | Iter15 | Loss0.7050 | val acc 0.6250\n",
      "Epoch 9 | Iter17 | Loss0.6808 | val acc 0.6042\n",
      "Epoch 10 | Iter1 | Loss0.5672 | val acc 0.6042\n",
      "Epoch 10 | Iter3 | Loss0.6370 | val acc 0.6250\n",
      "Epoch 10 | Iter5 | Loss0.7306 | val acc 0.6667\n",
      "Epoch 10 | Iter7 | Loss0.6461 | val acc 0.5625\n",
      "Epoch 10 | Iter9 | Loss0.7137 | val acc 0.5833\n",
      "Epoch 10 | Iter11 | Loss0.5919 | val acc 0.6042\n",
      "Epoch 10 | Iter13 | Loss0.6062 | val acc 0.5833\n",
      "Epoch 10 | Iter15 | Loss0.5384 | val acc 0.6667\n",
      "Epoch 10 | Iter17 | Loss0.4397 | val acc 0.5417\n",
      "Epoch 11 | Iter1 | Loss0.5876 | val acc 0.5625\n",
      "Epoch 11 | Iter3 | Loss0.7559 | val acc 0.5625\n",
      "Epoch 11 | Iter5 | Loss0.5130 | val acc 0.5625\n",
      "Epoch 11 | Iter7 | Loss0.6534 | val acc 0.5625\n",
      "Epoch 11 | Iter9 | Loss0.6294 | val acc 0.5417\n",
      "Epoch 11 | Iter11 | Loss0.5460 | val acc 0.6250\n",
      "Epoch 11 | Iter13 | Loss0.6204 | val acc 0.6042\n",
      "Epoch 11 | Iter15 | Loss0.5266 | val acc 0.5833\n",
      "Epoch 11 | Iter17 | Loss0.4952 | val acc 0.6458\n",
      "Epoch 12 | Iter1 | Loss0.5246 | val acc 0.6875\n",
      "Epoch 12 | Iter3 | Loss0.6307 | val acc 0.6250\n",
      "Epoch 12 | Iter5 | Loss0.4794 | val acc 0.4792\n",
      "Epoch 12 | Iter7 | Loss0.4500 | val acc 0.5417\n",
      "Epoch 12 | Iter9 | Loss0.5730 | val acc 0.5208\n",
      "Epoch 12 | Iter11 | Loss0.6735 | val acc 0.5000\n",
      "Epoch 12 | Iter13 | Loss0.6351 | val acc 0.5417\n",
      "Epoch 12 | Iter15 | Loss0.6615 | val acc 0.5625\n",
      "Epoch 12 | Iter17 | Loss0.4455 | val acc 0.5833\n",
      "Epoch 13 | Iter1 | Loss0.5475 | val acc 0.5208\n",
      "Epoch 13 | Iter3 | Loss0.4383 | val acc 0.5625\n",
      "Epoch 13 | Iter5 | Loss0.3902 | val acc 0.6042\n",
      "Epoch 13 | Iter7 | Loss0.4253 | val acc 0.5625\n",
      "Epoch 13 | Iter9 | Loss0.5245 | val acc 0.5833\n",
      "Epoch 13 | Iter11 | Loss0.4289 | val acc 0.6667\n",
      "Epoch 13 | Iter13 | Loss0.5039 | val acc 0.5625\n",
      "Epoch 13 | Iter15 | Loss0.4575 | val acc 0.5833\n",
      "Epoch 13 | Iter17 | Loss0.5620 | val acc 0.5417\n",
      "Epoch 14 | Iter1 | Loss0.6353 | val acc 0.6042\n",
      "Epoch 14 | Iter3 | Loss0.6378 | val acc 0.6250\n",
      "Epoch 14 | Iter5 | Loss0.5492 | val acc 0.6250\n",
      "Epoch 14 | Iter7 | Loss0.4534 | val acc 0.6875\n",
      "Epoch 14 | Iter9 | Loss0.5181 | val acc 0.6667\n",
      "Epoch 14 | Iter11 | Loss0.5960 | val acc 0.6875\n",
      "Epoch 14 | Iter13 | Loss0.3591 | val acc 0.6667\n",
      "Epoch 14 | Iter15 | Loss0.4903 | val acc 0.6458\n",
      "Epoch 14 | Iter17 | Loss0.3955 | val acc 0.5417\n",
      "Epoch 15 | Iter1 | Loss0.4759 | val acc 0.5833\n",
      "Epoch 15 | Iter3 | Loss0.3976 | val acc 0.5417\n",
      "Epoch 15 | Iter5 | Loss0.3522 | val acc 0.5625\n",
      "Epoch 15 | Iter7 | Loss0.4041 | val acc 0.7500\n",
      "Epoch 15 | Iter9 | Loss0.4010 | val acc 0.6250\n",
      "Epoch 15 | Iter11 | Loss0.5017 | val acc 0.5833\n",
      "Epoch 15 | Iter13 | Loss0.3156 | val acc 0.6042\n",
      "Epoch 15 | Iter15 | Loss0.3613 | val acc 0.5833\n",
      "Epoch 15 | Iter17 | Loss0.5118 | val acc 0.5625\n",
      "Epoch 16 | Iter1 | Loss0.2658 | val acc 0.6458\n",
      "Epoch 16 | Iter3 | Loss0.3791 | val acc 0.6042\n",
      "Epoch 16 | Iter5 | Loss0.4131 | val acc 0.6042\n",
      "Epoch 16 | Iter7 | Loss0.4418 | val acc 0.5833\n",
      "Epoch 16 | Iter9 | Loss0.4035 | val acc 0.6667\n",
      "Epoch 16 | Iter11 | Loss0.4296 | val acc 0.6458\n",
      "Epoch 16 | Iter13 | Loss0.3848 | val acc 0.6458\n",
      "Epoch 16 | Iter15 | Loss0.4601 | val acc 0.5833\n",
      "Epoch 16 | Iter17 | Loss0.2955 | val acc 0.6875\n",
      "Epoch 17 | Iter1 | Loss0.4681 | val acc 0.5417\n",
      "Epoch 17 | Iter3 | Loss0.5142 | val acc 0.5417\n",
      "Epoch 17 | Iter5 | Loss0.3921 | val acc 0.6042\n",
      "Epoch 17 | Iter7 | Loss0.2811 | val acc 0.5833\n",
      "Epoch 17 | Iter9 | Loss0.3314 | val acc 0.5208\n",
      "Epoch 17 | Iter11 | Loss0.3300 | val acc 0.5833\n",
      "Epoch 17 | Iter13 | Loss0.3563 | val acc 0.5417\n",
      "Epoch 17 | Iter15 | Loss0.3071 | val acc 0.6042\n",
      "Epoch 17 | Iter17 | Loss0.3220 | val acc 0.5417\n",
      "Epoch 18 | Iter1 | Loss0.5287 | val acc 0.6042\n",
      "Epoch 18 | Iter3 | Loss0.3150 | val acc 0.5208\n",
      "Epoch 18 | Iter5 | Loss0.2474 | val acc 0.5625\n",
      "Epoch 18 | Iter7 | Loss0.2706 | val acc 0.6250\n",
      "Epoch 18 | Iter9 | Loss0.6482 | val acc 0.5625\n",
      "Epoch 18 | Iter11 | Loss0.3741 | val acc 0.4792\n",
      "Epoch 18 | Iter13 | Loss0.3120 | val acc 0.4167\n",
      "Epoch 18 | Iter15 | Loss0.3834 | val acc 0.5000\n",
      "Epoch 18 | Iter17 | Loss0.4670 | val acc 0.4375\n",
      "Epoch 19 | Iter1 | Loss0.2812 | val acc 0.5417\n",
      "Epoch 19 | Iter3 | Loss0.3187 | val acc 0.5000\n",
      "Epoch 19 | Iter5 | Loss0.3493 | val acc 0.5417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Iter7 | Loss0.3091 | val acc 0.5417\n",
      "Epoch 19 | Iter9 | Loss0.2635 | val acc 0.5417\n",
      "Epoch 19 | Iter11 | Loss0.3395 | val acc 0.5208\n",
      "Epoch 19 | Iter13 | Loss0.3545 | val acc 0.4583\n",
      "Epoch 19 | Iter15 | Loss0.4491 | val acc 0.5208\n",
      "Epoch 19 | Iter17 | Loss0.3643 | val acc 0.6250\n",
      "Epoch 20 | Iter1 | Loss0.3242 | val acc 0.5625\n",
      "Epoch 20 | Iter3 | Loss0.1405 | val acc 0.5833\n",
      "Epoch 20 | Iter5 | Loss0.5106 | val acc 0.5833\n",
      "Epoch 20 | Iter7 | Loss0.2365 | val acc 0.5417\n",
      "Epoch 20 | Iter9 | Loss0.4577 | val acc 0.5833\n",
      "Epoch 20 | Iter11 | Loss0.3698 | val acc 0.5000\n",
      "Epoch 20 | Iter13 | Loss0.4515 | val acc 0.6250\n",
      "Epoch 20 | Iter15 | Loss0.3155 | val acc 0.6250\n",
      "Epoch 20 | Iter17 | Loss0.4360 | val acc 0.5833\n",
      "Epoch 21 | Iter1 | Loss0.2841 | val acc 0.6042\n",
      "Epoch 21 | Iter3 | Loss0.1654 | val acc 0.5417\n",
      "Epoch 21 | Iter5 | Loss0.3551 | val acc 0.4375\n",
      "Epoch 21 | Iter7 | Loss0.3774 | val acc 0.5625\n",
      "Epoch 21 | Iter9 | Loss0.4002 | val acc 0.5833\n",
      "Epoch 21 | Iter11 | Loss0.3028 | val acc 0.5417\n",
      "Epoch 21 | Iter13 | Loss0.4463 | val acc 0.5417\n",
      "Epoch 21 | Iter15 | Loss0.3641 | val acc 0.5625\n",
      "Epoch 21 | Iter17 | Loss0.3791 | val acc 0.5833\n",
      "Epoch 22 | Iter1 | Loss0.4117 | val acc 0.6667\n",
      "Epoch 22 | Iter3 | Loss0.5027 | val acc 0.6458\n",
      "Epoch 22 | Iter5 | Loss0.2339 | val acc 0.6250\n",
      "Epoch 22 | Iter7 | Loss0.2804 | val acc 0.6458\n",
      "Epoch 22 | Iter9 | Loss0.2652 | val acc 0.6042\n",
      "Epoch 22 | Iter11 | Loss0.2831 | val acc 0.6250\n",
      "Epoch 22 | Iter13 | Loss0.1537 | val acc 0.6250\n",
      "Epoch 22 | Iter15 | Loss0.3871 | val acc 0.6667\n",
      "Epoch 22 | Iter17 | Loss0.2220 | val acc 0.6458\n",
      "Epoch 23 | Iter1 | Loss0.2531 | val acc 0.6250\n",
      "Epoch 23 | Iter3 | Loss0.2651 | val acc 0.6458\n",
      "Epoch 23 | Iter5 | Loss0.4616 | val acc 0.6667\n",
      "Epoch 23 | Iter7 | Loss0.3658 | val acc 0.6250\n",
      "Epoch 23 | Iter9 | Loss0.3996 | val acc 0.6250\n",
      "Epoch 23 | Iter11 | Loss0.2737 | val acc 0.5625\n",
      "Epoch 23 | Iter13 | Loss0.3990 | val acc 0.6458\n",
      "Epoch 23 | Iter15 | Loss0.3680 | val acc 0.7083\n",
      "Epoch 23 | Iter17 | Loss0.3317 | val acc 0.6458\n",
      "Epoch 24 | Iter1 | Loss0.2462 | val acc 0.6667\n",
      "Epoch 24 | Iter3 | Loss0.3484 | val acc 0.6458\n",
      "Epoch 24 | Iter5 | Loss0.3582 | val acc 0.7500\n",
      "Epoch 24 | Iter7 | Loss0.3657 | val acc 0.7292\n",
      "Epoch 24 | Iter9 | Loss0.2498 | val acc 0.7083\n",
      "Epoch 24 | Iter11 | Loss0.3131 | val acc 0.6250\n",
      "Epoch 24 | Iter13 | Loss0.2475 | val acc 0.6250\n",
      "Epoch 24 | Iter15 | Loss0.2530 | val acc 0.6667\n",
      "Epoch 24 | Iter17 | Loss0.1931 | val acc 0.6250\n",
      "Epoch 25 | Iter1 | Loss0.3613 | val acc 0.6667\n",
      "Epoch 25 | Iter3 | Loss0.3562 | val acc 0.5208\n",
      "Epoch 25 | Iter5 | Loss0.4003 | val acc 0.5208\n",
      "Epoch 25 | Iter7 | Loss0.3579 | val acc 0.6250\n",
      "Epoch 25 | Iter9 | Loss0.2260 | val acc 0.6667\n",
      "Epoch 25 | Iter11 | Loss0.2896 | val acc 0.6667\n",
      "Epoch 25 | Iter13 | Loss0.3110 | val acc 0.6875\n",
      "Epoch 25 | Iter15 | Loss0.3268 | val acc 0.6250\n",
      "Epoch 25 | Iter17 | Loss0.4569 | val acc 0.6667\n",
      "--------------------------------------------------\n",
      "Training Net 2\n",
      "Epoch 0 | Iter1 | Loss1.6756 | val acc 0.1875\n",
      "Epoch 0 | Iter3 | Loss1.5849 | val acc 0.3750\n",
      "Epoch 0 | Iter5 | Loss1.5781 | val acc 0.3958\n",
      "Epoch 0 | Iter7 | Loss1.4746 | val acc 0.4167\n",
      "Epoch 0 | Iter9 | Loss1.5665 | val acc 0.4167\n",
      "Epoch 0 | Iter11 | Loss1.6219 | val acc 0.3750\n",
      "Epoch 0 | Iter13 | Loss1.4768 | val acc 0.3125\n",
      "Epoch 0 | Iter15 | Loss1.3997 | val acc 0.3542\n",
      "Epoch 0 | Iter17 | Loss1.5679 | val acc 0.3542\n",
      "Epoch 1 | Iter1 | Loss1.5012 | val acc 0.3333\n",
      "Epoch 1 | Iter3 | Loss1.4112 | val acc 0.3750\n",
      "Epoch 1 | Iter5 | Loss1.3321 | val acc 0.4167\n",
      "Epoch 1 | Iter7 | Loss1.4531 | val acc 0.3958\n",
      "Epoch 1 | Iter9 | Loss1.3352 | val acc 0.3542\n",
      "Epoch 1 | Iter11 | Loss1.2954 | val acc 0.3333\n",
      "Epoch 1 | Iter13 | Loss1.4160 | val acc 0.3542\n",
      "Epoch 1 | Iter15 | Loss1.4119 | val acc 0.3750\n",
      "Epoch 1 | Iter17 | Loss1.1816 | val acc 0.4375\n",
      "Epoch 2 | Iter1 | Loss1.4220 | val acc 0.3333\n",
      "Epoch 2 | Iter3 | Loss1.3211 | val acc 0.3542\n",
      "Epoch 2 | Iter5 | Loss1.2076 | val acc 0.4792\n",
      "Epoch 2 | Iter7 | Loss1.1199 | val acc 0.4583\n",
      "Epoch 2 | Iter9 | Loss1.3669 | val acc 0.4792\n",
      "Epoch 2 | Iter11 | Loss1.3062 | val acc 0.4583\n",
      "Epoch 2 | Iter13 | Loss1.1103 | val acc 0.4583\n",
      "Epoch 2 | Iter15 | Loss1.3186 | val acc 0.4792\n",
      "Epoch 2 | Iter17 | Loss1.1743 | val acc 0.5208\n",
      "Epoch 3 | Iter1 | Loss1.1686 | val acc 0.5000\n",
      "Epoch 3 | Iter3 | Loss1.3080 | val acc 0.5417\n",
      "Epoch 3 | Iter5 | Loss1.2093 | val acc 0.4375\n",
      "Epoch 3 | Iter7 | Loss1.1266 | val acc 0.3750\n",
      "Epoch 3 | Iter9 | Loss1.1373 | val acc 0.5417\n",
      "Epoch 3 | Iter11 | Loss1.2223 | val acc 0.4792\n",
      "Epoch 3 | Iter13 | Loss1.0364 | val acc 0.4375\n",
      "Epoch 3 | Iter15 | Loss1.1874 | val acc 0.4583\n",
      "Epoch 3 | Iter17 | Loss1.4370 | val acc 0.5417\n",
      "Epoch 4 | Iter1 | Loss0.9786 | val acc 0.5417\n",
      "Epoch 4 | Iter3 | Loss1.2088 | val acc 0.5833\n",
      "Epoch 4 | Iter5 | Loss0.9996 | val acc 0.5417\n",
      "Epoch 4 | Iter7 | Loss1.1774 | val acc 0.5208\n",
      "Epoch 4 | Iter9 | Loss1.0904 | val acc 0.6042\n",
      "Epoch 4 | Iter11 | Loss1.1606 | val acc 0.5625\n",
      "Epoch 4 | Iter13 | Loss0.9431 | val acc 0.4583\n",
      "Epoch 4 | Iter15 | Loss0.9842 | val acc 0.5000\n",
      "Epoch 4 | Iter17 | Loss0.8504 | val acc 0.5417\n",
      "Epoch 5 | Iter1 | Loss1.1208 | val acc 0.5208\n",
      "Epoch 5 | Iter3 | Loss1.0110 | val acc 0.5625\n",
      "Epoch 5 | Iter5 | Loss0.9223 | val acc 0.5208\n",
      "Epoch 5 | Iter7 | Loss1.0015 | val acc 0.5417\n",
      "Epoch 5 | Iter9 | Loss0.9972 | val acc 0.5833\n",
      "Epoch 5 | Iter11 | Loss0.9787 | val acc 0.5625\n",
      "Epoch 5 | Iter13 | Loss1.0359 | val acc 0.5833\n",
      "Epoch 5 | Iter15 | Loss0.9576 | val acc 0.5417\n",
      "Epoch 5 | Iter17 | Loss0.8993 | val acc 0.5417\n",
      "Epoch 6 | Iter1 | Loss0.9264 | val acc 0.4792\n",
      "Epoch 6 | Iter3 | Loss0.9005 | val acc 0.5000\n",
      "Epoch 6 | Iter5 | Loss1.1249 | val acc 0.4792\n",
      "Epoch 6 | Iter7 | Loss0.9152 | val acc 0.5833\n",
      "Epoch 6 | Iter9 | Loss0.9227 | val acc 0.5625\n",
      "Epoch 6 | Iter11 | Loss0.7674 | val acc 0.6042\n",
      "Epoch 6 | Iter13 | Loss0.7407 | val acc 0.5417\n",
      "Epoch 6 | Iter15 | Loss0.7322 | val acc 0.5625\n",
      "Epoch 6 | Iter17 | Loss0.8018 | val acc 0.5000\n",
      "Epoch 7 | Iter1 | Loss0.7689 | val acc 0.5833\n",
      "Epoch 7 | Iter3 | Loss0.8168 | val acc 0.5417\n",
      "Epoch 7 | Iter5 | Loss0.7308 | val acc 0.5208\n",
      "Epoch 7 | Iter7 | Loss0.7176 | val acc 0.5208\n",
      "Epoch 7 | Iter9 | Loss0.7692 | val acc 0.5000\n",
      "Epoch 7 | Iter11 | Loss0.9063 | val acc 0.5417\n",
      "Epoch 7 | Iter13 | Loss0.7940 | val acc 0.4583\n",
      "Epoch 7 | Iter15 | Loss0.7495 | val acc 0.4583\n",
      "Epoch 7 | Iter17 | Loss0.8013 | val acc 0.4792\n",
      "Epoch 8 | Iter1 | Loss0.7181 | val acc 0.5208\n",
      "Epoch 8 | Iter3 | Loss0.7422 | val acc 0.4583\n",
      "Epoch 8 | Iter5 | Loss0.7916 | val acc 0.6042\n",
      "Epoch 8 | Iter7 | Loss0.6073 | val acc 0.5833\n",
      "Epoch 8 | Iter9 | Loss0.6533 | val acc 0.5417\n",
      "Epoch 8 | Iter11 | Loss0.6781 | val acc 0.6042\n",
      "Epoch 8 | Iter13 | Loss0.7909 | val acc 0.5625\n",
      "Epoch 8 | Iter15 | Loss0.7312 | val acc 0.5208\n",
      "Epoch 8 | Iter17 | Loss0.8433 | val acc 0.5417\n",
      "Epoch 9 | Iter1 | Loss0.7125 | val acc 0.6042\n",
      "Epoch 9 | Iter3 | Loss0.7841 | val acc 0.5417\n",
      "Epoch 9 | Iter5 | Loss0.6262 | val acc 0.6875\n",
      "Epoch 9 | Iter7 | Loss0.6847 | val acc 0.6458\n",
      "Epoch 9 | Iter9 | Loss0.7117 | val acc 0.5625\n",
      "Epoch 9 | Iter11 | Loss0.5730 | val acc 0.5833\n",
      "Epoch 9 | Iter13 | Loss0.6352 | val acc 0.6250\n",
      "Epoch 9 | Iter15 | Loss0.7440 | val acc 0.7083\n",
      "Epoch 9 | Iter17 | Loss0.7122 | val acc 0.5000\n",
      "Epoch 10 | Iter1 | Loss0.6864 | val acc 0.6250\n",
      "Epoch 10 | Iter3 | Loss0.7016 | val acc 0.7083\n",
      "Epoch 10 | Iter5 | Loss0.6011 | val acc 0.6250\n",
      "Epoch 10 | Iter7 | Loss0.7183 | val acc 0.6250\n",
      "Epoch 10 | Iter9 | Loss0.6412 | val acc 0.6458\n",
      "Epoch 10 | Iter11 | Loss0.6636 | val acc 0.5833\n",
      "Epoch 10 | Iter13 | Loss0.6211 | val acc 0.5833\n",
      "Epoch 10 | Iter15 | Loss0.5708 | val acc 0.6250\n",
      "Epoch 10 | Iter17 | Loss0.6075 | val acc 0.6875\n",
      "Epoch 11 | Iter1 | Loss0.6134 | val acc 0.6667\n",
      "Epoch 11 | Iter3 | Loss0.5788 | val acc 0.6667\n",
      "Epoch 11 | Iter5 | Loss0.7056 | val acc 0.7292\n",
      "Epoch 11 | Iter7 | Loss0.4772 | val acc 0.6250\n",
      "Epoch 11 | Iter9 | Loss0.5836 | val acc 0.6042\n",
      "Epoch 11 | Iter11 | Loss0.5975 | val acc 0.5833\n",
      "Epoch 11 | Iter13 | Loss0.4182 | val acc 0.5833\n",
      "Epoch 11 | Iter15 | Loss0.4242 | val acc 0.5833\n",
      "Epoch 11 | Iter17 | Loss0.5433 | val acc 0.6458\n",
      "Epoch 12 | Iter1 | Loss0.4002 | val acc 0.6042\n",
      "Epoch 12 | Iter3 | Loss0.4941 | val acc 0.6458\n",
      "Epoch 12 | Iter5 | Loss0.5565 | val acc 0.7083\n",
      "Epoch 12 | Iter7 | Loss0.4291 | val acc 0.7083\n",
      "Epoch 12 | Iter9 | Loss0.4990 | val acc 0.6458\n",
      "Epoch 12 | Iter11 | Loss0.5259 | val acc 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Iter13 | Loss0.5614 | val acc 0.6667\n",
      "Epoch 12 | Iter15 | Loss0.4491 | val acc 0.6667\n",
      "Epoch 12 | Iter17 | Loss0.4500 | val acc 0.6250\n",
      "Epoch 13 | Iter1 | Loss0.5091 | val acc 0.6875\n",
      "Epoch 13 | Iter3 | Loss0.4886 | val acc 0.6458\n",
      "Epoch 13 | Iter5 | Loss0.3700 | val acc 0.6458\n",
      "Epoch 13 | Iter7 | Loss0.4390 | val acc 0.6250\n",
      "Epoch 13 | Iter9 | Loss0.5623 | val acc 0.6667\n",
      "Epoch 13 | Iter11 | Loss0.4018 | val acc 0.6042\n",
      "Epoch 13 | Iter13 | Loss0.4504 | val acc 0.6875\n",
      "Epoch 13 | Iter15 | Loss0.4194 | val acc 0.6250\n",
      "Epoch 13 | Iter17 | Loss0.3816 | val acc 0.6250\n",
      "Epoch 14 | Iter1 | Loss0.4634 | val acc 0.6042\n",
      "Epoch 14 | Iter3 | Loss0.6179 | val acc 0.6667\n",
      "Epoch 14 | Iter5 | Loss0.3669 | val acc 0.7083\n",
      "Epoch 14 | Iter7 | Loss0.4292 | val acc 0.6875\n",
      "Epoch 14 | Iter9 | Loss0.6855 | val acc 0.5625\n",
      "Epoch 14 | Iter11 | Loss0.4533 | val acc 0.6667\n",
      "Epoch 14 | Iter13 | Loss0.4271 | val acc 0.6667\n",
      "Epoch 14 | Iter15 | Loss0.4015 | val acc 0.6042\n",
      "Epoch 14 | Iter17 | Loss0.4293 | val acc 0.6875\n",
      "Epoch 15 | Iter1 | Loss0.2645 | val acc 0.6250\n",
      "Epoch 15 | Iter3 | Loss0.4846 | val acc 0.6042\n",
      "Epoch 15 | Iter5 | Loss0.4120 | val acc 0.6667\n",
      "Epoch 15 | Iter7 | Loss0.6228 | val acc 0.5000\n",
      "Epoch 15 | Iter9 | Loss0.6549 | val acc 0.5000\n",
      "Epoch 15 | Iter11 | Loss0.4485 | val acc 0.6250\n",
      "Epoch 15 | Iter13 | Loss0.4633 | val acc 0.6250\n",
      "Epoch 15 | Iter15 | Loss0.4178 | val acc 0.6667\n",
      "Epoch 15 | Iter17 | Loss0.3384 | val acc 0.6667\n",
      "Epoch 16 | Iter1 | Loss0.3291 | val acc 0.6875\n",
      "Epoch 16 | Iter3 | Loss0.4398 | val acc 0.6875\n",
      "Epoch 16 | Iter5 | Loss0.4858 | val acc 0.6875\n",
      "Epoch 16 | Iter7 | Loss0.3389 | val acc 0.6667\n",
      "Epoch 16 | Iter9 | Loss0.4990 | val acc 0.6042\n",
      "Epoch 16 | Iter11 | Loss0.4263 | val acc 0.6875\n",
      "Epoch 16 | Iter13 | Loss0.3701 | val acc 0.6250\n",
      "Epoch 16 | Iter15 | Loss0.3935 | val acc 0.6250\n",
      "Epoch 16 | Iter17 | Loss0.3830 | val acc 0.6042\n",
      "Epoch 17 | Iter1 | Loss0.3451 | val acc 0.6458\n",
      "Epoch 17 | Iter3 | Loss0.2845 | val acc 0.6250\n",
      "Epoch 17 | Iter5 | Loss0.3681 | val acc 0.6042\n",
      "Epoch 17 | Iter7 | Loss0.3773 | val acc 0.6042\n",
      "Epoch 17 | Iter9 | Loss0.3702 | val acc 0.6875\n",
      "Epoch 17 | Iter11 | Loss0.3734 | val acc 0.6250\n",
      "Epoch 17 | Iter13 | Loss0.3505 | val acc 0.6458\n",
      "Epoch 17 | Iter15 | Loss0.3491 | val acc 0.5625\n",
      "Epoch 17 | Iter17 | Loss0.4775 | val acc 0.6042\n",
      "Epoch 18 | Iter1 | Loss0.3546 | val acc 0.5625\n",
      "Epoch 18 | Iter3 | Loss0.2655 | val acc 0.5833\n",
      "Epoch 18 | Iter5 | Loss0.3797 | val acc 0.5833\n",
      "Epoch 18 | Iter7 | Loss0.3259 | val acc 0.6250\n",
      "Epoch 18 | Iter9 | Loss0.3546 | val acc 0.6250\n",
      "Epoch 18 | Iter11 | Loss0.3590 | val acc 0.6250\n",
      "Epoch 18 | Iter13 | Loss0.5611 | val acc 0.5625\n",
      "Epoch 18 | Iter15 | Loss0.3017 | val acc 0.6458\n",
      "Epoch 18 | Iter17 | Loss0.3747 | val acc 0.6042\n",
      "Epoch 19 | Iter1 | Loss0.2384 | val acc 0.6875\n",
      "Epoch 19 | Iter3 | Loss0.4429 | val acc 0.6875\n",
      "Epoch 19 | Iter5 | Loss0.3625 | val acc 0.6667\n",
      "Epoch 19 | Iter7 | Loss0.3290 | val acc 0.6458\n",
      "Epoch 19 | Iter9 | Loss0.4293 | val acc 0.5833\n",
      "Epoch 19 | Iter11 | Loss0.2651 | val acc 0.5833\n",
      "Epoch 19 | Iter13 | Loss0.3968 | val acc 0.5833\n",
      "Epoch 19 | Iter15 | Loss0.3403 | val acc 0.6458\n",
      "Epoch 19 | Iter17 | Loss0.2614 | val acc 0.6875\n",
      "Epoch 20 | Iter1 | Loss0.3987 | val acc 0.6458\n",
      "Epoch 20 | Iter3 | Loss0.4160 | val acc 0.6667\n",
      "Epoch 20 | Iter5 | Loss0.3524 | val acc 0.5417\n",
      "Epoch 20 | Iter7 | Loss0.3048 | val acc 0.5625\n",
      "Epoch 20 | Iter9 | Loss0.3745 | val acc 0.5833\n",
      "Epoch 20 | Iter11 | Loss0.2640 | val acc 0.5833\n",
      "Epoch 20 | Iter13 | Loss0.2771 | val acc 0.6458\n",
      "Epoch 20 | Iter15 | Loss0.1836 | val acc 0.6458\n",
      "Epoch 20 | Iter17 | Loss0.1792 | val acc 0.6875\n",
      "Epoch 21 | Iter1 | Loss0.3681 | val acc 0.6667\n",
      "Epoch 21 | Iter3 | Loss0.2588 | val acc 0.6250\n",
      "Epoch 21 | Iter5 | Loss0.2632 | val acc 0.6042\n",
      "Epoch 21 | Iter7 | Loss0.3803 | val acc 0.6250\n",
      "Epoch 21 | Iter9 | Loss0.3241 | val acc 0.6458\n",
      "Epoch 21 | Iter11 | Loss0.3137 | val acc 0.6458\n",
      "Epoch 21 | Iter13 | Loss0.2676 | val acc 0.6458\n",
      "Epoch 21 | Iter15 | Loss0.2536 | val acc 0.6667\n",
      "Epoch 21 | Iter17 | Loss0.4205 | val acc 0.6667\n",
      "Epoch 22 | Iter1 | Loss0.4379 | val acc 0.6250\n",
      "Epoch 22 | Iter3 | Loss0.2695 | val acc 0.6875\n",
      "Epoch 22 | Iter5 | Loss0.3435 | val acc 0.6875\n",
      "Epoch 22 | Iter7 | Loss0.1694 | val acc 0.7083\n",
      "Epoch 22 | Iter9 | Loss0.2940 | val acc 0.6458\n",
      "Epoch 22 | Iter11 | Loss0.2814 | val acc 0.5833\n",
      "Epoch 22 | Iter13 | Loss0.3564 | val acc 0.6250\n",
      "Epoch 22 | Iter15 | Loss0.2534 | val acc 0.5833\n",
      "Epoch 22 | Iter17 | Loss0.2380 | val acc 0.6250\n",
      "Epoch 23 | Iter1 | Loss0.3084 | val acc 0.6250\n",
      "Epoch 23 | Iter3 | Loss0.3156 | val acc 0.6875\n",
      "Epoch 23 | Iter5 | Loss0.2079 | val acc 0.6875\n",
      "Epoch 23 | Iter7 | Loss0.2381 | val acc 0.6667\n",
      "Epoch 23 | Iter9 | Loss0.2400 | val acc 0.6875\n",
      "Epoch 23 | Iter11 | Loss0.2504 | val acc 0.7083\n",
      "Epoch 23 | Iter13 | Loss0.2319 | val acc 0.6667\n",
      "Epoch 23 | Iter15 | Loss0.3609 | val acc 0.5625\n",
      "Epoch 23 | Iter17 | Loss0.1700 | val acc 0.4583\n",
      "Epoch 24 | Iter1 | Loss0.3562 | val acc 0.4792\n",
      "Epoch 24 | Iter3 | Loss0.2748 | val acc 0.6458\n",
      "Epoch 24 | Iter5 | Loss0.3821 | val acc 0.6042\n",
      "Epoch 24 | Iter7 | Loss0.3143 | val acc 0.6667\n",
      "Epoch 24 | Iter9 | Loss0.3165 | val acc 0.6458\n",
      "Epoch 24 | Iter11 | Loss0.3525 | val acc 0.6875\n",
      "Epoch 24 | Iter13 | Loss0.3625 | val acc 0.6250\n",
      "Epoch 24 | Iter15 | Loss0.3551 | val acc 0.6250\n",
      "Epoch 24 | Iter17 | Loss0.4353 | val acc 0.6250\n",
      "Epoch 25 | Iter1 | Loss0.2307 | val acc 0.5625\n",
      "Epoch 25 | Iter3 | Loss0.2498 | val acc 0.6667\n",
      "Epoch 25 | Iter5 | Loss0.2945 | val acc 0.6667\n",
      "Epoch 25 | Iter7 | Loss0.3782 | val acc 0.6250\n",
      "Epoch 25 | Iter9 | Loss0.3140 | val acc 0.5833\n",
      "Epoch 25 | Iter11 | Loss0.1962 | val acc 0.5833\n",
      "Epoch 25 | Iter13 | Loss0.1613 | val acc 0.6042\n",
      "Epoch 25 | Iter15 | Loss0.2071 | val acc 0.6667\n",
      "Epoch 25 | Iter17 | Loss0.1999 | val acc 0.6667\n",
      "--------------------------------------------------\n",
      "Training Net 3\n",
      "Epoch 0 | Iter1 | Loss1.4555 | val acc 0.2708\n",
      "Epoch 0 | Iter3 | Loss1.3864 | val acc 0.3125\n",
      "Epoch 0 | Iter5 | Loss1.7598 | val acc 0.2917\n",
      "Epoch 0 | Iter7 | Loss1.6281 | val acc 0.2917\n",
      "Epoch 0 | Iter9 | Loss1.5056 | val acc 0.2917\n",
      "Epoch 0 | Iter11 | Loss1.3767 | val acc 0.3125\n",
      "Epoch 0 | Iter13 | Loss1.6375 | val acc 0.2917\n",
      "Epoch 0 | Iter15 | Loss1.5866 | val acc 0.2708\n",
      "Epoch 0 | Iter17 | Loss1.3171 | val acc 0.2708\n",
      "Epoch 1 | Iter1 | Loss1.2810 | val acc 0.3333\n",
      "Epoch 1 | Iter3 | Loss1.6098 | val acc 0.2708\n",
      "Epoch 1 | Iter5 | Loss1.4470 | val acc 0.3750\n",
      "Epoch 1 | Iter7 | Loss1.3775 | val acc 0.3333\n",
      "Epoch 1 | Iter9 | Loss1.3716 | val acc 0.3125\n",
      "Epoch 1 | Iter11 | Loss1.5058 | val acc 0.2917\n",
      "Epoch 1 | Iter13 | Loss1.1669 | val acc 0.2500\n",
      "Epoch 1 | Iter15 | Loss1.3319 | val acc 0.2292\n",
      "Epoch 1 | Iter17 | Loss1.2882 | val acc 0.3125\n",
      "Epoch 2 | Iter1 | Loss1.1865 | val acc 0.2917\n",
      "Epoch 2 | Iter3 | Loss1.5018 | val acc 0.3750\n",
      "Epoch 2 | Iter5 | Loss1.4496 | val acc 0.3750\n",
      "Epoch 2 | Iter7 | Loss1.3625 | val acc 0.4792\n",
      "Epoch 2 | Iter9 | Loss1.4341 | val acc 0.4792\n",
      "Epoch 2 | Iter11 | Loss1.2902 | val acc 0.4792\n",
      "Epoch 2 | Iter13 | Loss1.2046 | val acc 0.4167\n",
      "Epoch 2 | Iter15 | Loss1.0885 | val acc 0.4792\n",
      "Epoch 2 | Iter17 | Loss1.2941 | val acc 0.4583\n",
      "Epoch 3 | Iter1 | Loss1.4005 | val acc 0.4375\n",
      "Epoch 3 | Iter3 | Loss1.2029 | val acc 0.4375\n",
      "Epoch 3 | Iter5 | Loss0.9879 | val acc 0.3958\n",
      "Epoch 3 | Iter7 | Loss1.4181 | val acc 0.4167\n",
      "Epoch 3 | Iter9 | Loss1.3579 | val acc 0.5000\n",
      "Epoch 3 | Iter11 | Loss1.1436 | val acc 0.4792\n",
      "Epoch 3 | Iter13 | Loss1.0899 | val acc 0.3750\n",
      "Epoch 3 | Iter15 | Loss1.2010 | val acc 0.5417\n",
      "Epoch 3 | Iter17 | Loss1.0051 | val acc 0.4792\n",
      "Epoch 4 | Iter1 | Loss1.0964 | val acc 0.4792\n",
      "Epoch 4 | Iter3 | Loss1.1010 | val acc 0.5208\n",
      "Epoch 4 | Iter5 | Loss1.1592 | val acc 0.4792\n",
      "Epoch 4 | Iter7 | Loss0.9948 | val acc 0.5208\n",
      "Epoch 4 | Iter9 | Loss1.0018 | val acc 0.4375\n",
      "Epoch 4 | Iter11 | Loss1.3720 | val acc 0.5000\n",
      "Epoch 4 | Iter13 | Loss1.1789 | val acc 0.5208\n",
      "Epoch 4 | Iter15 | Loss0.9082 | val acc 0.4792\n",
      "Epoch 4 | Iter17 | Loss1.0800 | val acc 0.2917\n",
      "Epoch 5 | Iter1 | Loss1.1377 | val acc 0.2708\n",
      "Epoch 5 | Iter3 | Loss0.9886 | val acc 0.4792\n",
      "Epoch 5 | Iter5 | Loss1.0499 | val acc 0.5208\n",
      "Epoch 5 | Iter7 | Loss1.0317 | val acc 0.5208\n",
      "Epoch 5 | Iter9 | Loss0.7825 | val acc 0.6042\n",
      "Epoch 5 | Iter11 | Loss1.0365 | val acc 0.5417\n",
      "Epoch 5 | Iter13 | Loss0.8935 | val acc 0.6042\n",
      "Epoch 5 | Iter15 | Loss1.0447 | val acc 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Iter17 | Loss0.9718 | val acc 0.5208\n",
      "Epoch 6 | Iter1 | Loss0.8852 | val acc 0.5000\n",
      "Epoch 6 | Iter3 | Loss0.8972 | val acc 0.5625\n",
      "Epoch 6 | Iter5 | Loss0.7457 | val acc 0.5000\n",
      "Epoch 6 | Iter7 | Loss0.9776 | val acc 0.6042\n",
      "Epoch 6 | Iter9 | Loss0.7779 | val acc 0.5625\n",
      "Epoch 6 | Iter11 | Loss0.7557 | val acc 0.5625\n",
      "Epoch 6 | Iter13 | Loss0.8284 | val acc 0.6458\n",
      "Epoch 6 | Iter15 | Loss0.8060 | val acc 0.5625\n",
      "Epoch 6 | Iter17 | Loss0.7045 | val acc 0.6458\n",
      "Epoch 7 | Iter1 | Loss0.8630 | val acc 0.5208\n",
      "Epoch 7 | Iter3 | Loss0.8706 | val acc 0.5625\n",
      "Epoch 7 | Iter5 | Loss0.7685 | val acc 0.5417\n",
      "Epoch 7 | Iter7 | Loss0.8901 | val acc 0.6458\n",
      "Epoch 7 | Iter9 | Loss0.7537 | val acc 0.6250\n",
      "Epoch 7 | Iter11 | Loss0.7315 | val acc 0.6250\n",
      "Epoch 7 | Iter13 | Loss0.8293 | val acc 0.5625\n",
      "Epoch 7 | Iter15 | Loss0.7350 | val acc 0.6250\n",
      "Epoch 7 | Iter17 | Loss0.8184 | val acc 0.5208\n",
      "Epoch 8 | Iter1 | Loss0.6730 | val acc 0.6042\n",
      "Epoch 8 | Iter3 | Loss0.7802 | val acc 0.5833\n",
      "Epoch 8 | Iter5 | Loss0.6067 | val acc 0.6458\n",
      "Epoch 8 | Iter7 | Loss0.7993 | val acc 0.6250\n",
      "Epoch 8 | Iter9 | Loss0.7838 | val acc 0.6042\n",
      "Epoch 8 | Iter11 | Loss0.6817 | val acc 0.5625\n",
      "Epoch 8 | Iter13 | Loss0.6008 | val acc 0.5208\n",
      "Epoch 8 | Iter15 | Loss0.5447 | val acc 0.6042\n",
      "Epoch 8 | Iter17 | Loss0.6760 | val acc 0.5625\n",
      "Epoch 9 | Iter1 | Loss0.6843 | val acc 0.6667\n",
      "Epoch 9 | Iter3 | Loss0.5392 | val acc 0.6042\n",
      "Epoch 9 | Iter5 | Loss0.9144 | val acc 0.6458\n",
      "Epoch 9 | Iter7 | Loss0.6348 | val acc 0.6042\n",
      "Epoch 9 | Iter9 | Loss0.5800 | val acc 0.5625\n",
      "Epoch 9 | Iter11 | Loss0.5682 | val acc 0.6667\n",
      "Epoch 9 | Iter13 | Loss0.7331 | val acc 0.6667\n",
      "Epoch 9 | Iter15 | Loss0.6541 | val acc 0.7083\n",
      "Epoch 9 | Iter17 | Loss0.5948 | val acc 0.6458\n",
      "Epoch 10 | Iter1 | Loss0.6685 | val acc 0.6875\n",
      "Epoch 10 | Iter3 | Loss0.5423 | val acc 0.6667\n",
      "Epoch 10 | Iter5 | Loss0.7120 | val acc 0.6667\n",
      "Epoch 10 | Iter7 | Loss0.6955 | val acc 0.6042\n",
      "Epoch 10 | Iter9 | Loss0.8329 | val acc 0.6667\n",
      "Epoch 10 | Iter11 | Loss0.6006 | val acc 0.6667\n",
      "Epoch 10 | Iter13 | Loss0.6171 | val acc 0.6667\n",
      "Epoch 10 | Iter15 | Loss0.6021 | val acc 0.7292\n",
      "Epoch 10 | Iter17 | Loss0.5922 | val acc 0.5625\n",
      "Epoch 11 | Iter1 | Loss0.5210 | val acc 0.6042\n",
      "Epoch 11 | Iter3 | Loss0.4912 | val acc 0.6250\n",
      "Epoch 11 | Iter5 | Loss0.6036 | val acc 0.6250\n",
      "Epoch 11 | Iter7 | Loss0.4106 | val acc 0.7083\n",
      "Epoch 11 | Iter9 | Loss0.5028 | val acc 0.7083\n",
      "Epoch 11 | Iter11 | Loss0.6099 | val acc 0.5833\n",
      "Epoch 11 | Iter13 | Loss0.6522 | val acc 0.5417\n",
      "Epoch 11 | Iter15 | Loss0.6815 | val acc 0.6458\n",
      "Epoch 11 | Iter17 | Loss0.4189 | val acc 0.6458\n",
      "Epoch 12 | Iter1 | Loss0.4459 | val acc 0.6458\n",
      "Epoch 12 | Iter3 | Loss0.3915 | val acc 0.6250\n",
      "Epoch 12 | Iter5 | Loss0.5478 | val acc 0.6458\n",
      "Epoch 12 | Iter7 | Loss0.5454 | val acc 0.6042\n",
      "Epoch 12 | Iter9 | Loss0.4552 | val acc 0.6250\n",
      "Epoch 12 | Iter11 | Loss0.5081 | val acc 0.6458\n",
      "Epoch 12 | Iter13 | Loss0.4664 | val acc 0.6458\n",
      "Epoch 12 | Iter15 | Loss0.4066 | val acc 0.5833\n",
      "Epoch 12 | Iter17 | Loss0.4133 | val acc 0.6250\n",
      "Epoch 13 | Iter1 | Loss0.4315 | val acc 0.6250\n",
      "Epoch 13 | Iter3 | Loss0.4852 | val acc 0.6875\n",
      "Epoch 13 | Iter5 | Loss0.5439 | val acc 0.7083\n",
      "Epoch 13 | Iter7 | Loss0.3710 | val acc 0.6875\n",
      "Epoch 13 | Iter9 | Loss0.4700 | val acc 0.6250\n",
      "Epoch 13 | Iter11 | Loss0.5859 | val acc 0.5625\n",
      "Epoch 13 | Iter13 | Loss0.3460 | val acc 0.6042\n",
      "Epoch 13 | Iter15 | Loss0.4905 | val acc 0.5833\n",
      "Epoch 13 | Iter17 | Loss0.4398 | val acc 0.6250\n",
      "Epoch 14 | Iter1 | Loss0.5634 | val acc 0.5833\n",
      "Epoch 14 | Iter3 | Loss0.4623 | val acc 0.5417\n",
      "Epoch 14 | Iter5 | Loss0.3862 | val acc 0.6042\n",
      "Epoch 14 | Iter7 | Loss0.3904 | val acc 0.6250\n",
      "Epoch 14 | Iter9 | Loss0.5073 | val acc 0.6458\n",
      "Epoch 14 | Iter11 | Loss0.5680 | val acc 0.6667\n",
      "Epoch 14 | Iter13 | Loss0.5660 | val acc 0.7292\n",
      "Epoch 14 | Iter15 | Loss0.5588 | val acc 0.6875\n",
      "Epoch 14 | Iter17 | Loss0.3724 | val acc 0.6667\n",
      "Epoch 15 | Iter1 | Loss0.4429 | val acc 0.6875\n",
      "Epoch 15 | Iter3 | Loss0.6166 | val acc 0.6250\n",
      "Epoch 15 | Iter5 | Loss0.3784 | val acc 0.6042\n",
      "Epoch 15 | Iter7 | Loss0.2879 | val acc 0.6250\n",
      "Epoch 15 | Iter9 | Loss0.3893 | val acc 0.7292\n",
      "Epoch 15 | Iter11 | Loss0.3324 | val acc 0.6042\n",
      "Epoch 15 | Iter13 | Loss0.6253 | val acc 0.6250\n",
      "Epoch 15 | Iter15 | Loss0.4252 | val acc 0.6250\n",
      "Epoch 15 | Iter17 | Loss0.4861 | val acc 0.6042\n",
      "Epoch 16 | Iter1 | Loss0.3983 | val acc 0.6250\n",
      "Epoch 16 | Iter3 | Loss0.3576 | val acc 0.6667\n",
      "Epoch 16 | Iter5 | Loss0.3784 | val acc 0.6875\n",
      "Epoch 16 | Iter7 | Loss0.3216 | val acc 0.5833\n",
      "Epoch 16 | Iter9 | Loss0.5545 | val acc 0.6458\n",
      "Epoch 16 | Iter11 | Loss0.4579 | val acc 0.5417\n",
      "Epoch 16 | Iter13 | Loss0.4764 | val acc 0.7083\n",
      "Epoch 16 | Iter15 | Loss0.4334 | val acc 0.6458\n",
      "Epoch 16 | Iter17 | Loss0.5040 | val acc 0.5625\n",
      "Epoch 17 | Iter1 | Loss0.6874 | val acc 0.6042\n",
      "Epoch 17 | Iter3 | Loss0.4358 | val acc 0.5833\n",
      "Epoch 17 | Iter5 | Loss0.2959 | val acc 0.6458\n",
      "Epoch 17 | Iter7 | Loss0.2301 | val acc 0.6667\n",
      "Epoch 17 | Iter9 | Loss0.4446 | val acc 0.6250\n",
      "Epoch 17 | Iter11 | Loss0.4447 | val acc 0.6667\n",
      "Epoch 17 | Iter13 | Loss0.3723 | val acc 0.6042\n",
      "Epoch 17 | Iter15 | Loss0.5102 | val acc 0.5625\n",
      "Epoch 17 | Iter17 | Loss0.5070 | val acc 0.5833\n",
      "Epoch 18 | Iter1 | Loss0.4876 | val acc 0.6042\n",
      "Epoch 18 | Iter3 | Loss0.3507 | val acc 0.6875\n",
      "Epoch 18 | Iter5 | Loss0.3133 | val acc 0.6875\n",
      "Epoch 18 | Iter7 | Loss0.1448 | val acc 0.6667\n",
      "Epoch 18 | Iter9 | Loss0.4914 | val acc 0.6042\n",
      "Epoch 18 | Iter11 | Loss0.3491 | val acc 0.6667\n",
      "Epoch 18 | Iter13 | Loss0.2657 | val acc 0.6458\n",
      "Epoch 18 | Iter15 | Loss0.2650 | val acc 0.6250\n",
      "Epoch 18 | Iter17 | Loss0.3152 | val acc 0.6667\n",
      "Epoch 19 | Iter1 | Loss0.3549 | val acc 0.6458\n",
      "Epoch 19 | Iter3 | Loss0.2977 | val acc 0.6875\n",
      "Epoch 19 | Iter5 | Loss0.3599 | val acc 0.7500\n",
      "Epoch 19 | Iter7 | Loss0.4599 | val acc 0.7500\n",
      "Epoch 19 | Iter9 | Loss0.2691 | val acc 0.6875\n",
      "Epoch 19 | Iter11 | Loss0.2803 | val acc 0.7500\n",
      "Epoch 19 | Iter13 | Loss0.2558 | val acc 0.6875\n",
      "Epoch 19 | Iter15 | Loss0.2739 | val acc 0.6875\n",
      "Epoch 19 | Iter17 | Loss0.2445 | val acc 0.6042\n",
      "Epoch 20 | Iter1 | Loss0.3111 | val acc 0.6250\n",
      "Epoch 20 | Iter3 | Loss0.4430 | val acc 0.5833\n",
      "Epoch 20 | Iter5 | Loss0.2851 | val acc 0.5833\n",
      "Epoch 20 | Iter7 | Loss0.1774 | val acc 0.6875\n",
      "Epoch 20 | Iter9 | Loss0.3964 | val acc 0.6667\n",
      "Epoch 20 | Iter11 | Loss0.3051 | val acc 0.6250\n",
      "Epoch 20 | Iter13 | Loss0.3256 | val acc 0.6875\n",
      "Epoch 20 | Iter15 | Loss0.3874 | val acc 0.6667\n",
      "Epoch 20 | Iter17 | Loss0.5546 | val acc 0.6458\n",
      "Epoch 21 | Iter1 | Loss0.2412 | val acc 0.6458\n",
      "Epoch 21 | Iter3 | Loss0.2768 | val acc 0.6667\n",
      "Epoch 21 | Iter5 | Loss0.2592 | val acc 0.6042\n",
      "Epoch 21 | Iter7 | Loss0.3552 | val acc 0.6458\n",
      "Epoch 21 | Iter9 | Loss0.2419 | val acc 0.6875\n",
      "Epoch 21 | Iter11 | Loss0.3351 | val acc 0.6667\n",
      "Epoch 21 | Iter13 | Loss0.2064 | val acc 0.6667\n",
      "Epoch 21 | Iter15 | Loss0.3638 | val acc 0.7500\n",
      "Epoch 21 | Iter17 | Loss0.2995 | val acc 0.6667\n",
      "Epoch 22 | Iter1 | Loss0.3746 | val acc 0.6875\n",
      "Epoch 22 | Iter3 | Loss0.2710 | val acc 0.6875\n",
      "Epoch 22 | Iter5 | Loss0.5615 | val acc 0.7500\n",
      "Epoch 22 | Iter7 | Loss0.3948 | val acc 0.7500\n",
      "Epoch 22 | Iter9 | Loss0.1657 | val acc 0.6875\n",
      "Epoch 22 | Iter11 | Loss0.3886 | val acc 0.7292\n",
      "Epoch 22 | Iter13 | Loss0.3054 | val acc 0.7083\n",
      "Epoch 22 | Iter15 | Loss0.3493 | val acc 0.6042\n",
      "Epoch 22 | Iter17 | Loss0.3787 | val acc 0.6458\n",
      "Epoch 23 | Iter1 | Loss0.2276 | val acc 0.7083\n",
      "Epoch 23 | Iter3 | Loss0.4390 | val acc 0.7083\n",
      "Epoch 23 | Iter5 | Loss0.4038 | val acc 0.6458\n",
      "Epoch 23 | Iter7 | Loss0.3562 | val acc 0.6458\n",
      "Epoch 23 | Iter9 | Loss0.3168 | val acc 0.6458\n",
      "Epoch 23 | Iter11 | Loss0.2298 | val acc 0.6875\n",
      "Epoch 23 | Iter13 | Loss0.4034 | val acc 0.6250\n",
      "Epoch 23 | Iter15 | Loss0.3651 | val acc 0.6250\n",
      "Epoch 23 | Iter17 | Loss0.2297 | val acc 0.6458\n",
      "Epoch 24 | Iter1 | Loss0.2267 | val acc 0.6667\n",
      "Epoch 24 | Iter3 | Loss0.3271 | val acc 0.7292\n",
      "Epoch 24 | Iter5 | Loss0.2310 | val acc 0.7083\n",
      "Epoch 24 | Iter7 | Loss0.4474 | val acc 0.6667\n",
      "Epoch 24 | Iter9 | Loss0.3246 | val acc 0.6667\n",
      "Epoch 24 | Iter11 | Loss0.2061 | val acc 0.7083\n",
      "Epoch 24 | Iter13 | Loss0.4236 | val acc 0.7500\n",
      "Epoch 24 | Iter15 | Loss0.1751 | val acc 0.7292\n",
      "Epoch 24 | Iter17 | Loss0.2229 | val acc 0.7708\n",
      "Epoch 25 | Iter1 | Loss0.2620 | val acc 0.7708\n",
      "Epoch 25 | Iter3 | Loss0.3120 | val acc 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Iter5 | Loss0.2435 | val acc 0.7083\n",
      "Epoch 25 | Iter7 | Loss0.2404 | val acc 0.6667\n",
      "Epoch 25 | Iter9 | Loss0.3568 | val acc 0.7083\n",
      "Epoch 25 | Iter11 | Loss0.3816 | val acc 0.7083\n",
      "Epoch 25 | Iter13 | Loss0.1300 | val acc 0.7083\n",
      "Epoch 25 | Iter15 | Loss0.3541 | val acc 0.7083\n",
      "Epoch 25 | Iter17 | Loss0.2139 | val acc 0.6875\n",
      "--------------------------------------------------\n",
      "Training Net 4\n",
      "Epoch 0 | Iter1 | Loss1.5047 | val acc 0.3750\n",
      "Epoch 0 | Iter3 | Loss1.4869 | val acc 0.3750\n",
      "Epoch 0 | Iter5 | Loss1.5971 | val acc 0.4375\n",
      "Epoch 0 | Iter7 | Loss1.7690 | val acc 0.3750\n",
      "Epoch 0 | Iter9 | Loss1.5654 | val acc 0.4792\n",
      "Epoch 0 | Iter11 | Loss1.3856 | val acc 0.4375\n",
      "Epoch 0 | Iter13 | Loss1.3477 | val acc 0.3542\n",
      "Epoch 0 | Iter15 | Loss1.5447 | val acc 0.4167\n",
      "Epoch 0 | Iter17 | Loss1.3452 | val acc 0.3958\n",
      "Epoch 1 | Iter1 | Loss1.3476 | val acc 0.3958\n",
      "Epoch 1 | Iter3 | Loss1.2933 | val acc 0.5000\n",
      "Epoch 1 | Iter5 | Loss1.3011 | val acc 0.4792\n",
      "Epoch 1 | Iter7 | Loss1.3818 | val acc 0.4583\n",
      "Epoch 1 | Iter9 | Loss1.1480 | val acc 0.4792\n",
      "Epoch 1 | Iter11 | Loss1.4132 | val acc 0.4375\n",
      "Epoch 1 | Iter13 | Loss1.2776 | val acc 0.3958\n",
      "Epoch 1 | Iter15 | Loss1.3972 | val acc 0.3958\n",
      "Epoch 1 | Iter17 | Loss1.3880 | val acc 0.3750\n",
      "Epoch 2 | Iter1 | Loss1.3901 | val acc 0.4375\n",
      "Epoch 2 | Iter3 | Loss1.2680 | val acc 0.5000\n",
      "Epoch 2 | Iter5 | Loss1.1405 | val acc 0.5000\n",
      "Epoch 2 | Iter7 | Loss1.2544 | val acc 0.4583\n",
      "Epoch 2 | Iter9 | Loss1.2640 | val acc 0.4167\n",
      "Epoch 2 | Iter11 | Loss1.2645 | val acc 0.4583\n",
      "Epoch 2 | Iter13 | Loss1.2784 | val acc 0.4167\n",
      "Epoch 2 | Iter15 | Loss1.2910 | val acc 0.3958\n",
      "Epoch 2 | Iter17 | Loss1.2016 | val acc 0.4167\n",
      "Epoch 3 | Iter1 | Loss1.1341 | val acc 0.3958\n",
      "Epoch 3 | Iter3 | Loss1.1546 | val acc 0.3750\n",
      "Epoch 3 | Iter5 | Loss1.2645 | val acc 0.3958\n",
      "Epoch 3 | Iter7 | Loss1.1851 | val acc 0.5000\n",
      "Epoch 3 | Iter9 | Loss1.1877 | val acc 0.5000\n",
      "Epoch 3 | Iter11 | Loss1.0179 | val acc 0.4792\n",
      "Epoch 3 | Iter13 | Loss1.0800 | val acc 0.4375\n",
      "Epoch 3 | Iter15 | Loss1.1462 | val acc 0.3958\n",
      "Epoch 3 | Iter17 | Loss1.0322 | val acc 0.5000\n",
      "Epoch 4 | Iter1 | Loss1.0607 | val acc 0.4583\n",
      "Epoch 4 | Iter3 | Loss1.0678 | val acc 0.4583\n",
      "Epoch 4 | Iter5 | Loss1.0012 | val acc 0.4167\n",
      "Epoch 4 | Iter7 | Loss1.0216 | val acc 0.3958\n",
      "Epoch 4 | Iter9 | Loss0.9905 | val acc 0.3958\n",
      "Epoch 4 | Iter11 | Loss1.0592 | val acc 0.3750\n",
      "Epoch 4 | Iter13 | Loss0.9319 | val acc 0.3750\n",
      "Epoch 4 | Iter15 | Loss0.8220 | val acc 0.4167\n",
      "Epoch 4 | Iter17 | Loss1.0935 | val acc 0.3542\n",
      "Epoch 5 | Iter1 | Loss0.9534 | val acc 0.3125\n",
      "Epoch 5 | Iter3 | Loss0.9853 | val acc 0.3333\n",
      "Epoch 5 | Iter5 | Loss0.9676 | val acc 0.3750\n",
      "Epoch 5 | Iter7 | Loss1.0072 | val acc 0.3542\n",
      "Epoch 5 | Iter9 | Loss0.9879 | val acc 0.3750\n",
      "Epoch 5 | Iter11 | Loss1.1008 | val acc 0.3333\n",
      "Epoch 5 | Iter13 | Loss0.9691 | val acc 0.3125\n",
      "Epoch 5 | Iter15 | Loss0.9754 | val acc 0.3750\n",
      "Epoch 5 | Iter17 | Loss1.0066 | val acc 0.5417\n",
      "Epoch 6 | Iter1 | Loss0.9798 | val acc 0.4167\n",
      "Epoch 6 | Iter3 | Loss0.8543 | val acc 0.3750\n",
      "Epoch 6 | Iter5 | Loss1.0795 | val acc 0.2708\n",
      "Epoch 6 | Iter7 | Loss0.8454 | val acc 0.3542\n",
      "Epoch 6 | Iter9 | Loss0.9482 | val acc 0.3542\n",
      "Epoch 6 | Iter11 | Loss0.9159 | val acc 0.3542\n",
      "Epoch 6 | Iter13 | Loss0.9116 | val acc 0.4583\n",
      "Epoch 6 | Iter15 | Loss0.9484 | val acc 0.4583\n",
      "Epoch 6 | Iter17 | Loss0.9730 | val acc 0.4375\n",
      "Epoch 7 | Iter1 | Loss0.8438 | val acc 0.3958\n",
      "Epoch 7 | Iter3 | Loss0.7612 | val acc 0.3958\n",
      "Epoch 7 | Iter5 | Loss0.7900 | val acc 0.4375\n",
      "Epoch 7 | Iter7 | Loss0.9177 | val acc 0.5000\n",
      "Epoch 7 | Iter9 | Loss0.7022 | val acc 0.5000\n",
      "Epoch 7 | Iter11 | Loss0.8424 | val acc 0.4583\n",
      "Epoch 7 | Iter13 | Loss0.8261 | val acc 0.4167\n",
      "Epoch 7 | Iter15 | Loss0.8509 | val acc 0.5000\n",
      "Epoch 7 | Iter17 | Loss0.8509 | val acc 0.4792\n",
      "Epoch 8 | Iter1 | Loss0.7938 | val acc 0.4583\n",
      "Epoch 8 | Iter3 | Loss0.7893 | val acc 0.4583\n",
      "Epoch 8 | Iter5 | Loss0.7245 | val acc 0.4167\n",
      "Epoch 8 | Iter7 | Loss0.7922 | val acc 0.4375\n",
      "Epoch 8 | Iter9 | Loss0.6702 | val acc 0.3750\n",
      "Epoch 8 | Iter11 | Loss0.6836 | val acc 0.4375\n",
      "Epoch 8 | Iter13 | Loss0.9249 | val acc 0.4792\n",
      "Epoch 8 | Iter15 | Loss0.8844 | val acc 0.4792\n",
      "Epoch 8 | Iter17 | Loss0.7327 | val acc 0.3958\n",
      "Epoch 9 | Iter1 | Loss0.6654 | val acc 0.4583\n",
      "Epoch 9 | Iter3 | Loss0.7244 | val acc 0.4375\n",
      "Epoch 9 | Iter5 | Loss0.7363 | val acc 0.4583\n",
      "Epoch 9 | Iter7 | Loss0.6135 | val acc 0.4583\n",
      "Epoch 9 | Iter9 | Loss0.6422 | val acc 0.5417\n",
      "Epoch 9 | Iter11 | Loss0.7036 | val acc 0.4167\n",
      "Epoch 9 | Iter13 | Loss0.6174 | val acc 0.3958\n",
      "Epoch 9 | Iter15 | Loss0.7440 | val acc 0.4375\n",
      "Epoch 9 | Iter17 | Loss0.6106 | val acc 0.4792\n",
      "Epoch 10 | Iter1 | Loss0.6267 | val acc 0.4167\n",
      "Epoch 10 | Iter3 | Loss0.6004 | val acc 0.4792\n",
      "Epoch 10 | Iter5 | Loss0.5553 | val acc 0.5000\n",
      "Epoch 10 | Iter7 | Loss0.6638 | val acc 0.5000\n",
      "Epoch 10 | Iter9 | Loss0.5718 | val acc 0.5000\n",
      "Epoch 10 | Iter11 | Loss0.6206 | val acc 0.5417\n",
      "Epoch 10 | Iter13 | Loss0.5701 | val acc 0.4792\n",
      "Epoch 10 | Iter15 | Loss0.8044 | val acc 0.4583\n",
      "Epoch 10 | Iter17 | Loss0.6928 | val acc 0.4167\n",
      "Epoch 11 | Iter1 | Loss0.5542 | val acc 0.5833\n",
      "Epoch 11 | Iter3 | Loss0.5584 | val acc 0.4583\n",
      "Epoch 11 | Iter5 | Loss0.6661 | val acc 0.5000\n",
      "Epoch 11 | Iter7 | Loss0.6060 | val acc 0.5000\n",
      "Epoch 11 | Iter9 | Loss0.5381 | val acc 0.4792\n",
      "Epoch 11 | Iter11 | Loss0.5193 | val acc 0.5625\n",
      "Epoch 11 | Iter13 | Loss0.5385 | val acc 0.5417\n",
      "Epoch 11 | Iter15 | Loss0.5720 | val acc 0.4583\n",
      "Epoch 11 | Iter17 | Loss0.4983 | val acc 0.4583\n",
      "Epoch 12 | Iter1 | Loss0.5229 | val acc 0.5208\n",
      "Epoch 12 | Iter3 | Loss0.5578 | val acc 0.4583\n",
      "Epoch 12 | Iter5 | Loss0.5255 | val acc 0.5000\n",
      "Epoch 12 | Iter7 | Loss0.4761 | val acc 0.4792\n",
      "Epoch 12 | Iter9 | Loss0.4657 | val acc 0.5208\n",
      "Epoch 12 | Iter11 | Loss0.5227 | val acc 0.4583\n",
      "Epoch 12 | Iter13 | Loss0.4687 | val acc 0.5417\n",
      "Epoch 12 | Iter15 | Loss0.4378 | val acc 0.5208\n",
      "Epoch 12 | Iter17 | Loss0.5245 | val acc 0.3958\n",
      "Epoch 13 | Iter1 | Loss0.5013 | val acc 0.4583\n",
      "Epoch 13 | Iter3 | Loss0.4331 | val acc 0.4167\n",
      "Epoch 13 | Iter5 | Loss0.4690 | val acc 0.3958\n",
      "Epoch 13 | Iter7 | Loss0.5123 | val acc 0.4167\n",
      "Epoch 13 | Iter9 | Loss0.4502 | val acc 0.4792\n",
      "Epoch 13 | Iter11 | Loss0.5335 | val acc 0.4792\n",
      "Epoch 13 | Iter13 | Loss0.4571 | val acc 0.5208\n",
      "Epoch 13 | Iter15 | Loss0.5814 | val acc 0.5208\n",
      "Epoch 13 | Iter17 | Loss0.5281 | val acc 0.5625\n",
      "Epoch 14 | Iter1 | Loss0.3934 | val acc 0.5417\n",
      "Epoch 14 | Iter3 | Loss0.3502 | val acc 0.5000\n",
      "Epoch 14 | Iter5 | Loss0.4680 | val acc 0.5417\n",
      "Epoch 14 | Iter7 | Loss0.6150 | val acc 0.4792\n",
      "Epoch 14 | Iter9 | Loss0.5261 | val acc 0.4583\n",
      "Epoch 14 | Iter11 | Loss0.4163 | val acc 0.5000\n",
      "Epoch 14 | Iter13 | Loss0.5027 | val acc 0.4583\n",
      "Epoch 14 | Iter15 | Loss0.3871 | val acc 0.5417\n",
      "Epoch 14 | Iter17 | Loss0.8377 | val acc 0.4375\n",
      "Epoch 15 | Iter1 | Loss0.5205 | val acc 0.5000\n",
      "Epoch 15 | Iter3 | Loss0.5159 | val acc 0.3958\n",
      "Epoch 15 | Iter5 | Loss0.5134 | val acc 0.4167\n",
      "Epoch 15 | Iter7 | Loss0.5972 | val acc 0.5208\n",
      "Epoch 15 | Iter9 | Loss0.3361 | val acc 0.6042\n",
      "Epoch 15 | Iter11 | Loss0.3984 | val acc 0.6250\n",
      "Epoch 15 | Iter13 | Loss0.2617 | val acc 0.5625\n",
      "Epoch 15 | Iter15 | Loss0.4934 | val acc 0.5625\n",
      "Epoch 15 | Iter17 | Loss0.5636 | val acc 0.5625\n",
      "Epoch 16 | Iter1 | Loss0.2624 | val acc 0.5625\n",
      "Epoch 16 | Iter3 | Loss0.3933 | val acc 0.5833\n",
      "Epoch 16 | Iter5 | Loss0.3557 | val acc 0.5833\n",
      "Epoch 16 | Iter7 | Loss0.5844 | val acc 0.5417\n",
      "Epoch 16 | Iter9 | Loss0.6137 | val acc 0.5208\n",
      "Epoch 16 | Iter11 | Loss0.3980 | val acc 0.5417\n",
      "Epoch 16 | Iter13 | Loss0.7597 | val acc 0.4375\n",
      "Epoch 16 | Iter15 | Loss0.3858 | val acc 0.4792\n",
      "Epoch 16 | Iter17 | Loss0.5052 | val acc 0.5000\n",
      "Epoch 17 | Iter1 | Loss0.3124 | val acc 0.5833\n",
      "Epoch 17 | Iter3 | Loss0.3733 | val acc 0.5417\n",
      "Epoch 17 | Iter5 | Loss0.4326 | val acc 0.5417\n",
      "Epoch 17 | Iter7 | Loss0.3576 | val acc 0.5208\n",
      "Epoch 17 | Iter9 | Loss0.4071 | val acc 0.4792\n",
      "Epoch 17 | Iter11 | Loss0.4156 | val acc 0.4792\n",
      "Epoch 17 | Iter13 | Loss0.4999 | val acc 0.5417\n",
      "Epoch 17 | Iter15 | Loss0.5962 | val acc 0.4792\n",
      "Epoch 17 | Iter17 | Loss0.6422 | val acc 0.5000\n",
      "Epoch 18 | Iter1 | Loss0.4473 | val acc 0.5000\n",
      "Epoch 18 | Iter3 | Loss0.3431 | val acc 0.5417\n",
      "Epoch 18 | Iter5 | Loss0.4204 | val acc 0.5000\n",
      "Epoch 18 | Iter7 | Loss0.4448 | val acc 0.5208\n",
      "Epoch 18 | Iter9 | Loss0.3865 | val acc 0.5208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Iter11 | Loss0.2201 | val acc 0.5208\n",
      "Epoch 18 | Iter13 | Loss0.4066 | val acc 0.5000\n",
      "Epoch 18 | Iter15 | Loss0.3420 | val acc 0.5417\n",
      "Epoch 18 | Iter17 | Loss0.3734 | val acc 0.5625\n",
      "Epoch 19 | Iter1 | Loss0.4022 | val acc 0.6042\n",
      "Epoch 19 | Iter3 | Loss0.4402 | val acc 0.5833\n",
      "Epoch 19 | Iter5 | Loss0.3533 | val acc 0.6042\n",
      "Epoch 19 | Iter7 | Loss0.5149 | val acc 0.5833\n",
      "Epoch 19 | Iter9 | Loss0.2796 | val acc 0.5208\n",
      "Epoch 19 | Iter11 | Loss0.2680 | val acc 0.5417\n",
      "Epoch 19 | Iter13 | Loss0.2818 | val acc 0.5000\n",
      "Epoch 19 | Iter15 | Loss0.2686 | val acc 0.5208\n",
      "Epoch 19 | Iter17 | Loss0.3938 | val acc 0.5625\n",
      "Epoch 20 | Iter1 | Loss0.3304 | val acc 0.5000\n",
      "Epoch 20 | Iter3 | Loss0.3059 | val acc 0.5417\n",
      "Epoch 20 | Iter5 | Loss0.2338 | val acc 0.5208\n",
      "Epoch 20 | Iter7 | Loss0.4147 | val acc 0.5625\n",
      "Epoch 20 | Iter9 | Loss0.2867 | val acc 0.6042\n",
      "Epoch 20 | Iter11 | Loss0.2601 | val acc 0.5625\n",
      "Epoch 20 | Iter13 | Loss0.5061 | val acc 0.6042\n",
      "Epoch 20 | Iter15 | Loss0.2884 | val acc 0.5833\n",
      "Epoch 20 | Iter17 | Loss0.2942 | val acc 0.6042\n",
      "Epoch 21 | Iter1 | Loss0.4875 | val acc 0.5625\n",
      "Epoch 21 | Iter3 | Loss0.3470 | val acc 0.6458\n",
      "Epoch 21 | Iter5 | Loss0.3790 | val acc 0.6250\n",
      "Epoch 21 | Iter7 | Loss0.2313 | val acc 0.5833\n",
      "Epoch 21 | Iter9 | Loss0.2298 | val acc 0.6250\n",
      "Epoch 21 | Iter11 | Loss0.2960 | val acc 0.5625\n",
      "Epoch 21 | Iter13 | Loss0.3080 | val acc 0.5833\n",
      "Epoch 21 | Iter15 | Loss0.4053 | val acc 0.5833\n",
      "Epoch 21 | Iter17 | Loss0.3368 | val acc 0.6250\n",
      "Epoch 22 | Iter1 | Loss0.2312 | val acc 0.5833\n",
      "Epoch 22 | Iter3 | Loss0.2484 | val acc 0.6042\n",
      "Epoch 22 | Iter5 | Loss0.6092 | val acc 0.5625\n",
      "Epoch 22 | Iter7 | Loss0.3727 | val acc 0.5417\n",
      "Epoch 22 | Iter9 | Loss0.2905 | val acc 0.5417\n",
      "Epoch 22 | Iter11 | Loss0.3561 | val acc 0.5417\n",
      "Epoch 22 | Iter13 | Loss0.2933 | val acc 0.5417\n",
      "Epoch 22 | Iter15 | Loss0.1500 | val acc 0.5417\n",
      "Epoch 22 | Iter17 | Loss0.4599 | val acc 0.5208\n",
      "Epoch 23 | Iter1 | Loss0.4519 | val acc 0.5208\n",
      "Epoch 23 | Iter3 | Loss0.3282 | val acc 0.5417\n",
      "Epoch 23 | Iter5 | Loss0.2936 | val acc 0.5417\n",
      "Epoch 23 | Iter7 | Loss0.4534 | val acc 0.5417\n",
      "Epoch 23 | Iter9 | Loss0.2971 | val acc 0.5208\n",
      "Epoch 23 | Iter11 | Loss0.4028 | val acc 0.5625\n",
      "Epoch 23 | Iter13 | Loss0.3507 | val acc 0.5417\n",
      "Epoch 23 | Iter15 | Loss0.3139 | val acc 0.5833\n",
      "Epoch 23 | Iter17 | Loss0.3550 | val acc 0.5417\n",
      "Epoch 24 | Iter1 | Loss0.3157 | val acc 0.5208\n",
      "Epoch 24 | Iter3 | Loss0.2521 | val acc 0.5208\n",
      "Epoch 24 | Iter5 | Loss0.3872 | val acc 0.4792\n",
      "Epoch 24 | Iter7 | Loss0.3214 | val acc 0.4583\n",
      "Epoch 24 | Iter9 | Loss0.3086 | val acc 0.4792\n",
      "Epoch 24 | Iter11 | Loss0.3446 | val acc 0.4792\n",
      "Epoch 24 | Iter13 | Loss0.3176 | val acc 0.5417\n",
      "Epoch 24 | Iter15 | Loss0.2501 | val acc 0.4792\n",
      "Epoch 24 | Iter17 | Loss0.1696 | val acc 0.5417\n",
      "Epoch 25 | Iter1 | Loss0.1890 | val acc 0.4792\n",
      "Epoch 25 | Iter3 | Loss0.2872 | val acc 0.4792\n",
      "Epoch 25 | Iter5 | Loss0.3886 | val acc 0.5000\n",
      "Epoch 25 | Iter7 | Loss0.3371 | val acc 0.5000\n",
      "Epoch 25 | Iter9 | Loss0.2336 | val acc 0.5417\n",
      "Epoch 25 | Iter11 | Loss0.3166 | val acc 0.5833\n",
      "Epoch 25 | Iter13 | Loss0.3172 | val acc 0.6250\n",
      "Epoch 25 | Iter15 | Loss0.2198 | val acc 0.5417\n",
      "Epoch 25 | Iter17 | Loss0.3322 | val acc 0.5625\n",
      "--------------------------------------------------\n",
      "Training Net 5\n",
      "Epoch 0 | Iter1 | Loss1.6803 | val acc 0.3750\n",
      "Epoch 0 | Iter3 | Loss1.6789 | val acc 0.3750\n",
      "Epoch 0 | Iter5 | Loss1.4618 | val acc 0.3750\n",
      "Epoch 0 | Iter7 | Loss1.5594 | val acc 0.3750\n",
      "Epoch 0 | Iter9 | Loss1.4955 | val acc 0.3750\n",
      "Epoch 0 | Iter11 | Loss1.4616 | val acc 0.3542\n",
      "Epoch 0 | Iter13 | Loss1.5755 | val acc 0.3958\n",
      "Epoch 0 | Iter15 | Loss1.4105 | val acc 0.3333\n",
      "Epoch 0 | Iter17 | Loss1.6701 | val acc 0.3125\n",
      "Epoch 1 | Iter1 | Loss1.4876 | val acc 0.2292\n",
      "Epoch 1 | Iter3 | Loss1.3786 | val acc 0.2708\n",
      "Epoch 1 | Iter5 | Loss1.3913 | val acc 0.2917\n",
      "Epoch 1 | Iter7 | Loss1.4100 | val acc 0.3333\n",
      "Epoch 1 | Iter9 | Loss1.2674 | val acc 0.3333\n",
      "Epoch 1 | Iter11 | Loss1.2600 | val acc 0.3333\n",
      "Epoch 1 | Iter13 | Loss1.1938 | val acc 0.3333\n",
      "Epoch 1 | Iter15 | Loss1.3599 | val acc 0.2917\n",
      "Epoch 1 | Iter17 | Loss1.1434 | val acc 0.3333\n",
      "Epoch 2 | Iter1 | Loss1.2754 | val acc 0.3542\n",
      "Epoch 2 | Iter3 | Loss1.2976 | val acc 0.3542\n",
      "Epoch 2 | Iter5 | Loss1.3675 | val acc 0.3958\n",
      "Epoch 2 | Iter7 | Loss1.3177 | val acc 0.4375\n",
      "Epoch 2 | Iter9 | Loss1.1589 | val acc 0.4375\n",
      "Epoch 2 | Iter11 | Loss1.2756 | val acc 0.3542\n",
      "Epoch 2 | Iter13 | Loss1.3748 | val acc 0.4167\n",
      "Epoch 2 | Iter15 | Loss1.2717 | val acc 0.4167\n",
      "Epoch 2 | Iter17 | Loss1.0945 | val acc 0.4375\n",
      "Epoch 3 | Iter1 | Loss1.2334 | val acc 0.3750\n",
      "Epoch 3 | Iter3 | Loss1.1742 | val acc 0.3333\n",
      "Epoch 3 | Iter5 | Loss1.2032 | val acc 0.4167\n",
      "Epoch 3 | Iter7 | Loss1.3222 | val acc 0.4167\n",
      "Epoch 3 | Iter9 | Loss1.1193 | val acc 0.4375\n",
      "Epoch 3 | Iter11 | Loss1.1389 | val acc 0.4583\n",
      "Epoch 3 | Iter13 | Loss1.1265 | val acc 0.3958\n",
      "Epoch 3 | Iter15 | Loss1.2148 | val acc 0.3958\n",
      "Epoch 3 | Iter17 | Loss1.2367 | val acc 0.3542\n",
      "Epoch 4 | Iter1 | Loss1.1334 | val acc 0.4375\n",
      "Epoch 4 | Iter3 | Loss1.1224 | val acc 0.4167\n",
      "Epoch 4 | Iter5 | Loss0.9879 | val acc 0.4167\n",
      "Epoch 4 | Iter7 | Loss1.0616 | val acc 0.4167\n",
      "Epoch 4 | Iter9 | Loss0.9619 | val acc 0.4375\n",
      "Epoch 4 | Iter11 | Loss1.0327 | val acc 0.3750\n",
      "Epoch 4 | Iter13 | Loss1.0415 | val acc 0.3750\n",
      "Epoch 4 | Iter15 | Loss0.8759 | val acc 0.3958\n",
      "Epoch 4 | Iter17 | Loss1.0783 | val acc 0.4167\n",
      "Epoch 5 | Iter1 | Loss1.0678 | val acc 0.3750\n",
      "Epoch 5 | Iter3 | Loss0.9372 | val acc 0.3333\n",
      "Epoch 5 | Iter5 | Loss1.1516 | val acc 0.3542\n",
      "Epoch 5 | Iter7 | Loss0.8589 | val acc 0.3333\n",
      "Epoch 5 | Iter9 | Loss1.0867 | val acc 0.4167\n",
      "Epoch 5 | Iter11 | Loss1.0103 | val acc 0.4375\n",
      "Epoch 5 | Iter13 | Loss1.0319 | val acc 0.3542\n",
      "Epoch 5 | Iter15 | Loss0.8639 | val acc 0.3542\n",
      "Epoch 5 | Iter17 | Loss1.0666 | val acc 0.3333\n",
      "Epoch 6 | Iter1 | Loss0.9353 | val acc 0.4792\n",
      "Epoch 6 | Iter3 | Loss0.8461 | val acc 0.4792\n",
      "Epoch 6 | Iter5 | Loss0.9763 | val acc 0.4375\n",
      "Epoch 6 | Iter7 | Loss0.9993 | val acc 0.4167\n",
      "Epoch 6 | Iter9 | Loss0.9962 | val acc 0.4375\n",
      "Epoch 6 | Iter11 | Loss0.8937 | val acc 0.4583\n",
      "Epoch 6 | Iter13 | Loss1.0041 | val acc 0.5000\n",
      "Epoch 6 | Iter15 | Loss0.8083 | val acc 0.4583\n",
      "Epoch 6 | Iter17 | Loss1.0175 | val acc 0.4583\n",
      "Epoch 7 | Iter1 | Loss0.7389 | val acc 0.4375\n",
      "Epoch 7 | Iter3 | Loss0.8939 | val acc 0.3958\n",
      "Epoch 7 | Iter5 | Loss0.7128 | val acc 0.4375\n",
      "Epoch 7 | Iter7 | Loss1.0049 | val acc 0.3750\n",
      "Epoch 7 | Iter9 | Loss0.9377 | val acc 0.4375\n",
      "Epoch 7 | Iter11 | Loss0.6396 | val acc 0.3750\n",
      "Epoch 7 | Iter13 | Loss0.7520 | val acc 0.4375\n",
      "Epoch 7 | Iter15 | Loss0.8450 | val acc 0.4375\n",
      "Epoch 7 | Iter17 | Loss0.7844 | val acc 0.4167\n",
      "Epoch 8 | Iter1 | Loss0.7433 | val acc 0.3750\n",
      "Epoch 8 | Iter3 | Loss0.8599 | val acc 0.3542\n",
      "Epoch 8 | Iter5 | Loss0.6716 | val acc 0.4583\n",
      "Epoch 8 | Iter7 | Loss0.7054 | val acc 0.3750\n",
      "Epoch 8 | Iter9 | Loss0.7467 | val acc 0.4583\n",
      "Epoch 8 | Iter11 | Loss0.6813 | val acc 0.4792\n",
      "Epoch 8 | Iter13 | Loss0.7680 | val acc 0.4583\n",
      "Epoch 8 | Iter15 | Loss0.9844 | val acc 0.4167\n",
      "Epoch 8 | Iter17 | Loss0.7987 | val acc 0.3958\n",
      "Epoch 9 | Iter1 | Loss0.7125 | val acc 0.3125\n",
      "Epoch 9 | Iter3 | Loss0.7173 | val acc 0.4167\n",
      "Epoch 9 | Iter5 | Loss0.6819 | val acc 0.3958\n",
      "Epoch 9 | Iter7 | Loss0.8072 | val acc 0.3958\n",
      "Epoch 9 | Iter9 | Loss0.7657 | val acc 0.3958\n",
      "Epoch 9 | Iter11 | Loss0.7284 | val acc 0.4375\n",
      "Epoch 9 | Iter13 | Loss0.8198 | val acc 0.4375\n",
      "Epoch 9 | Iter15 | Loss0.6728 | val acc 0.5417\n",
      "Epoch 9 | Iter17 | Loss0.7156 | val acc 0.4792\n",
      "Epoch 10 | Iter1 | Loss0.5845 | val acc 0.4583\n",
      "Epoch 10 | Iter3 | Loss0.7824 | val acc 0.4375\n",
      "Epoch 10 | Iter5 | Loss0.7072 | val acc 0.4792\n",
      "Epoch 10 | Iter7 | Loss0.6794 | val acc 0.4375\n",
      "Epoch 10 | Iter9 | Loss0.5537 | val acc 0.4167\n",
      "Epoch 10 | Iter11 | Loss0.5189 | val acc 0.4583\n",
      "Epoch 10 | Iter13 | Loss0.7846 | val acc 0.4583\n",
      "Epoch 10 | Iter15 | Loss0.6350 | val acc 0.4375\n",
      "Epoch 10 | Iter17 | Loss0.6169 | val acc 0.4583\n",
      "Epoch 11 | Iter1 | Loss0.5901 | val acc 0.4792\n",
      "Epoch 11 | Iter3 | Loss0.8172 | val acc 0.4583\n",
      "Epoch 11 | Iter5 | Loss0.4219 | val acc 0.4583\n",
      "Epoch 11 | Iter7 | Loss0.5625 | val acc 0.4583\n",
      "Epoch 11 | Iter9 | Loss0.5591 | val acc 0.3958\n",
      "Epoch 11 | Iter11 | Loss0.5964 | val acc 0.4167\n",
      "Epoch 11 | Iter13 | Loss0.6461 | val acc 0.4792\n",
      "Epoch 11 | Iter15 | Loss0.5525 | val acc 0.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Iter17 | Loss0.7050 | val acc 0.3750\n",
      "Epoch 12 | Iter1 | Loss0.5055 | val acc 0.4167\n",
      "Epoch 12 | Iter3 | Loss0.5461 | val acc 0.4583\n",
      "Epoch 12 | Iter5 | Loss0.4895 | val acc 0.4167\n",
      "Epoch 12 | Iter7 | Loss0.6098 | val acc 0.4583\n",
      "Epoch 12 | Iter9 | Loss0.3814 | val acc 0.3958\n",
      "Epoch 12 | Iter11 | Loss0.6205 | val acc 0.4583\n",
      "Epoch 12 | Iter13 | Loss0.6246 | val acc 0.4375\n",
      "Epoch 12 | Iter15 | Loss0.4480 | val acc 0.4792\n",
      "Epoch 12 | Iter17 | Loss0.6936 | val acc 0.4792\n",
      "Epoch 13 | Iter1 | Loss0.6266 | val acc 0.4375\n",
      "Epoch 13 | Iter3 | Loss0.4834 | val acc 0.4583\n",
      "Epoch 13 | Iter5 | Loss0.5362 | val acc 0.5000\n",
      "Epoch 13 | Iter7 | Loss0.7015 | val acc 0.5000\n",
      "Epoch 13 | Iter9 | Loss0.4645 | val acc 0.4167\n",
      "Epoch 13 | Iter11 | Loss0.5601 | val acc 0.3750\n",
      "Epoch 13 | Iter13 | Loss0.4707 | val acc 0.4792\n",
      "Epoch 13 | Iter15 | Loss0.4133 | val acc 0.4167\n",
      "Epoch 13 | Iter17 | Loss0.5999 | val acc 0.4792\n",
      "Epoch 14 | Iter1 | Loss0.4800 | val acc 0.5000\n",
      "Epoch 14 | Iter3 | Loss0.4589 | val acc 0.5000\n",
      "Epoch 14 | Iter5 | Loss0.5442 | val acc 0.5208\n",
      "Epoch 14 | Iter7 | Loss0.3875 | val acc 0.5208\n",
      "Epoch 14 | Iter9 | Loss0.6925 | val acc 0.4583\n",
      "Epoch 14 | Iter11 | Loss0.6024 | val acc 0.5208\n",
      "Epoch 14 | Iter13 | Loss0.3811 | val acc 0.5417\n",
      "Epoch 14 | Iter15 | Loss0.5356 | val acc 0.5208\n",
      "Epoch 14 | Iter17 | Loss0.4494 | val acc 0.5208\n",
      "Epoch 15 | Iter1 | Loss0.4078 | val acc 0.4583\n",
      "Epoch 15 | Iter3 | Loss0.5877 | val acc 0.4583\n",
      "Epoch 15 | Iter5 | Loss0.6194 | val acc 0.4375\n",
      "Epoch 15 | Iter7 | Loss0.4202 | val acc 0.4375\n",
      "Epoch 15 | Iter9 | Loss0.4017 | val acc 0.4375\n",
      "Epoch 15 | Iter11 | Loss0.2876 | val acc 0.4792\n",
      "Epoch 15 | Iter13 | Loss0.4763 | val acc 0.3542\n",
      "Epoch 15 | Iter15 | Loss0.4028 | val acc 0.3958\n",
      "Epoch 15 | Iter17 | Loss0.3033 | val acc 0.4583\n",
      "Epoch 16 | Iter1 | Loss0.4254 | val acc 0.4167\n",
      "Epoch 16 | Iter3 | Loss0.3466 | val acc 0.4375\n",
      "Epoch 16 | Iter5 | Loss0.3942 | val acc 0.3958\n",
      "Epoch 16 | Iter7 | Loss0.4625 | val acc 0.5417\n",
      "Epoch 16 | Iter9 | Loss0.3718 | val acc 0.5417\n",
      "Epoch 16 | Iter11 | Loss0.3914 | val acc 0.5000\n",
      "Epoch 16 | Iter13 | Loss0.3404 | val acc 0.5000\n",
      "Epoch 16 | Iter15 | Loss0.2856 | val acc 0.5417\n",
      "Epoch 16 | Iter17 | Loss0.4676 | val acc 0.5000\n",
      "Epoch 17 | Iter1 | Loss0.3315 | val acc 0.5000\n",
      "Epoch 17 | Iter3 | Loss0.6204 | val acc 0.4167\n",
      "Epoch 17 | Iter5 | Loss0.3707 | val acc 0.4583\n",
      "Epoch 17 | Iter7 | Loss0.3510 | val acc 0.4792\n",
      "Epoch 17 | Iter9 | Loss0.4740 | val acc 0.5208\n",
      "Epoch 17 | Iter11 | Loss0.3893 | val acc 0.5000\n",
      "Epoch 17 | Iter13 | Loss0.4044 | val acc 0.4375\n",
      "Epoch 17 | Iter15 | Loss0.4725 | val acc 0.4167\n",
      "Epoch 17 | Iter17 | Loss0.3087 | val acc 0.4167\n",
      "Epoch 18 | Iter1 | Loss0.4622 | val acc 0.4167\n",
      "Epoch 18 | Iter3 | Loss0.3933 | val acc 0.4375\n",
      "Epoch 18 | Iter5 | Loss0.3666 | val acc 0.4792\n",
      "Epoch 18 | Iter7 | Loss0.5107 | val acc 0.5000\n",
      "Epoch 18 | Iter9 | Loss0.3146 | val acc 0.4375\n",
      "Epoch 18 | Iter11 | Loss0.4559 | val acc 0.4583\n",
      "Epoch 18 | Iter13 | Loss0.3312 | val acc 0.4792\n",
      "Epoch 18 | Iter15 | Loss0.3065 | val acc 0.5208\n",
      "Epoch 18 | Iter17 | Loss0.3640 | val acc 0.5000\n",
      "Epoch 19 | Iter1 | Loss0.4198 | val acc 0.4583\n",
      "Epoch 19 | Iter3 | Loss0.3365 | val acc 0.5000\n",
      "Epoch 19 | Iter5 | Loss0.2089 | val acc 0.4583\n",
      "Epoch 19 | Iter7 | Loss0.3377 | val acc 0.5000\n",
      "Epoch 19 | Iter9 | Loss0.3473 | val acc 0.5417\n",
      "Epoch 19 | Iter11 | Loss0.4520 | val acc 0.5208\n",
      "Epoch 19 | Iter13 | Loss0.4026 | val acc 0.5417\n",
      "Epoch 19 | Iter15 | Loss0.3378 | val acc 0.4792\n",
      "Epoch 19 | Iter17 | Loss0.2132 | val acc 0.4583\n",
      "Epoch 20 | Iter1 | Loss0.3294 | val acc 0.4583\n",
      "Epoch 20 | Iter3 | Loss0.2795 | val acc 0.4583\n",
      "Epoch 20 | Iter5 | Loss0.3362 | val acc 0.4583\n",
      "Epoch 20 | Iter7 | Loss0.2700 | val acc 0.4375\n",
      "Epoch 20 | Iter9 | Loss0.2985 | val acc 0.5000\n",
      "Epoch 20 | Iter11 | Loss0.2991 | val acc 0.5417\n",
      "Epoch 20 | Iter13 | Loss0.3279 | val acc 0.5208\n",
      "Epoch 20 | Iter15 | Loss0.2433 | val acc 0.5208\n",
      "Epoch 20 | Iter17 | Loss0.5045 | val acc 0.4792\n",
      "Epoch 21 | Iter1 | Loss0.4643 | val acc 0.5417\n",
      "Epoch 21 | Iter3 | Loss0.3695 | val acc 0.5417\n",
      "Epoch 21 | Iter5 | Loss0.3738 | val acc 0.4375\n",
      "Epoch 21 | Iter7 | Loss0.5469 | val acc 0.5625\n",
      "Epoch 21 | Iter9 | Loss0.3961 | val acc 0.5208\n",
      "Epoch 21 | Iter11 | Loss0.1589 | val acc 0.5000\n",
      "Epoch 21 | Iter13 | Loss0.4151 | val acc 0.5000\n",
      "Epoch 21 | Iter15 | Loss0.4090 | val acc 0.5000\n",
      "Epoch 21 | Iter17 | Loss0.3770 | val acc 0.4583\n",
      "Epoch 22 | Iter1 | Loss0.3767 | val acc 0.5000\n",
      "Epoch 22 | Iter3 | Loss0.2899 | val acc 0.4792\n",
      "Epoch 22 | Iter5 | Loss0.3939 | val acc 0.4583\n",
      "Epoch 22 | Iter7 | Loss0.3263 | val acc 0.4583\n",
      "Epoch 22 | Iter9 | Loss0.2879 | val acc 0.5000\n",
      "Epoch 22 | Iter11 | Loss0.4255 | val acc 0.4583\n",
      "Epoch 22 | Iter13 | Loss0.3511 | val acc 0.3958\n",
      "Epoch 22 | Iter15 | Loss0.1920 | val acc 0.4583\n",
      "Epoch 22 | Iter17 | Loss0.2759 | val acc 0.4792\n",
      "Epoch 23 | Iter1 | Loss0.3918 | val acc 0.4583\n",
      "Epoch 23 | Iter3 | Loss0.3006 | val acc 0.4792\n",
      "Epoch 23 | Iter5 | Loss0.3664 | val acc 0.4583\n",
      "Epoch 23 | Iter7 | Loss0.1984 | val acc 0.4792\n",
      "Epoch 23 | Iter9 | Loss0.1951 | val acc 0.5000\n",
      "Epoch 23 | Iter11 | Loss0.2075 | val acc 0.5208\n",
      "Epoch 23 | Iter13 | Loss0.4677 | val acc 0.5208\n",
      "Epoch 23 | Iter15 | Loss0.3619 | val acc 0.5208\n",
      "Epoch 23 | Iter17 | Loss0.2364 | val acc 0.4792\n",
      "Epoch 24 | Iter1 | Loss0.3087 | val acc 0.5208\n",
      "Epoch 24 | Iter3 | Loss0.3302 | val acc 0.4583\n",
      "Epoch 24 | Iter5 | Loss0.4235 | val acc 0.4792\n",
      "Epoch 24 | Iter7 | Loss0.2990 | val acc 0.5000\n",
      "Epoch 24 | Iter9 | Loss0.3505 | val acc 0.4375\n",
      "Epoch 24 | Iter11 | Loss0.2463 | val acc 0.4792\n",
      "Epoch 24 | Iter13 | Loss0.3264 | val acc 0.4583\n",
      "Epoch 24 | Iter15 | Loss0.1980 | val acc 0.4583\n",
      "Epoch 24 | Iter17 | Loss0.3411 | val acc 0.5000\n",
      "Epoch 25 | Iter1 | Loss0.3934 | val acc 0.5208\n",
      "Epoch 25 | Iter3 | Loss0.3709 | val acc 0.5000\n",
      "Epoch 25 | Iter5 | Loss0.1884 | val acc 0.5000\n",
      "Epoch 25 | Iter7 | Loss0.3114 | val acc 0.5000\n",
      "Epoch 25 | Iter9 | Loss0.2278 | val acc 0.5208\n",
      "Epoch 25 | Iter11 | Loss0.3531 | val acc 0.4792\n",
      "Epoch 25 | Iter13 | Loss0.2412 | val acc 0.4792\n",
      "Epoch 25 | Iter15 | Loss0.3680 | val acc 0.5000\n",
      "Epoch 25 | Iter17 | Loss0.5245 | val acc 0.5000\n",
      "--------------------------------------------------\n",
      "Training Net 6\n",
      "Epoch 0 | Iter1 | Loss1.3017 | val acc 0.3750\n",
      "Epoch 0 | Iter3 | Loss1.7989 | val acc 0.3542\n",
      "Epoch 0 | Iter5 | Loss1.5599 | val acc 0.2917\n",
      "Epoch 0 | Iter7 | Loss1.6205 | val acc 0.3333\n",
      "Epoch 0 | Iter9 | Loss1.6003 | val acc 0.1875\n",
      "Epoch 0 | Iter11 | Loss1.3517 | val acc 0.2708\n",
      "Epoch 0 | Iter13 | Loss1.4898 | val acc 0.2292\n",
      "Epoch 0 | Iter15 | Loss1.5292 | val acc 0.1875\n",
      "Epoch 0 | Iter17 | Loss1.6050 | val acc 0.2917\n",
      "Epoch 1 | Iter1 | Loss1.5157 | val acc 0.3125\n",
      "Epoch 1 | Iter3 | Loss1.2613 | val acc 0.3125\n",
      "Epoch 1 | Iter5 | Loss1.4859 | val acc 0.2708\n",
      "Epoch 1 | Iter7 | Loss1.3340 | val acc 0.2917\n",
      "Epoch 1 | Iter9 | Loss1.3786 | val acc 0.2083\n",
      "Epoch 1 | Iter11 | Loss1.5218 | val acc 0.1875\n",
      "Epoch 1 | Iter13 | Loss1.3398 | val acc 0.2500\n",
      "Epoch 1 | Iter15 | Loss1.3978 | val acc 0.2708\n",
      "Epoch 1 | Iter17 | Loss1.3803 | val acc 0.2917\n",
      "Epoch 2 | Iter1 | Loss1.2269 | val acc 0.2083\n",
      "Epoch 2 | Iter3 | Loss1.4001 | val acc 0.2500\n",
      "Epoch 2 | Iter5 | Loss1.0712 | val acc 0.2083\n",
      "Epoch 2 | Iter7 | Loss1.2753 | val acc 0.2917\n",
      "Epoch 2 | Iter9 | Loss1.2919 | val acc 0.3542\n",
      "Epoch 2 | Iter11 | Loss1.1154 | val acc 0.4167\n",
      "Epoch 2 | Iter13 | Loss1.2409 | val acc 0.5000\n",
      "Epoch 2 | Iter15 | Loss1.0566 | val acc 0.4583\n",
      "Epoch 2 | Iter17 | Loss1.4487 | val acc 0.4375\n",
      "Epoch 3 | Iter1 | Loss1.1996 | val acc 0.4583\n",
      "Epoch 3 | Iter3 | Loss1.2182 | val acc 0.5000\n",
      "Epoch 3 | Iter5 | Loss1.1770 | val acc 0.4792\n",
      "Epoch 3 | Iter7 | Loss1.1960 | val acc 0.4583\n",
      "Epoch 3 | Iter9 | Loss1.0876 | val acc 0.4167\n",
      "Epoch 3 | Iter11 | Loss1.2169 | val acc 0.3958\n",
      "Epoch 3 | Iter13 | Loss1.0620 | val acc 0.5000\n",
      "Epoch 3 | Iter15 | Loss1.1675 | val acc 0.4792\n",
      "Epoch 3 | Iter17 | Loss1.2593 | val acc 0.5000\n",
      "Epoch 4 | Iter1 | Loss1.1662 | val acc 0.4792\n",
      "Epoch 4 | Iter3 | Loss1.1164 | val acc 0.5625\n",
      "Epoch 4 | Iter5 | Loss1.0098 | val acc 0.5000\n",
      "Epoch 4 | Iter7 | Loss0.9059 | val acc 0.5208\n",
      "Epoch 4 | Iter9 | Loss0.9343 | val acc 0.3958\n",
      "Epoch 4 | Iter11 | Loss1.2116 | val acc 0.4792\n",
      "Epoch 4 | Iter13 | Loss1.0118 | val acc 0.5417\n",
      "Epoch 4 | Iter15 | Loss1.2137 | val acc 0.5000\n",
      "Epoch 4 | Iter17 | Loss0.8326 | val acc 0.5833\n",
      "Epoch 5 | Iter1 | Loss0.9518 | val acc 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Iter3 | Loss0.8583 | val acc 0.5833\n",
      "Epoch 5 | Iter5 | Loss0.9842 | val acc 0.5208\n",
      "Epoch 5 | Iter7 | Loss0.9937 | val acc 0.5208\n",
      "Epoch 5 | Iter9 | Loss0.9218 | val acc 0.6042\n",
      "Epoch 5 | Iter11 | Loss0.8256 | val acc 0.6250\n",
      "Epoch 5 | Iter13 | Loss0.9984 | val acc 0.6042\n",
      "Epoch 5 | Iter15 | Loss0.8224 | val acc 0.5625\n",
      "Epoch 5 | Iter17 | Loss1.1018 | val acc 0.5000\n",
      "Epoch 6 | Iter1 | Loss0.9911 | val acc 0.5625\n",
      "Epoch 6 | Iter3 | Loss0.8184 | val acc 0.5625\n",
      "Epoch 6 | Iter5 | Loss0.7684 | val acc 0.5625\n",
      "Epoch 6 | Iter7 | Loss0.9246 | val acc 0.5417\n",
      "Epoch 6 | Iter9 | Loss0.7255 | val acc 0.5000\n",
      "Epoch 6 | Iter11 | Loss0.9119 | val acc 0.4792\n",
      "Epoch 6 | Iter13 | Loss0.7612 | val acc 0.5833\n",
      "Epoch 6 | Iter15 | Loss0.8456 | val acc 0.4792\n",
      "Epoch 6 | Iter17 | Loss0.8911 | val acc 0.6042\n",
      "Epoch 7 | Iter1 | Loss0.8506 | val acc 0.6250\n",
      "Epoch 7 | Iter3 | Loss0.7708 | val acc 0.5417\n",
      "Epoch 7 | Iter5 | Loss0.7328 | val acc 0.5208\n",
      "Epoch 7 | Iter7 | Loss0.9244 | val acc 0.5417\n",
      "Epoch 7 | Iter9 | Loss0.8207 | val acc 0.6250\n",
      "Epoch 7 | Iter11 | Loss0.8878 | val acc 0.6042\n",
      "Epoch 7 | Iter13 | Loss0.7289 | val acc 0.6042\n",
      "Epoch 7 | Iter15 | Loss0.6722 | val acc 0.6042\n",
      "Epoch 7 | Iter17 | Loss0.6900 | val acc 0.6250\n",
      "Epoch 8 | Iter1 | Loss0.6368 | val acc 0.6875\n",
      "Epoch 8 | Iter3 | Loss0.7165 | val acc 0.7083\n",
      "Epoch 8 | Iter5 | Loss0.8404 | val acc 0.6667\n",
      "Epoch 8 | Iter7 | Loss0.6619 | val acc 0.5833\n",
      "Epoch 8 | Iter9 | Loss0.7570 | val acc 0.6458\n",
      "Epoch 8 | Iter11 | Loss0.6327 | val acc 0.6875\n",
      "Epoch 8 | Iter13 | Loss0.7206 | val acc 0.6250\n",
      "Epoch 8 | Iter15 | Loss0.7857 | val acc 0.6667\n",
      "Epoch 8 | Iter17 | Loss0.7802 | val acc 0.5833\n",
      "Epoch 9 | Iter1 | Loss0.6407 | val acc 0.6875\n",
      "Epoch 9 | Iter3 | Loss0.7580 | val acc 0.7083\n",
      "Epoch 9 | Iter5 | Loss0.6677 | val acc 0.6667\n",
      "Epoch 9 | Iter7 | Loss0.6164 | val acc 0.7500\n",
      "Epoch 9 | Iter9 | Loss0.6385 | val acc 0.6458\n",
      "Epoch 9 | Iter11 | Loss0.5064 | val acc 0.5833\n",
      "Epoch 9 | Iter13 | Loss0.6077 | val acc 0.6458\n",
      "Epoch 9 | Iter15 | Loss0.7610 | val acc 0.6042\n",
      "Epoch 9 | Iter17 | Loss0.5669 | val acc 0.6250\n",
      "Epoch 10 | Iter1 | Loss0.6619 | val acc 0.5833\n",
      "Epoch 10 | Iter3 | Loss0.7263 | val acc 0.7292\n",
      "Epoch 10 | Iter5 | Loss0.5839 | val acc 0.6667\n",
      "Epoch 10 | Iter7 | Loss0.5769 | val acc 0.6042\n",
      "Epoch 10 | Iter9 | Loss0.5191 | val acc 0.6458\n",
      "Epoch 10 | Iter11 | Loss0.5824 | val acc 0.5625\n",
      "Epoch 10 | Iter13 | Loss0.5472 | val acc 0.6458\n",
      "Epoch 10 | Iter15 | Loss0.6306 | val acc 0.7083\n",
      "Epoch 10 | Iter17 | Loss0.8004 | val acc 0.7292\n",
      "Epoch 11 | Iter1 | Loss0.5500 | val acc 0.7083\n",
      "Epoch 11 | Iter3 | Loss0.5356 | val acc 0.7500\n",
      "Epoch 11 | Iter5 | Loss0.5689 | val acc 0.6458\n",
      "Epoch 11 | Iter7 | Loss0.6162 | val acc 0.6042\n",
      "Epoch 11 | Iter9 | Loss0.5577 | val acc 0.6042\n",
      "Epoch 11 | Iter11 | Loss0.4262 | val acc 0.7083\n",
      "Epoch 11 | Iter13 | Loss0.5415 | val acc 0.6458\n",
      "Epoch 11 | Iter15 | Loss0.5693 | val acc 0.5833\n",
      "Epoch 11 | Iter17 | Loss0.6200 | val acc 0.6042\n",
      "Epoch 12 | Iter1 | Loss0.6422 | val acc 0.6667\n",
      "Epoch 12 | Iter3 | Loss0.4226 | val acc 0.6458\n",
      "Epoch 12 | Iter5 | Loss0.5961 | val acc 0.6458\n",
      "Epoch 12 | Iter7 | Loss0.5510 | val acc 0.6875\n",
      "Epoch 12 | Iter9 | Loss0.5359 | val acc 0.6667\n",
      "Epoch 12 | Iter11 | Loss0.5875 | val acc 0.6875\n",
      "Epoch 12 | Iter13 | Loss0.5537 | val acc 0.5417\n",
      "Epoch 12 | Iter15 | Loss0.4052 | val acc 0.6042\n",
      "Epoch 12 | Iter17 | Loss0.3170 | val acc 0.6250\n",
      "Epoch 13 | Iter1 | Loss0.6100 | val acc 0.7083\n",
      "Epoch 13 | Iter3 | Loss0.6387 | val acc 0.7500\n",
      "Epoch 13 | Iter5 | Loss0.5516 | val acc 0.7292\n",
      "Epoch 13 | Iter7 | Loss0.4355 | val acc 0.8125\n",
      "Epoch 13 | Iter9 | Loss0.4022 | val acc 0.7083\n",
      "Epoch 13 | Iter11 | Loss0.4341 | val acc 0.7292\n",
      "Epoch 13 | Iter13 | Loss0.4014 | val acc 0.7708\n",
      "Epoch 13 | Iter15 | Loss0.4293 | val acc 0.7292\n",
      "Epoch 13 | Iter17 | Loss0.5651 | val acc 0.7292\n",
      "Epoch 14 | Iter1 | Loss0.5144 | val acc 0.7083\n",
      "Epoch 14 | Iter3 | Loss0.4852 | val acc 0.6667\n",
      "Epoch 14 | Iter5 | Loss0.4150 | val acc 0.7500\n",
      "Epoch 14 | Iter7 | Loss0.5234 | val acc 0.7708\n",
      "Epoch 14 | Iter9 | Loss0.3113 | val acc 0.7500\n",
      "Epoch 14 | Iter11 | Loss0.3400 | val acc 0.7500\n",
      "Epoch 14 | Iter13 | Loss0.4473 | val acc 0.6667\n",
      "Epoch 14 | Iter15 | Loss0.3455 | val acc 0.7292\n",
      "Epoch 14 | Iter17 | Loss0.4806 | val acc 0.7083\n",
      "Epoch 15 | Iter1 | Loss0.3270 | val acc 0.7292\n",
      "Epoch 15 | Iter3 | Loss0.4930 | val acc 0.6875\n",
      "Epoch 15 | Iter5 | Loss0.2450 | val acc 0.7292\n",
      "Epoch 15 | Iter7 | Loss0.5689 | val acc 0.6458\n",
      "Epoch 15 | Iter9 | Loss0.3786 | val acc 0.6875\n",
      "Epoch 15 | Iter11 | Loss0.3386 | val acc 0.6458\n",
      "Epoch 15 | Iter13 | Loss0.3826 | val acc 0.6667\n",
      "Epoch 15 | Iter15 | Loss0.4275 | val acc 0.6667\n",
      "Epoch 15 | Iter17 | Loss0.4484 | val acc 0.7083\n",
      "Epoch 16 | Iter1 | Loss0.4116 | val acc 0.7917\n",
      "Epoch 16 | Iter3 | Loss0.6086 | val acc 0.5833\n",
      "Epoch 16 | Iter5 | Loss0.3887 | val acc 0.6667\n",
      "Epoch 16 | Iter7 | Loss0.4612 | val acc 0.6875\n",
      "Epoch 16 | Iter9 | Loss0.3657 | val acc 0.5625\n",
      "Epoch 16 | Iter11 | Loss0.4122 | val acc 0.6667\n",
      "Epoch 16 | Iter13 | Loss0.4322 | val acc 0.7708\n",
      "Epoch 16 | Iter15 | Loss0.3722 | val acc 0.7292\n",
      "Epoch 16 | Iter17 | Loss0.3901 | val acc 0.6875\n",
      "Epoch 17 | Iter1 | Loss0.3399 | val acc 0.6250\n",
      "Epoch 17 | Iter3 | Loss0.3100 | val acc 0.7083\n",
      "Epoch 17 | Iter5 | Loss0.2992 | val acc 0.6250\n",
      "Epoch 17 | Iter7 | Loss0.3686 | val acc 0.6667\n",
      "Epoch 17 | Iter9 | Loss0.4322 | val acc 0.6667\n",
      "Epoch 17 | Iter11 | Loss0.3456 | val acc 0.6667\n",
      "Epoch 17 | Iter13 | Loss0.2805 | val acc 0.7083\n",
      "Epoch 17 | Iter15 | Loss0.3252 | val acc 0.6667\n",
      "Epoch 17 | Iter17 | Loss0.3891 | val acc 0.7292\n",
      "Epoch 18 | Iter1 | Loss0.3827 | val acc 0.7292\n",
      "Epoch 18 | Iter3 | Loss0.3280 | val acc 0.6667\n",
      "Epoch 18 | Iter5 | Loss0.4097 | val acc 0.6875\n",
      "Epoch 18 | Iter7 | Loss0.6020 | val acc 0.6875\n",
      "Epoch 18 | Iter9 | Loss0.3464 | val acc 0.6042\n",
      "Epoch 18 | Iter11 | Loss0.3632 | val acc 0.6667\n",
      "Epoch 18 | Iter13 | Loss0.4991 | val acc 0.6875\n",
      "Epoch 18 | Iter15 | Loss0.3571 | val acc 0.7292\n",
      "Epoch 18 | Iter17 | Loss0.6403 | val acc 0.7292\n",
      "Epoch 19 | Iter1 | Loss0.2975 | val acc 0.6875\n",
      "Epoch 19 | Iter3 | Loss0.2730 | val acc 0.6458\n",
      "Epoch 19 | Iter5 | Loss0.3211 | val acc 0.6458\n",
      "Epoch 19 | Iter7 | Loss0.4263 | val acc 0.6875\n",
      "Epoch 19 | Iter9 | Loss0.2495 | val acc 0.7083\n",
      "Epoch 19 | Iter11 | Loss0.2155 | val acc 0.7083\n",
      "Epoch 19 | Iter13 | Loss0.4423 | val acc 0.5000\n",
      "Epoch 19 | Iter15 | Loss0.3417 | val acc 0.7083\n",
      "Epoch 19 | Iter17 | Loss0.3279 | val acc 0.7083\n",
      "Epoch 20 | Iter1 | Loss0.0935 | val acc 0.7500\n",
      "Epoch 20 | Iter3 | Loss0.3834 | val acc 0.7083\n",
      "Epoch 20 | Iter5 | Loss0.3537 | val acc 0.7292\n",
      "Epoch 20 | Iter7 | Loss0.3231 | val acc 0.7917\n",
      "Epoch 20 | Iter9 | Loss0.3848 | val acc 0.7500\n",
      "Epoch 20 | Iter11 | Loss0.3485 | val acc 0.7500\n",
      "Epoch 20 | Iter13 | Loss0.3830 | val acc 0.7917\n",
      "Epoch 20 | Iter15 | Loss0.2663 | val acc 0.7292\n",
      "Epoch 20 | Iter17 | Loss0.1986 | val acc 0.7083\n",
      "Epoch 21 | Iter1 | Loss0.2873 | val acc 0.7083\n",
      "Epoch 21 | Iter3 | Loss0.2426 | val acc 0.6875\n",
      "Epoch 21 | Iter5 | Loss0.3710 | val acc 0.7083\n",
      "Epoch 21 | Iter7 | Loss0.3976 | val acc 0.7083\n",
      "Epoch 21 | Iter9 | Loss0.1859 | val acc 0.7083\n",
      "Epoch 21 | Iter11 | Loss0.3167 | val acc 0.6875\n",
      "Epoch 21 | Iter13 | Loss0.3680 | val acc 0.7500\n",
      "Epoch 21 | Iter15 | Loss0.3145 | val acc 0.6042\n",
      "Epoch 21 | Iter17 | Loss0.2391 | val acc 0.6250\n",
      "Epoch 22 | Iter1 | Loss0.1655 | val acc 0.6458\n",
      "Epoch 22 | Iter3 | Loss0.2545 | val acc 0.6250\n",
      "Epoch 22 | Iter5 | Loss0.3111 | val acc 0.6875\n",
      "Epoch 22 | Iter7 | Loss0.2946 | val acc 0.6667\n",
      "Epoch 22 | Iter9 | Loss0.2476 | val acc 0.6458\n",
      "Epoch 22 | Iter11 | Loss0.3530 | val acc 0.6042\n",
      "Epoch 22 | Iter13 | Loss0.3343 | val acc 0.6458\n",
      "Epoch 22 | Iter15 | Loss0.2524 | val acc 0.7083\n",
      "Epoch 22 | Iter17 | Loss0.3662 | val acc 0.6875\n",
      "Epoch 23 | Iter1 | Loss0.2920 | val acc 0.6250\n",
      "Epoch 23 | Iter3 | Loss0.2524 | val acc 0.5833\n",
      "Epoch 23 | Iter5 | Loss0.2414 | val acc 0.7083\n",
      "Epoch 23 | Iter7 | Loss0.3629 | val acc 0.6875\n",
      "Epoch 23 | Iter9 | Loss0.2700 | val acc 0.7500\n",
      "Epoch 23 | Iter11 | Loss0.1709 | val acc 0.7083\n",
      "Epoch 23 | Iter13 | Loss0.4573 | val acc 0.7083\n",
      "Epoch 23 | Iter15 | Loss0.3204 | val acc 0.6875\n",
      "Epoch 23 | Iter17 | Loss0.4258 | val acc 0.6875\n",
      "Epoch 24 | Iter1 | Loss0.3985 | val acc 0.6250\n",
      "Epoch 24 | Iter3 | Loss0.3933 | val acc 0.6250\n",
      "Epoch 24 | Iter5 | Loss0.2287 | val acc 0.6458\n",
      "Epoch 24 | Iter7 | Loss0.3892 | val acc 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Iter9 | Loss0.1621 | val acc 0.7083\n",
      "Epoch 24 | Iter11 | Loss0.3006 | val acc 0.6875\n",
      "Epoch 24 | Iter13 | Loss0.3028 | val acc 0.6458\n",
      "Epoch 24 | Iter15 | Loss0.3159 | val acc 0.7292\n",
      "Epoch 24 | Iter17 | Loss0.1906 | val acc 0.7500\n",
      "Epoch 25 | Iter1 | Loss0.1845 | val acc 0.7083\n",
      "Epoch 25 | Iter3 | Loss0.4183 | val acc 0.7292\n",
      "Epoch 25 | Iter5 | Loss0.2355 | val acc 0.6875\n",
      "Epoch 25 | Iter7 | Loss0.3658 | val acc 0.7083\n",
      "Epoch 25 | Iter9 | Loss0.2371 | val acc 0.6875\n",
      "Epoch 25 | Iter11 | Loss0.3319 | val acc 0.7292\n",
      "Epoch 25 | Iter13 | Loss0.2672 | val acc 0.7500\n",
      "Epoch 25 | Iter15 | Loss0.2633 | val acc 0.7083\n",
      "Epoch 25 | Iter17 | Loss0.2651 | val acc 0.7917\n",
      "--------------------------------------------------\n",
      "Training Net 7\n",
      "Epoch 0 | Iter1 | Loss1.5614 | val acc 0.1667\n",
      "Epoch 0 | Iter3 | Loss1.4592 | val acc 0.1667\n",
      "Epoch 0 | Iter5 | Loss1.7603 | val acc 0.1667\n",
      "Epoch 0 | Iter7 | Loss1.5689 | val acc 0.1250\n",
      "Epoch 0 | Iter9 | Loss1.7458 | val acc 0.0833\n",
      "Epoch 0 | Iter11 | Loss1.5826 | val acc 0.1250\n",
      "Epoch 0 | Iter13 | Loss1.5179 | val acc 0.1458\n",
      "Epoch 0 | Iter15 | Loss1.5100 | val acc 0.1667\n",
      "Epoch 0 | Iter17 | Loss1.5382 | val acc 0.1458\n",
      "Epoch 1 | Iter1 | Loss1.5400 | val acc 0.2917\n",
      "Epoch 1 | Iter3 | Loss1.3739 | val acc 0.2917\n",
      "Epoch 1 | Iter5 | Loss1.2765 | val acc 0.2708\n",
      "Epoch 1 | Iter7 | Loss1.4134 | val acc 0.2708\n",
      "Epoch 1 | Iter9 | Loss1.4193 | val acc 0.2292\n",
      "Epoch 1 | Iter11 | Loss1.3366 | val acc 0.3125\n",
      "Epoch 1 | Iter13 | Loss1.6189 | val acc 0.1875\n",
      "Epoch 1 | Iter15 | Loss1.4127 | val acc 0.3125\n",
      "Epoch 1 | Iter17 | Loss1.2440 | val acc 0.3333\n",
      "Epoch 2 | Iter1 | Loss1.2958 | val acc 0.3125\n",
      "Epoch 2 | Iter3 | Loss1.3617 | val acc 0.3125\n",
      "Epoch 2 | Iter5 | Loss1.3543 | val acc 0.3542\n",
      "Epoch 2 | Iter7 | Loss1.3179 | val acc 0.3542\n",
      "Epoch 2 | Iter9 | Loss1.2237 | val acc 0.3542\n",
      "Epoch 2 | Iter11 | Loss1.3975 | val acc 0.2917\n",
      "Epoch 2 | Iter13 | Loss1.2620 | val acc 0.3542\n",
      "Epoch 2 | Iter15 | Loss1.1472 | val acc 0.2917\n",
      "Epoch 2 | Iter17 | Loss1.3458 | val acc 0.3542\n",
      "Epoch 3 | Iter1 | Loss1.2027 | val acc 0.3333\n",
      "Epoch 3 | Iter3 | Loss1.2194 | val acc 0.3333\n",
      "Epoch 3 | Iter5 | Loss1.2662 | val acc 0.2917\n",
      "Epoch 3 | Iter7 | Loss1.2245 | val acc 0.3125\n",
      "Epoch 3 | Iter9 | Loss1.2192 | val acc 0.2917\n",
      "Epoch 3 | Iter11 | Loss1.2245 | val acc 0.3542\n",
      "Epoch 3 | Iter13 | Loss1.1237 | val acc 0.4167\n",
      "Epoch 3 | Iter15 | Loss1.2228 | val acc 0.3750\n",
      "Epoch 3 | Iter17 | Loss1.2758 | val acc 0.4583\n",
      "Epoch 4 | Iter1 | Loss1.1170 | val acc 0.4375\n",
      "Epoch 4 | Iter3 | Loss1.2687 | val acc 0.3958\n",
      "Epoch 4 | Iter5 | Loss1.1123 | val acc 0.3542\n",
      "Epoch 4 | Iter7 | Loss1.1545 | val acc 0.4167\n",
      "Epoch 4 | Iter9 | Loss1.2462 | val acc 0.4167\n",
      "Epoch 4 | Iter11 | Loss1.0373 | val acc 0.4583\n",
      "Epoch 4 | Iter13 | Loss1.1367 | val acc 0.4792\n",
      "Epoch 4 | Iter15 | Loss1.1296 | val acc 0.4583\n",
      "Epoch 4 | Iter17 | Loss1.1997 | val acc 0.4375\n",
      "Epoch 5 | Iter1 | Loss1.1778 | val acc 0.4375\n",
      "Epoch 5 | Iter3 | Loss1.0827 | val acc 0.4375\n",
      "Epoch 5 | Iter5 | Loss1.1516 | val acc 0.4792\n",
      "Epoch 5 | Iter7 | Loss1.1242 | val acc 0.3750\n",
      "Epoch 5 | Iter9 | Loss1.1424 | val acc 0.4583\n",
      "Epoch 5 | Iter11 | Loss1.0559 | val acc 0.4375\n",
      "Epoch 5 | Iter13 | Loss0.9799 | val acc 0.4167\n",
      "Epoch 5 | Iter15 | Loss1.1402 | val acc 0.4375\n",
      "Epoch 5 | Iter17 | Loss0.9353 | val acc 0.5000\n",
      "Epoch 6 | Iter1 | Loss1.1092 | val acc 0.5000\n",
      "Epoch 6 | Iter3 | Loss1.0893 | val acc 0.5208\n",
      "Epoch 6 | Iter5 | Loss0.9792 | val acc 0.5417\n",
      "Epoch 6 | Iter7 | Loss0.9186 | val acc 0.5833\n",
      "Epoch 6 | Iter9 | Loss0.9940 | val acc 0.3542\n",
      "Epoch 6 | Iter11 | Loss0.9401 | val acc 0.5417\n",
      "Epoch 6 | Iter13 | Loss1.0203 | val acc 0.6042\n",
      "Epoch 6 | Iter15 | Loss0.9520 | val acc 0.5417\n",
      "Epoch 6 | Iter17 | Loss0.9593 | val acc 0.5833\n",
      "Epoch 7 | Iter1 | Loss1.1282 | val acc 0.6250\n",
      "Epoch 7 | Iter3 | Loss0.9852 | val acc 0.4167\n",
      "Epoch 7 | Iter5 | Loss0.9101 | val acc 0.3750\n",
      "Epoch 7 | Iter7 | Loss0.9350 | val acc 0.5208\n",
      "Epoch 7 | Iter9 | Loss1.0035 | val acc 0.3958\n",
      "Epoch 7 | Iter11 | Loss1.0755 | val acc 0.5208\n",
      "Epoch 7 | Iter13 | Loss0.7606 | val acc 0.4583\n",
      "Epoch 7 | Iter15 | Loss1.0355 | val acc 0.4792\n",
      "Epoch 7 | Iter17 | Loss1.0035 | val acc 0.5000\n",
      "Epoch 8 | Iter1 | Loss1.0543 | val acc 0.5833\n",
      "Epoch 8 | Iter3 | Loss0.7646 | val acc 0.5417\n",
      "Epoch 8 | Iter5 | Loss1.0469 | val acc 0.4583\n",
      "Epoch 8 | Iter7 | Loss0.7844 | val acc 0.5208\n",
      "Epoch 8 | Iter9 | Loss0.8541 | val acc 0.4792\n",
      "Epoch 8 | Iter11 | Loss0.9957 | val acc 0.5833\n",
      "Epoch 8 | Iter13 | Loss0.7967 | val acc 0.5625\n",
      "Epoch 8 | Iter15 | Loss0.7067 | val acc 0.4583\n",
      "Epoch 8 | Iter17 | Loss0.8872 | val acc 0.5208\n",
      "Epoch 9 | Iter1 | Loss0.7106 | val acc 0.5833\n",
      "Epoch 9 | Iter3 | Loss0.8479 | val acc 0.5833\n",
      "Epoch 9 | Iter5 | Loss0.9551 | val acc 0.4792\n",
      "Epoch 9 | Iter7 | Loss0.8223 | val acc 0.5208\n",
      "Epoch 9 | Iter9 | Loss0.8600 | val acc 0.5208\n",
      "Epoch 9 | Iter11 | Loss0.8286 | val acc 0.5208\n",
      "Epoch 9 | Iter13 | Loss0.7525 | val acc 0.5000\n",
      "Epoch 9 | Iter15 | Loss0.8366 | val acc 0.5833\n",
      "Epoch 9 | Iter17 | Loss0.9133 | val acc 0.4167\n",
      "Epoch 10 | Iter1 | Loss0.7038 | val acc 0.5208\n",
      "Epoch 10 | Iter3 | Loss0.7537 | val acc 0.5417\n",
      "Epoch 10 | Iter5 | Loss0.7771 | val acc 0.5833\n",
      "Epoch 10 | Iter7 | Loss0.8759 | val acc 0.5625\n",
      "Epoch 10 | Iter9 | Loss0.6338 | val acc 0.5625\n",
      "Epoch 10 | Iter11 | Loss0.8753 | val acc 0.5417\n",
      "Epoch 10 | Iter13 | Loss0.6777 | val acc 0.5417\n",
      "Epoch 10 | Iter15 | Loss0.8844 | val acc 0.5833\n",
      "Epoch 10 | Iter17 | Loss0.7629 | val acc 0.5833\n",
      "Epoch 11 | Iter1 | Loss0.6888 | val acc 0.5833\n",
      "Epoch 11 | Iter3 | Loss0.7027 | val acc 0.5625\n",
      "Epoch 11 | Iter5 | Loss0.7435 | val acc 0.4792\n",
      "Epoch 11 | Iter7 | Loss0.8037 | val acc 0.4792\n",
      "Epoch 11 | Iter9 | Loss0.6566 | val acc 0.4375\n",
      "Epoch 11 | Iter11 | Loss0.8592 | val acc 0.3958\n",
      "Epoch 11 | Iter13 | Loss0.5596 | val acc 0.4375\n",
      "Epoch 11 | Iter15 | Loss0.8410 | val acc 0.5417\n",
      "Epoch 11 | Iter17 | Loss0.6250 | val acc 0.3958\n",
      "Epoch 12 | Iter1 | Loss0.6925 | val acc 0.5000\n",
      "Epoch 12 | Iter3 | Loss0.6344 | val acc 0.4792\n",
      "Epoch 12 | Iter5 | Loss0.6491 | val acc 0.5625\n",
      "Epoch 12 | Iter7 | Loss0.7841 | val acc 0.5000\n",
      "Epoch 12 | Iter9 | Loss0.6180 | val acc 0.5000\n",
      "Epoch 12 | Iter11 | Loss0.6583 | val acc 0.5208\n",
      "Epoch 12 | Iter13 | Loss0.6501 | val acc 0.5000\n",
      "Epoch 12 | Iter15 | Loss0.5786 | val acc 0.4792\n",
      "Epoch 12 | Iter17 | Loss0.5500 | val acc 0.5208\n",
      "Epoch 13 | Iter1 | Loss0.4472 | val acc 0.5417\n",
      "Epoch 13 | Iter3 | Loss0.6408 | val acc 0.5208\n",
      "Epoch 13 | Iter5 | Loss0.5210 | val acc 0.4583\n",
      "Epoch 13 | Iter7 | Loss0.5977 | val acc 0.5833\n",
      "Epoch 13 | Iter9 | Loss0.6068 | val acc 0.5625\n",
      "Epoch 13 | Iter11 | Loss0.6980 | val acc 0.5833\n",
      "Epoch 13 | Iter13 | Loss0.5739 | val acc 0.5417\n",
      "Epoch 13 | Iter15 | Loss0.4836 | val acc 0.4792\n",
      "Epoch 13 | Iter17 | Loss0.6860 | val acc 0.6458\n",
      "Epoch 14 | Iter1 | Loss0.5211 | val acc 0.5625\n",
      "Epoch 14 | Iter3 | Loss0.6144 | val acc 0.6250\n",
      "Epoch 14 | Iter5 | Loss0.4369 | val acc 0.6250\n",
      "Epoch 14 | Iter7 | Loss0.5355 | val acc 0.6042\n",
      "Epoch 14 | Iter9 | Loss0.4767 | val acc 0.5208\n",
      "Epoch 14 | Iter11 | Loss0.5384 | val acc 0.5000\n",
      "Epoch 14 | Iter13 | Loss0.5398 | val acc 0.6042\n",
      "Epoch 14 | Iter15 | Loss0.3423 | val acc 0.6458\n",
      "Epoch 14 | Iter17 | Loss0.6128 | val acc 0.6250\n",
      "Epoch 15 | Iter1 | Loss0.4459 | val acc 0.5417\n",
      "Epoch 15 | Iter3 | Loss0.4159 | val acc 0.5208\n",
      "Epoch 15 | Iter5 | Loss0.3203 | val acc 0.3958\n",
      "Epoch 15 | Iter7 | Loss0.4303 | val acc 0.3958\n",
      "Epoch 15 | Iter9 | Loss0.4196 | val acc 0.4167\n",
      "Epoch 15 | Iter11 | Loss0.5547 | val acc 0.6250\n",
      "Epoch 15 | Iter13 | Loss0.5562 | val acc 0.6250\n",
      "Epoch 15 | Iter15 | Loss0.4353 | val acc 0.6458\n",
      "Epoch 15 | Iter17 | Loss0.3925 | val acc 0.5833\n",
      "Epoch 16 | Iter1 | Loss0.4561 | val acc 0.6042\n",
      "Epoch 16 | Iter3 | Loss0.3852 | val acc 0.6250\n",
      "Epoch 16 | Iter5 | Loss0.4221 | val acc 0.3958\n",
      "Epoch 16 | Iter7 | Loss0.5860 | val acc 0.4792\n",
      "Epoch 16 | Iter9 | Loss0.3351 | val acc 0.6042\n",
      "Epoch 16 | Iter11 | Loss0.5352 | val acc 0.4792\n",
      "Epoch 16 | Iter13 | Loss0.4481 | val acc 0.5208\n",
      "Epoch 16 | Iter15 | Loss0.3379 | val acc 0.5417\n",
      "Epoch 16 | Iter17 | Loss0.4626 | val acc 0.5208\n",
      "Epoch 17 | Iter1 | Loss0.3418 | val acc 0.4792\n",
      "Epoch 17 | Iter3 | Loss0.2668 | val acc 0.4583\n",
      "Epoch 17 | Iter5 | Loss0.3913 | val acc 0.5000\n",
      "Epoch 17 | Iter7 | Loss0.4352 | val acc 0.5625\n",
      "Epoch 17 | Iter9 | Loss0.4656 | val acc 0.4583\n",
      "Epoch 17 | Iter11 | Loss0.3688 | val acc 0.5417\n",
      "Epoch 17 | Iter13 | Loss0.2989 | val acc 0.5208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Iter15 | Loss0.3583 | val acc 0.4583\n",
      "Epoch 17 | Iter17 | Loss0.3956 | val acc 0.5000\n",
      "Epoch 18 | Iter1 | Loss0.4121 | val acc 0.5000\n",
      "Epoch 18 | Iter3 | Loss0.4961 | val acc 0.6250\n",
      "Epoch 18 | Iter5 | Loss0.4526 | val acc 0.5833\n",
      "Epoch 18 | Iter7 | Loss0.3878 | val acc 0.6250\n",
      "Epoch 18 | Iter9 | Loss0.4745 | val acc 0.4792\n",
      "Epoch 18 | Iter11 | Loss0.3426 | val acc 0.5000\n",
      "Epoch 18 | Iter13 | Loss0.3883 | val acc 0.6250\n",
      "Epoch 18 | Iter15 | Loss0.2389 | val acc 0.6250\n",
      "Epoch 18 | Iter17 | Loss0.3214 | val acc 0.6667\n",
      "Epoch 19 | Iter1 | Loss0.3280 | val acc 0.3958\n",
      "Epoch 19 | Iter3 | Loss0.5195 | val acc 0.5000\n",
      "Epoch 19 | Iter5 | Loss0.4460 | val acc 0.5208\n",
      "Epoch 19 | Iter7 | Loss0.3542 | val acc 0.6042\n",
      "Epoch 19 | Iter9 | Loss0.4021 | val acc 0.6042\n",
      "Epoch 19 | Iter11 | Loss0.4237 | val acc 0.5208\n",
      "Epoch 19 | Iter13 | Loss0.4658 | val acc 0.4792\n",
      "Epoch 19 | Iter15 | Loss0.3429 | val acc 0.3958\n",
      "Epoch 19 | Iter17 | Loss0.4284 | val acc 0.5208\n",
      "Epoch 20 | Iter1 | Loss0.3950 | val acc 0.5625\n",
      "Epoch 20 | Iter3 | Loss0.2807 | val acc 0.6042\n",
      "Epoch 20 | Iter5 | Loss0.3805 | val acc 0.5625\n",
      "Epoch 20 | Iter7 | Loss0.2826 | val acc 0.5417\n",
      "Epoch 20 | Iter9 | Loss0.3616 | val acc 0.5000\n",
      "Epoch 20 | Iter11 | Loss0.3067 | val acc 0.4792\n",
      "Epoch 20 | Iter13 | Loss0.4416 | val acc 0.4583\n",
      "Epoch 20 | Iter15 | Loss0.5240 | val acc 0.5833\n",
      "Epoch 20 | Iter17 | Loss0.6152 | val acc 0.5417\n",
      "Epoch 21 | Iter1 | Loss0.3495 | val acc 0.5000\n",
      "Epoch 21 | Iter3 | Loss0.4943 | val acc 0.5208\n",
      "Epoch 21 | Iter5 | Loss0.5059 | val acc 0.6042\n",
      "Epoch 21 | Iter7 | Loss0.2906 | val acc 0.6042\n",
      "Epoch 21 | Iter9 | Loss0.4824 | val acc 0.5417\n",
      "Epoch 21 | Iter11 | Loss0.4250 | val acc 0.5833\n",
      "Epoch 21 | Iter13 | Loss0.2948 | val acc 0.6250\n",
      "Epoch 21 | Iter15 | Loss0.3353 | val acc 0.6042\n",
      "Epoch 21 | Iter17 | Loss0.4356 | val acc 0.6667\n",
      "Epoch 22 | Iter1 | Loss0.3242 | val acc 0.6250\n",
      "Epoch 22 | Iter3 | Loss0.3227 | val acc 0.6458\n",
      "Epoch 22 | Iter5 | Loss0.2556 | val acc 0.6042\n",
      "Epoch 22 | Iter7 | Loss0.4224 | val acc 0.5417\n",
      "Epoch 22 | Iter9 | Loss0.1744 | val acc 0.5625\n",
      "Epoch 22 | Iter11 | Loss0.3069 | val acc 0.5833\n",
      "Epoch 22 | Iter13 | Loss0.3600 | val acc 0.5417\n",
      "Epoch 22 | Iter15 | Loss0.3289 | val acc 0.5417\n",
      "Epoch 22 | Iter17 | Loss0.5027 | val acc 0.5833\n",
      "Epoch 23 | Iter1 | Loss0.3497 | val acc 0.5417\n",
      "Epoch 23 | Iter3 | Loss0.5586 | val acc 0.5208\n",
      "Epoch 23 | Iter5 | Loss0.4221 | val acc 0.5417\n",
      "Epoch 23 | Iter7 | Loss0.2128 | val acc 0.6042\n",
      "Epoch 23 | Iter9 | Loss0.2667 | val acc 0.5625\n",
      "Epoch 23 | Iter11 | Loss0.2604 | val acc 0.6042\n",
      "Epoch 23 | Iter13 | Loss0.3301 | val acc 0.6250\n",
      "Epoch 23 | Iter15 | Loss0.2294 | val acc 0.6250\n",
      "Epoch 23 | Iter17 | Loss0.4096 | val acc 0.6875\n",
      "Epoch 24 | Iter1 | Loss0.2824 | val acc 0.5833\n",
      "Epoch 24 | Iter3 | Loss0.2442 | val acc 0.5000\n",
      "Epoch 24 | Iter5 | Loss0.3089 | val acc 0.6875\n",
      "Epoch 24 | Iter7 | Loss0.3206 | val acc 0.4792\n",
      "Epoch 24 | Iter9 | Loss0.2952 | val acc 0.5000\n",
      "Epoch 24 | Iter11 | Loss0.3134 | val acc 0.5208\n",
      "Epoch 24 | Iter13 | Loss0.2915 | val acc 0.5625\n",
      "Epoch 24 | Iter15 | Loss0.1910 | val acc 0.6250\n",
      "Epoch 24 | Iter17 | Loss0.4905 | val acc 0.6458\n",
      "Epoch 25 | Iter1 | Loss0.3453 | val acc 0.6458\n",
      "Epoch 25 | Iter3 | Loss0.3569 | val acc 0.6458\n",
      "Epoch 25 | Iter5 | Loss0.3515 | val acc 0.6667\n",
      "Epoch 25 | Iter7 | Loss0.3606 | val acc 0.6875\n",
      "Epoch 25 | Iter9 | Loss0.3420 | val acc 0.6875\n",
      "Epoch 25 | Iter11 | Loss0.4146 | val acc 0.6042\n",
      "Epoch 25 | Iter13 | Loss0.2786 | val acc 0.5417\n",
      "Epoch 25 | Iter15 | Loss0.1992 | val acc 0.6458\n",
      "Epoch 25 | Iter17 | Loss0.3310 | val acc 0.4792\n",
      "Test accuracy is:  0.56\n"
     ]
    }
   ],
   "source": [
    "net_1 = Net()\n",
    "net_2 = Net()\n",
    "net_3 = Net()\n",
    "net_4 = Net()\n",
    "net_5 = Net()\n",
    "net_6 = Net()\n",
    "net_7 = Net()\n",
    "list_net = [net_1, net_2, net_3, net_4, net_5, net_6, net_7]\n",
    "list_best_net = [Net(), Net(), Net(), Net(), Net(), Net(), Net()]\n",
    "for n,net in enumerate(list_net):\n",
    "    #val_acc_history = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(net.parameters(),lr = 0.001)\n",
    "    print('--------------------------------------------------')\n",
    "    print('Training Net {}'.format(n+1))\n",
    "    for epoch in range(26):\n",
    "        for i , data in enumerate(train_loader_1, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 2 == 1:\n",
    "                net.eval()\n",
    "                val_correct, val_total = 0, 0 \n",
    "                for val_data in val_loader_1:\n",
    "                    val_images, val_labels = val_data\n",
    "                    val_outputs = net(val_images)\n",
    "                    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                    val_total += val_labels.size(0)\n",
    "                    val_correct += (val_predicted == val_labels).sum().item()\n",
    "                val_acc = val_correct / val_total\n",
    "                print('Epoch {} | Iter{} | Loss{:.4f} | val acc {:.4f}'.format(\n",
    "                    epoch, i , loss, val_acc))\n",
    "                #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "                #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "        #val_correct, val_total = 0, 0\n",
    "        #for val_data in val_loader_1:\n",
    "        #    val_images, val_labels = val_data\n",
    "        #    val_outputs = net(val_images)\n",
    "        #    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        #    val_total += val_labels.size(0)\n",
    "        #    val_correct += (val_predicted == val_labels).sum().item()\n",
    "        #val_acc = val_correct / val_total\n",
    "        #val_acc_history.append(val_acc)\n",
    "        #if val_acc == max(val_acc_history):\n",
    "        #    list_best_net[n] = Net()\n",
    "        #    list_best_net[n].load_state_dict(net.state_dict())\n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_images, test_labels = test_data\n",
    "    test_predicted_list = []\n",
    "    for net in list_net:\n",
    "    #for net_best in list_best_net:\n",
    "        test_outputs = net(test_images)\n",
    "        #test_outputs = net_best(test_images)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_predicted_list.append(test_predicted.numpy())\n",
    "    test_predicted_list = np.array(test_predicted_list)\n",
    "    test_predicted_result = []\n",
    "    for vote in range(np.shape(test_predicted_list)[1]):\n",
    "        test_predicted_result.append(Counter(test_predicted_list[:,vote]).most_common(1)[0][0])\n",
    "    test_predicted = torch.Tensor(test_predicted_result)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
