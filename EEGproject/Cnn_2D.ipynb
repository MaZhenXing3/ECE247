{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 3 3 2 2 3 3 0 2 3 2 0 1 1 3 3 2 0 2 1 0 1 3 2 0 1 1 3 2 2 1 1 2 0 0\n",
      " 0 0 3 1 2 0 1 3 2 0 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "# For subject 1\n",
    "X_train_valid_1 = X_train_valid[np.where(person_train_valid==0)[0]]\n",
    "y_train_valid_1 = y_train_valid[np.where(person_train_valid==0)[0]] - 769\n",
    "X_test_1 = X_test[np.where(person_test==0)[0]]\n",
    "y_test_1 = y_test[np.where(person_test==0)[0]] - 769\n",
    "print(y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train_valid_1, y_train_valid_1,\n",
    "                                                              test_size=0.2,shuffle=True)\n",
    "\n",
    "\n",
    "X_train_1 = X_train_1.reshape(X_train_1.shape[0],1,X_train_1.shape[1],X_train_1.shape[2])\n",
    "X_valid_1 = X_valid_1.reshape(X_valid_1.shape[0],1,X_valid_1.shape[1],X_valid_1.shape[2])\n",
    "X_test_1 = X_test_1.reshape(X_test_1.shape[0],1,X_test_1.shape[1],X_test_1.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = Dataset(X_train_1,y_train_1)\n",
    "val_set_1 = Dataset(X_valid_1,y_valid_1)\n",
    "test_set_1 = Dataset(X_test_1, y_test_1)\n",
    "\n",
    "train_loader_1 = torch.utils.data.DataLoader(train_set_1,batch_size=24,shuffle=True)\n",
    "val_loader_1 = torch.utils.data.DataLoader(val_set_1,batch_size=6,shuffle=True)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_set_1,batch_size=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv11): Conv2d(1, 15, kernel_size=(1, 11), stride=(1, 1))\n",
      "  (bn11): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv12): Conv2d(990, 990, kernel_size=(22, 1), stride=(1, 1))\n",
      "  (bn12): BatchNorm2d(990, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(1, 50, kernel_size=(15, 11), stride=(1, 1))\n",
      "  (bn21): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv31): Conv2d(1, 100, kernel_size=(50, 12), stride=(1, 1))\n",
      "  (bn31): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv41): Conv2d(1, 200, kernel_size=(100, 11), stride=(1, 1))\n",
      "  (bn41): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=5000, out_features=600, bias=True)\n",
      "  (fc2): Linear(in_features=600, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=4, bias=True)\n",
      "  (drop): Dropout(p=0.8, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()  # initial the model\n",
    "        self.conv11 = nn.Conv2d(1,15,(1,11)) # depth 20, 22*990\n",
    "        self.bn11 = nn.BatchNorm2d(15)\n",
    "        # permute 990,  22 x 12\n",
    "        self.conv12 = nn.Conv2d(990,990,(22,1)) # after permutes, 1, 15*990\n",
    "        self.bn12 = nn.BatchNorm2d(990) \n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d((1,3),stride = (1,2)) # 1, 15*494\n",
    "        # now do normal conv - maxpool\n",
    "        # block2\n",
    "        self.conv21 = nn.Conv2d(1,50,(15,11)) # after permute 1, 50*484\n",
    "        self.bn21 = nn.BatchNorm2d(50)\n",
    "        self.pool2 = nn.MaxPool2d((1,3),stride = (1,3))\n",
    "        # block3\n",
    "        self.conv31 = nn.Conv2d(1,100,(50,12))# after permute 1, 100*150\n",
    "        self.bn31 = nn.BatchNorm2d(100)\n",
    "        self.pool3 = nn.MaxPool2d((1,3),stride = (1,3))\n",
    "        #block4\n",
    "        self.conv41 = nn.Conv2d(1,200,(100,11)) # after permute 1, 200*40\n",
    "        self.bn41 = nn.BatchNorm2d(200)\n",
    "        self.pool4 = nn.MaxPool2d((1,2),stride = (1,2))\n",
    "        #linear \n",
    "        self.fc1 = nn.Linear(100*50,600)\n",
    "        self.fc2 = nn.Linear(600,60)\n",
    "        self.fc3 = nn.Linear(60,4)\n",
    "        self.drop = nn.Dropout(0.8)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn11(self.conv11(x)))\n",
    "        x = x.permute(0,3,2,1)\n",
    "        x = F.relu(self.bn12(self.conv12(x)))\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = self.pool1(x)\n",
    "        # now do normal 2d [conv - max] * 3\n",
    "        x = F.relu(self.bn21(self.conv21(x)))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.bn31(self.conv31(x)))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.pool3(x)\n",
    "        #x = F.relu(self.bn41(self.conv41(x)))\n",
    "        #x = x.permute(0,2,1,3)\n",
    "        #x = self.pool4(x)\n",
    "        \n",
    "        x = x.view(-1,100*50)\n",
    "        x = self.drop(F.elu(self.fc1(x)))\n",
    "        x = self.drop(F.elu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = 0.0005)\n",
    "writer = SummaryWriter('./tensorboard/run1',flush_secs = 30) # for board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Iter1 | Loss1.8423 | TrainAcc0.2083 | val acc 0.3125\n",
      "Epoch 0 | Iter3 | Loss1.3950 | TrainAcc0.3333 | val acc 0.3542\n",
      "Epoch 0 | Iter5 | Loss1.6417 | TrainAcc0.2917 | val acc 0.3333\n",
      "Epoch 0 | Iter7 | Loss1.6836 | TrainAcc0.3333 | val acc 0.3333\n",
      "Epoch 1 | Iter1 | Loss1.6417 | TrainAcc0.4167 | val acc 0.2708\n",
      "Epoch 1 | Iter3 | Loss1.6027 | TrainAcc0.2500 | val acc 0.2708\n",
      "Epoch 1 | Iter5 | Loss1.2947 | TrainAcc0.4167 | val acc 0.2917\n",
      "Epoch 1 | Iter7 | Loss1.2956 | TrainAcc0.2381 | val acc 0.2708\n",
      "Epoch 2 | Iter1 | Loss1.3836 | TrainAcc0.3333 | val acc 0.2708\n",
      "Epoch 2 | Iter3 | Loss1.8769 | TrainAcc0.2500 | val acc 0.2708\n",
      "Epoch 2 | Iter5 | Loss1.6363 | TrainAcc0.3333 | val acc 0.2708\n",
      "Epoch 2 | Iter7 | Loss1.8593 | TrainAcc0.3333 | val acc 0.2500\n",
      "Epoch 3 | Iter1 | Loss1.5921 | TrainAcc0.4167 | val acc 0.2917\n",
      "Epoch 3 | Iter3 | Loss1.5385 | TrainAcc0.4167 | val acc 0.2708\n",
      "Epoch 3 | Iter5 | Loss1.6260 | TrainAcc0.3750 | val acc 0.2708\n",
      "Epoch 3 | Iter7 | Loss1.0672 | TrainAcc0.5714 | val acc 0.2917\n",
      "Epoch 4 | Iter1 | Loss1.1334 | TrainAcc0.5417 | val acc 0.2917\n",
      "Epoch 4 | Iter3 | Loss1.1311 | TrainAcc0.5417 | val acc 0.2292\n",
      "Epoch 4 | Iter5 | Loss1.2723 | TrainAcc0.3333 | val acc 0.2708\n",
      "Epoch 4 | Iter7 | Loss1.1433 | TrainAcc0.5238 | val acc 0.2708\n",
      "Epoch 5 | Iter1 | Loss1.3100 | TrainAcc0.4583 | val acc 0.2708\n",
      "Epoch 5 | Iter3 | Loss1.0391 | TrainAcc0.5417 | val acc 0.2708\n",
      "Epoch 5 | Iter5 | Loss1.0936 | TrainAcc0.6667 | val acc 0.3125\n",
      "Epoch 5 | Iter7 | Loss1.3647 | TrainAcc0.3810 | val acc 0.3333\n",
      "Epoch 6 | Iter1 | Loss1.2398 | TrainAcc0.2917 | val acc 0.3125\n",
      "Epoch 6 | Iter3 | Loss1.1550 | TrainAcc0.5000 | val acc 0.3333\n",
      "Epoch 6 | Iter5 | Loss1.4567 | TrainAcc0.5833 | val acc 0.3542\n",
      "Epoch 6 | Iter7 | Loss1.2512 | TrainAcc0.4762 | val acc 0.3125\n",
      "Epoch 7 | Iter1 | Loss1.3572 | TrainAcc0.2500 | val acc 0.3125\n",
      "Epoch 7 | Iter3 | Loss1.3423 | TrainAcc0.5417 | val acc 0.3125\n",
      "Epoch 7 | Iter5 | Loss1.0033 | TrainAcc0.6250 | val acc 0.2917\n",
      "Epoch 7 | Iter7 | Loss0.9653 | TrainAcc0.3810 | val acc 0.2500\n",
      "Epoch 8 | Iter1 | Loss0.8231 | TrainAcc0.7083 | val acc 0.2708\n",
      "Epoch 8 | Iter3 | Loss0.9145 | TrainAcc0.6667 | val acc 0.2500\n",
      "Epoch 8 | Iter5 | Loss0.9795 | TrainAcc0.5000 | val acc 0.2708\n",
      "Epoch 8 | Iter7 | Loss0.9879 | TrainAcc0.6667 | val acc 0.2708\n",
      "Epoch 9 | Iter1 | Loss0.8844 | TrainAcc0.6250 | val acc 0.2708\n",
      "Epoch 9 | Iter3 | Loss1.0414 | TrainAcc0.5833 | val acc 0.3125\n",
      "Epoch 9 | Iter5 | Loss0.8057 | TrainAcc0.5833 | val acc 0.2917\n",
      "Epoch 9 | Iter7 | Loss0.7501 | TrainAcc0.6667 | val acc 0.2917\n",
      "Epoch 10 | Iter1 | Loss0.7376 | TrainAcc0.6667 | val acc 0.2917\n",
      "Epoch 10 | Iter3 | Loss0.9461 | TrainAcc0.5833 | val acc 0.2500\n",
      "Epoch 10 | Iter5 | Loss1.0007 | TrainAcc0.5000 | val acc 0.2708\n",
      "Epoch 10 | Iter7 | Loss0.7145 | TrainAcc0.8095 | val acc 0.2708\n",
      "Epoch 11 | Iter1 | Loss0.7996 | TrainAcc0.5417 | val acc 0.2708\n",
      "Epoch 11 | Iter3 | Loss0.6464 | TrainAcc0.7500 | val acc 0.2917\n",
      "Epoch 11 | Iter5 | Loss0.5889 | TrainAcc0.7500 | val acc 0.2708\n",
      "Epoch 11 | Iter7 | Loss1.1524 | TrainAcc0.6667 | val acc 0.2708\n",
      "Epoch 12 | Iter1 | Loss0.3855 | TrainAcc0.8333 | val acc 0.2500\n",
      "Epoch 12 | Iter3 | Loss0.5821 | TrainAcc0.7083 | val acc 0.2500\n",
      "Epoch 12 | Iter5 | Loss0.9267 | TrainAcc0.6667 | val acc 0.2708\n",
      "Epoch 12 | Iter7 | Loss0.3925 | TrainAcc0.8571 | val acc 0.2708\n",
      "Epoch 13 | Iter1 | Loss0.6917 | TrainAcc0.6667 | val acc 0.2500\n",
      "Epoch 13 | Iter3 | Loss0.5908 | TrainAcc0.7500 | val acc 0.2917\n",
      "Epoch 13 | Iter5 | Loss0.2528 | TrainAcc0.9583 | val acc 0.3125\n",
      "Epoch 13 | Iter7 | Loss0.4561 | TrainAcc0.7619 | val acc 0.3125\n",
      "Epoch 14 | Iter1 | Loss0.2591 | TrainAcc0.8750 | val acc 0.2917\n",
      "Epoch 14 | Iter3 | Loss0.3998 | TrainAcc0.8333 | val acc 0.2500\n",
      "Epoch 14 | Iter5 | Loss0.4964 | TrainAcc0.8333 | val acc 0.2500\n",
      "Epoch 14 | Iter7 | Loss1.1116 | TrainAcc0.6190 | val acc 0.2708\n",
      "Epoch 15 | Iter1 | Loss0.2581 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 15 | Iter3 | Loss0.1815 | TrainAcc0.9167 | val acc 0.2917\n",
      "Epoch 15 | Iter5 | Loss0.3650 | TrainAcc0.8750 | val acc 0.2917\n",
      "Epoch 15 | Iter7 | Loss0.3218 | TrainAcc0.8571 | val acc 0.3125\n",
      "Epoch 16 | Iter1 | Loss0.2262 | TrainAcc0.9167 | val acc 0.2917\n",
      "Epoch 16 | Iter3 | Loss0.3531 | TrainAcc0.9167 | val acc 0.2917\n",
      "Epoch 16 | Iter5 | Loss0.4803 | TrainAcc0.7500 | val acc 0.2917\n",
      "Epoch 16 | Iter7 | Loss0.1968 | TrainAcc0.9524 | val acc 0.2917\n",
      "Epoch 17 | Iter1 | Loss0.2781 | TrainAcc0.8750 | val acc 0.2500\n",
      "Epoch 17 | Iter3 | Loss0.1748 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 17 | Iter5 | Loss0.2098 | TrainAcc0.9167 | val acc 0.2708\n",
      "Epoch 17 | Iter7 | Loss0.2265 | TrainAcc0.9048 | val acc 0.2708\n",
      "Epoch 18 | Iter1 | Loss0.1421 | TrainAcc0.9583 | val acc 0.3125\n",
      "Epoch 18 | Iter3 | Loss0.2263 | TrainAcc0.8750 | val acc 0.2917\n",
      "Epoch 18 | Iter5 | Loss0.1057 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 18 | Iter7 | Loss0.2194 | TrainAcc0.9048 | val acc 0.2708\n",
      "Epoch 19 | Iter1 | Loss0.1467 | TrainAcc0.9583 | val acc 0.2292\n",
      "Epoch 19 | Iter3 | Loss0.0892 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 19 | Iter5 | Loss0.0848 | TrainAcc1.0000 | val acc 0.2292\n",
      "Epoch 19 | Iter7 | Loss0.3060 | TrainAcc0.9048 | val acc 0.2500\n",
      "Epoch 20 | Iter1 | Loss0.1648 | TrainAcc0.9583 | val acc 0.2083\n",
      "Epoch 20 | Iter3 | Loss0.1053 | TrainAcc0.9583 | val acc 0.2083\n",
      "Epoch 20 | Iter5 | Loss0.2827 | TrainAcc0.8333 | val acc 0.2292\n",
      "Epoch 20 | Iter7 | Loss0.1771 | TrainAcc0.9524 | val acc 0.2292\n",
      "Epoch 21 | Iter1 | Loss0.1636 | TrainAcc0.9583 | val acc 0.2083\n",
      "Epoch 21 | Iter3 | Loss0.1574 | TrainAcc0.9167 | val acc 0.2292\n",
      "Epoch 21 | Iter5 | Loss0.1881 | TrainAcc0.9583 | val acc 0.2292\n",
      "Epoch 21 | Iter7 | Loss0.1466 | TrainAcc0.9048 | val acc 0.2292\n",
      "Epoch 22 | Iter1 | Loss0.0270 | TrainAcc1.0000 | val acc 0.2292\n",
      "Epoch 22 | Iter3 | Loss0.1110 | TrainAcc0.9167 | val acc 0.2292\n",
      "Epoch 22 | Iter5 | Loss0.3598 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 22 | Iter7 | Loss0.0549 | TrainAcc1.0000 | val acc 0.2292\n",
      "Epoch 23 | Iter1 | Loss0.1211 | TrainAcc1.0000 | val acc 0.2292\n",
      "Epoch 23 | Iter3 | Loss0.0704 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 23 | Iter5 | Loss0.0650 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 23 | Iter7 | Loss0.2789 | TrainAcc0.8571 | val acc 0.2708\n",
      "Epoch 24 | Iter1 | Loss0.0092 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 24 | Iter3 | Loss0.0915 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 24 | Iter5 | Loss0.0539 | TrainAcc1.0000 | val acc 0.2500\n",
      "Epoch 24 | Iter7 | Loss0.1845 | TrainAcc0.9048 | val acc 0.2708\n",
      "Epoch 25 | Iter1 | Loss0.1335 | TrainAcc0.8750 | val acc 0.2500\n",
      "Epoch 25 | Iter3 | Loss0.0574 | TrainAcc1.0000 | val acc 0.2500\n",
      "Epoch 25 | Iter5 | Loss0.0634 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 25 | Iter7 | Loss0.0956 | TrainAcc1.0000 | val acc 0.2500\n",
      "Epoch 26 | Iter1 | Loss0.1299 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 26 | Iter3 | Loss0.0211 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 26 | Iter5 | Loss0.0538 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 26 | Iter7 | Loss0.0685 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 27 | Iter1 | Loss0.1049 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 27 | Iter3 | Loss0.1111 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 27 | Iter5 | Loss0.1060 | TrainAcc0.9583 | val acc 0.2917\n",
      "Epoch 27 | Iter7 | Loss0.1325 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 28 | Iter1 | Loss0.0434 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 28 | Iter3 | Loss0.1070 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 28 | Iter5 | Loss0.0445 | TrainAcc1.0000 | val acc 0.2500\n",
      "Epoch 28 | Iter7 | Loss0.0205 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 29 | Iter1 | Loss0.0438 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 29 | Iter3 | Loss0.1304 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 29 | Iter5 | Loss0.0572 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 29 | Iter7 | Loss0.1056 | TrainAcc0.9524 | val acc 0.2708\n",
      "Epoch 30 | Iter1 | Loss0.4528 | TrainAcc0.9167 | val acc 0.2500\n",
      "Epoch 30 | Iter3 | Loss0.0858 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 30 | Iter5 | Loss0.0836 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 30 | Iter7 | Loss0.1189 | TrainAcc0.9524 | val acc 0.2708\n",
      "Epoch 31 | Iter1 | Loss0.0240 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 31 | Iter3 | Loss0.1730 | TrainAcc0.9167 | val acc 0.2917\n",
      "Epoch 31 | Iter5 | Loss0.0593 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 31 | Iter7 | Loss0.0795 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 32 | Iter1 | Loss0.0866 | TrainAcc0.9583 | val acc 0.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Iter3 | Loss0.1192 | TrainAcc0.9583 | val acc 0.2292\n",
      "Epoch 32 | Iter5 | Loss0.1252 | TrainAcc0.9583 | val acc 0.2292\n",
      "Epoch 32 | Iter7 | Loss0.2326 | TrainAcc0.9048 | val acc 0.2292\n",
      "Epoch 33 | Iter1 | Loss0.0522 | TrainAcc0.9583 | val acc 0.2083\n",
      "Epoch 33 | Iter3 | Loss0.1745 | TrainAcc0.9167 | val acc 0.2292\n",
      "Epoch 33 | Iter5 | Loss0.1048 | TrainAcc0.9583 | val acc 0.2500\n",
      "Epoch 33 | Iter7 | Loss0.0438 | TrainAcc1.0000 | val acc 0.2292\n",
      "Epoch 34 | Iter1 | Loss0.0582 | TrainAcc1.0000 | val acc 0.2708\n",
      "Epoch 34 | Iter3 | Loss0.1461 | TrainAcc0.9583 | val acc 0.2292\n",
      "Epoch 34 | Iter5 | Loss0.0725 | TrainAcc0.9583 | val acc 0.2708\n",
      "Epoch 34 | Iter7 | Loss0.4692 | TrainAcc0.9524 | val acc 0.2083\n",
      "Test accuracy is:  0.3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-da6fb444626c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy is: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "val_acc_history = []\n",
    "train_acc_history = []\n",
    "for epoch in range(35):\n",
    "    for i , data in enumerate(train_loader_1, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        train_acc = (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        if i % 2 == 1:\n",
    "            net.eval()\n",
    "            val_correct, val_total = 0, 0 \n",
    "            for val_data in val_loader_1:\n",
    "                val_images, val_labels = val_data\n",
    "                val_outputs = net(val_images)\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (val_predicted == val_labels).sum().item()\n",
    "            val_acc = val_correct / val_total\n",
    "            print('Epoch {} | Iter{} | Loss{:.4f} | TrainAcc{:.4f} | val acc {:.4f}'.format(\n",
    "                epoch, i , loss, train_acc, val_acc))\n",
    "            #writer.add_scalar('Train/Loss',loss,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('Train/ACC',train_acc,epoch*len(trainloader) + i)\n",
    "            #writer.add_scalar('VAL/ACC',val_acc,epoch*len(trainloader) + i)\n",
    "    net.eval()\n",
    "    train_correct, train_total = 0, 0\n",
    "    for train_data in train_loader_1:\n",
    "        train_inputs, train_labels = train_data\n",
    "        train_outputs = net(train_inputs)\n",
    "        _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "        train_total += train_labels.size(0)\n",
    "        train_correct += (train_predicted == train_labels).sum().item()\n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    val_correct, val_total = 0, 0\n",
    "    for val_data in val_loader_1:\n",
    "        val_images, val_labels = val_data\n",
    "        val_outputs = net(val_images)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_acc = val_correct / val_total\n",
    "    val_acc_history.append(val_acc)\n",
    "    #if val_acc == max(val_acc_history):\n",
    "    #    net_best = Net()\n",
    "    #    net_best.load_state_dict(net.state_dict())\n",
    "        \n",
    "test_correct, test_total = 0, 0\n",
    "for test_data in test_loader_1:\n",
    "    test_images, test_labels = test_data\n",
    "    test_outputs = net(test_images)\n",
    "    #test_outputs = net_best(test_images)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    test_total += test_labels.size(0)\n",
    "    test_correct += (test_predicted == test_labels).sum().item()\n",
    "test_acc = test_correct / test_total\n",
    "print('Test accuracy is: ',test_acc)\n",
    "plt.plot(train_acc_history,)\n",
    "plt.plot(val_acc_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train_acc','val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2  3  4]\n",
      "  [ 5  6  7]\n",
      "  [ 1  2  3]]\n",
      "\n",
      " [[-2 -3 -4]\n",
      "  [-5 -6 -7]\n",
      "  [-1 -2 -3]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  5,  6,  7,  1,  2,  3, -2, -3, -4, -5, -6, -7, -1,\n",
       "        -2, -3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[2,3,4],[5,6,7],[1,2,3]],[[-2,-3,-4],[-5,-6,-7],[-1,-2,-3]]])\n",
    "print(a)\n",
    "a.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
